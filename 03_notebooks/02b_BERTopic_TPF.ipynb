{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1752563b",
   "metadata": {
    "id": "1752563b"
   },
   "source": [
    "# Notebook zum Topic Modeling der Drittmitteldaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1cc05",
   "metadata": {
    "id": "3bd1cc05"
   },
   "source": [
    "> Dieses Notebook folgt dem gleichen Aufbau wie das _Topic Modeling_ für die Publikationsdaten.\n",
    "\n",
    "Gleich am Anfang ist einzustellen, ob man einen _Grid Search_ durchführen möchte oder eine _Evaluation Pipeline_. Erstere sucht über die systematische Veränderung von Modellparametern das beste Modell; Zweitere basiert auf den Ergebnissen des _Grid Search_ und kann deswegen nur ausgeführt werden, wenn dieser zumindest einmal gelaufen ist. Die Ergebnisse des _Grid Search_ werden dafür geladen.\n",
    "\n",
    "Das Notebook folgt einem bestimmten Aufbau:\n",
    "1. Die einzelnen Zellen müssen sequentiell, also in Reihe, durchlaufen werden.\n",
    "2. Die einzelnen Schritte des Codes werden jeder für sich erläutert und dann aufbgebaut, durch Variablen und Funktionen, sodass nachfolgende Zellen von vorherigen Zellen abhängen.\n",
    "3. Das Notebook kann dabei zwei verschiedene Ziele verfolgen, (i) Durchführung des _grid search_ und mit dem Ziel der Auswahl eines besten Modells, (ii) Auswertung des _topic modeling_ mit dem vorher eruierten, besten Modell. Es ist darauf zu achten, dass der zweite Schritt nur vollzogen werden kann, wenn der erste zumindest einmal durchgeführt wurde, da auf das gespeicherte, beste Modell zugegriffen werden muss.\n",
    "  3.1 Um das einzustellen, gibt es in Zelle 3 zwei Variablen, die entsprechend zu steuern sind. Alles Weitere passiert dann automatisch.\n",
    "4. Da insb. der _grid search_ nicht lokal durchgeführt werden konnte, gibt es in der ersten Zelle eine automatische Umgebungserkennung, die registrieren kann, ob man lokal oder in Google Colab arbeitet. In Google Colab wurde mit gekauften Recheneinheiten verfahren und einer A100 gearbeitet.\n",
    "\n",
    "> Abschließend ist noch anzumerken, dass alle Stellen, die mit der Hilfe moderner KI-Unterstützung überarbeitet wurden, z. B. aufgrund von Fehlerhaftigkeit oder schlechter Funktionalität, als solche gekennzeichnet sind (zum Suchen: \"**[KI]**\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358dad19",
   "metadata": {
    "id": "358dad19"
   },
   "source": [
    "## Festlegung der _Pipeline_ (_Grid Search_ oder Modellauswertung)\n",
    "\n",
    "Im Folgenden muss festgelegt werden, welche Pipeline genommen werden soll. Dafür muss nur die erste Variable eingestellt werden, entweder True oder False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598086b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1770115380016,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "f598086b",
    "outputId": "0de4acd5-c0a9-419f-9af3-d0c2cdb31237"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##############################################################################\n",
    "grid_search_pipeline = False\n",
    "evaluation_pipeline = True if grid_search_pipeline is False else False\n",
    "\n",
    "using_all_models = True if grid_search_pipeline is True else False  # Wenn True, werden alle Modelle genutzt, die für das Grid Search gebraucht werden! Embeddings werden neu erstellt und gespeichert!\n",
    "using_top_models = False if grid_search_pipeline is True else True  # Wenn True, werden nur die beiden besten Modelle genutzt, basierend auf der Grid-Search-Auswertung! Embeddings werden geladen!\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "print(f\"Grid Search: {grid_search_pipeline}\\nEvaluation: {evaluation_pipeline}\\n\"\n",
    "f\"Alle Modelle einbeziehen: {using_all_models}\\nNur beste Modelle: {using_top_models}\")\n",
    "\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"Wenn man den Grid Search durchführen möchte, sollte man sicherstellen, dass man die Hardware dafür hat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c9cb8",
   "metadata": {
    "id": "460c9cb8"
   },
   "source": [
    "## Start der Vorbereitungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f17ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48965,
     "status": "ok",
     "timestamp": 1770115429032,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "f91f17ac",
    "outputId": "e60ba27b-b79c-491e-adae-6c3dc3b6feea"
   },
   "outputs": [],
   "source": [
    "# Diese erste Zeile prüft automatisch, ob in Colab oder lokal gearbeitet wird und setzt die Pfade\n",
    "# entsprechend zu den unterschiedlichen Verzeichnissen! Außerdem importiert sie die wichtigsten\n",
    "# Module.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Erkennungsvariable als bool setzen\n",
    "colab_active = \"google.colab\" in sys.modules\n",
    "\n",
    "# print(colab_active)\n",
    "\n",
    "if colab_active is True:\n",
    "    print(\"Notebook befindet sich in Colab-Env. Drive wird gemountet und die nötigen\"\n",
    "    \" Pakete werden installiert.\")\n",
    "\n",
    "    print(\"\\nDrive wird verbunden.\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    base_dir = Path(\"/content/drive/Othercomputers/laptop/masterarbeit\")\n",
    "\n",
    "    # cuML GPU Beschleunigung: Import der anderen UMAP und HDBSCAN Module!\n",
    "    # (Quellen:\n",
    "    # https://odsc.medium.com/accelerating-umap-processing-10-million-records-in-under-a-minute-with-no-code-changes-5d580deb05a7\n",
    "    # https://docs.rapids.ai/api/cuml/stable/\n",
    "    # https://docs.rapids.ai/install/#selector)\n",
    "\n",
    "    print(\"\\ncuML-Pakete werden importiert.\")\n",
    "    from cuml.manifold import UMAP\n",
    "    from cuml.cluster import HDBSCAN\n",
    "\n",
    "    # Installation weiterer Packages für das Colab-Environment\n",
    "    print(\"\\nInstallation weiterer Pakete.\")\n",
    "    %pip install -q bertopic sentence-transformers hdbscan anthropic --upgrade gensim litellm\n",
    "\n",
    "    # Pfade werden definiert\n",
    "    data_dir_pubs = base_dir / \"01_data\" / \"01_csv_data\" / \"99_pubmed\"  # nur PubMed!\n",
    "    data_dir_tpf = base_dir / \"01_data\" / \"01_csv_data\"                 # hier liegen tpf Daten\n",
    "\n",
    "    embedds_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"01_embeddings\"\n",
    "    topic_results_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"02_topic_results\"\n",
    "    topic_visuals_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"03_topic_visuals\"\n",
    "    grid_search_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"04_grid_search\"\n",
    "    models_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"05_models\"\n",
    "\n",
    "    # Check auf erreichbare Pfade\n",
    "    all_paths = [base_dir, data_dir_pubs, data_dir_tpf, embedds_dir, topic_results_dir,\n",
    "                 topic_visuals_dir, grid_search_dir, models_dir]\n",
    "\n",
    "    no_paths = [x for x in all_paths if not x.exists()]\n",
    "\n",
    "    if no_paths:\n",
    "        print(f\"Folgende Pfade konnten nicht erreicht werden:\\n{no_paths}.\")\n",
    "    else:\n",
    "        print(\"\\nAlle Pfade konnten gesetzt und gefunden werden!\")\n",
    "\n",
    "else:\n",
    "    print(\"Notebook ist lokal! Pfade werden entsprechend der Ordnerstruktur\"\n",
    "          \" geprüft und ggf. gesetzt.\")\n",
    "\n",
    "    # Import der nicht-GPU-optimierten Module von UMAP und HDBSCAN\n",
    "    print(\"\\nImport der UMAP- und HDBSCAN-Module (nicht-GPU-optimiert).\")\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "\n",
    "    # Ordnerpfade definieren\n",
    "    print(\"\\nAufsetzen und Prüfung der Ordnerpfade in lokaler Umgebung.\")\n",
    "    base_dir = Path.cwd().parent # entspricht dem Ordner \"masterarbeit\"\n",
    "\n",
    "    # Pfade werden definiert\n",
    "    data_dir_pubs = base_dir / \"01_data\" / \"01_csv_data\" / \"99_pubmed\"  # nur PubMed!\n",
    "    data_dir_tpf = base_dir / \"01_data\" / \"01_csv_data\"                 # hier liegen tpf Daten\n",
    "\n",
    "    embedds_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"01_embeddings\"\n",
    "    topic_results_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"02_topic_results\"\n",
    "    topic_visuals_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"03_topic_visuals\"\n",
    "    grid_search_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"04_grid_search\"\n",
    "    models_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"05_models\"\n",
    "\n",
    "    # Check auf erreichbare Pfade\n",
    "    all_paths = [base_dir, data_dir_pubs, data_dir_tpf, embedds_dir, topic_results_dir,\n",
    "                 topic_visuals_dir, grid_search_dir, models_dir]\n",
    "\n",
    "    no_paths = [x for x in all_paths if not x.exists()]\n",
    "\n",
    "    if no_paths:\n",
    "        print(f\"\\nFolgende Pfade konnten nicht erreicht werden:\\n{no_paths}.\")\n",
    "    else:\n",
    "        print(\"\\nAlle Pfade konnten gesetzt und gefunden werden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fec71a",
   "metadata": {
    "id": "d0fec71a"
   },
   "source": [
    "## Alle Importe und Laden der _Transformer Model_\n",
    "\n",
    "Folgend werden alle notwendigen Importe durchgeführt. Außerdem werden die verschiedenen Transformer-Modelle in einer Dataclass geladen -- je nach Pipeline und Umgebung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a2b9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "87ca2a1d2142458aa67cc7b6bf1877b3",
      "54c458d22e5b48d9b6076a7e8290a17e",
      "7ef66a9cdbd041cd9418ea6bbc098248",
      "2deabf501ad34d7880c796f2351661e2",
      "b09542177d384088946a2514f73b5273",
      "6dde8d44b8324277bf5d7e54f37d4bb5",
      "1926dc4eaac34de7a3428b5bd975b222",
      "e369b271a0b9416da04146de02a751d0",
      "7aacc98a0e7f45ea959599097cf1f289",
      "badd13bf50f74daea98ec30117760bd0",
      "5a310bcda62b4975a79e4e7576df95ee",
      "f41575d0024a4ac992ac53148560e48c",
      "9fa21ad3b4064f01bb08bee790c13228",
      "154fe608b8bc46dabe08e7cb13b9b0ed",
      "c93218adea794435ab2852f09a4bedef",
      "07c4d556b4114c10a65726f706d92b99",
      "2ccf9f02ebe3414d862cee82130ce434",
      "72cacfb1ba8542bd821299c89efc163e",
      "52e6941390e546feadc0d81b1e419bba",
      "1ace86caa9df4e3eb3409c8fb6dd6377",
      "d3194b9892e64cf9ac9418226ee49623",
      "9baaf73fc2934c84b7b7c95661c217a3",
      "0250a5ec04e54d1e8b5a68ac68d4f790",
      "64ee00cae2e4404791ee0ef5cd79ec31",
      "60f94fd1fb254ef7bd7654f4eee5fdab",
      "8efbaba7e0f94fd594254bbcf6c088c0",
      "4e3f9444d1f4439cbb7b9b894a96c686",
      "f093dc4510c646f893df6ae5c6d9f8fd",
      "1843b22a228e468ebaa0193788c0d89b",
      "895f3ad0a960416482be655f52793755",
      "325a847296e64ed3a7a3f319007f7db6",
      "c779aa914545456aa91dff11eadfd429",
      "5a3d9742e75841e4bc20d76e0d683822",
      "ca64367fa92b413fa54faa79349d4e17",
      "ade1d69902d4485798961b2596c079f7",
      "6bc43cec0256494ea91ba6b78caaef3b",
      "03c42540727047f2a0a1a5fd34bb358a",
      "46d7adf58e604993bb6b9f263b3764ab",
      "bc2e48fbb35c414e9af669078dbafd82",
      "1a15c1bdf69b4cc4a335b69cdfe1a41c",
      "e251c68f90e8438a99e3241a1895e4ca",
      "0c0ec007ddff4b0c85751df8b5684048",
      "367c615de6e14621a7ab694a650f49e8",
      "b99c7b37393c4386a2a66d1bad9ee709",
      "3ed0a719afcc4f619a06e0a3c4de4c4d",
      "2c19f380213e449b874c8c3fceef1e32",
      "541370bc6b0e4bb19f48a5a63b218f4a",
      "4f669de56ee14a8d9c759c4d86a8ebad",
      "719fef3d5d2e403292ed2c5f9d803ef1",
      "cdf7ca8289334785845cfb46238b9964",
      "7fd676037a494d86b6520f49755cf6bf",
      "6f6f01aa2e634c95b810e0ff0933e5b6",
      "c0e1e22cf25c43e2b2ad16a703c014b0",
      "8c91a43472ec458499243b2984f28a82",
      "fcca2944f98549c2b5a3607c52937305",
      "92ca06d258164d7ba6b0f7466804e62f",
      "f2bd9e5e29e04f95bfc83cb729afd3cd",
      "b90ff5d2fb8e4c2baae7b28f9b30a2d6",
      "045980e5cb9547f5871e1ec1f0f30f8d",
      "d6e50a7795da44d2b30509ab326a8f4d",
      "ab1bf9ef7eac47068bdace45606462df",
      "b742487a29f9417f95d3f4b13bfb6647",
      "ea95716334b942ce9c7da6d1e6d40502",
      "2d4762a6854144d1a82025b4e2e81b95",
      "6ad5ce92b0314cb79519e7232a6beea3",
      "67f8310afe20421aa206872bf2ba0a0c",
      "8fb72d05a2144849a675c9917df6ef86",
      "6c8ab0ed8d0e4957a6163aab50b169e7",
      "61b5144cceab4b00898cb7d6e6c09392",
      "74759cf91ee5482ab71b0a98baa160ac",
      "f092fc9995944ef189cb19f49ce50879",
      "34098022c10e4c83a2e36d7b3d4f31f7",
      "5b92bb94d3164fccb3be1c641915b191",
      "61ccf37f3c684838b703c3eeb2a9e11c",
      "5493bd1152ea493689eb334ed4b3bdb0",
      "c5445aeb3b6a4c0b9d7b7e2beb5c2f9a",
      "3901cad0a4384702b8f2f1d9eb2f7266",
      "c7c7a898a8324444a1905f12861326f5",
      "1ce3b302cd4848c896f0a22adbf46423",
      "b4c2b67218f2411fb0413bbc1ea45103",
      "a4a36e8d477d496ea7d0d8f01c30f8c7",
      "b8d39a5d6fff4fbca0950ef049caba07",
      "0338d0c0695246828bf4ee93602890b0",
      "deb985de79814f58944e546b3fbaf5a5",
      "b52c0834ec4348d293162315d2109e70",
      "eb89652940a1400d978fb4c8223630d0",
      "626bdf7941f446039af4f8a87811f1e5",
      "ec7ce21b3ba647fbba22a11bd7ea16fc",
      "ce0947d352f444c48677ddcd807abe41",
      "f44d40fe895b4081b49b094f15dc8817",
      "80364989a05741e386ea547a2b077b06",
      "aa77323699f8418e83d977cd54f35e44",
      "e468222ccabe420db0b086252f08af39",
      "a30d18c9e23a4a55b5d7d7014f35873d",
      "05b3f6b2ac1b40569becb81aebbcbc62",
      "c5331f08b43e410bbd8c0ffda2f178de",
      "dd00855985084bf8b22438a34ffda085",
      "538ee7bfce224409b827307c36c98b91",
      "4bf9b18876b64b4da4c623b11941a496",
      "5cbe145e524c4777b97a60cefdca99a4",
      "723acf2274aa4bf19ddcc0276ffff623",
      "e04ec7394acc403bafd0ed6814f770d9",
      "f61209bbbd7241e4b178ec8d423cd6a7",
      "fd388ef36dcc43f68ca1cd4edf393314",
      "3a9e302c22874a4386f2f94ccd4b84a2",
      "c5df148d36634c18a80ac36aeb140fda",
      "ce8ca22d7fd84306b0c9f43e96fbd25e",
      "59865b29541f419382c801ff83cfd31c",
      "f4f2dfb3ced44c44905abf7cc2b1350b",
      "d99810bca8a742be8bc4070c263f8525",
      "ccb939f3c8d64a738e11bd1734a9b558",
      "fcaf4105e9414b0787a46ef626a3d943",
      "59c34cf0825441a7a14f0c8326661dc1",
      "eec5410a441847879a2477b78965138e",
      "17f0aaceef114fad8d265f53959985e4",
      "a89de9e0c29e4694b9f3d1fbc604f5b9",
      "7eee9fbcde0043a79b2414a8628023db",
      "4f230da6255a4b618eb1ee55fd7fc2e7",
      "a5236047b0eb4f978f323b97a1280bd5",
      "dbde198bf627403e93c98543f5786fb3",
      "2b610c5053134144ac725aaa23be9238",
      "d2b3dfffc8404349b213e810415e325a",
      "77c42501265e4e148a3e3590990b4c82",
      "fb516bb5ed7f42448f0c3102222c712a",
      "a0c6d52f6b144580bc92a73c1689acc1",
      "cc25f73156394f1d874945a38d75684d",
      "069d134611b84fa18f31c06262462ca0",
      "a5c87dad2c814e41802b6857e47be487",
      "f281923e9d9c4b3b9106387b315839e1",
      "fa759f9ec867412b8cf46d2af8a20ff1",
      "499c0e24c8bf440daa039697e953e6ca",
      "2b8b531e0e2c44cbaabc2ef631218872",
      "4b838bf95f1b4f7a93c66b57682bfaa4",
      "491f0b6b537341bd88dcb37651b9710c",
      "4ec5b294f961472197a8236bce505f22",
      "c66befef6e334a1cab45ac3b80e4d519",
      "87278e020087405cb66f83f253cfefd4",
      "3ef89ab12d1f450c83cf8b9897559c37",
      "e33d32d06d5746438f81b247844a0050",
      "edf5adec5a9b4dc08503eafd2164fd38",
      "0cdc9e59d19149d592d9de079bafe54a",
      "a27813e949f14558a8d3c364dab3b354",
      "d0027c0566364ca2af5254d74d332ff5",
      "a50c60a9ee5348f090c71b07649d6667",
      "b5a4ba7078e5485db52efac6b016ed72",
      "b443af609c7c49c2a9895ae6353e9220",
      "0432f94f452349a2859a7b1cfcdcf177",
      "3acd71a663ea4c6794aab8f6370a907c",
      "aff08fda42ab4c77b7f300f24fbb266c",
      "a96d34f47b14489ca901f9d16d66d7e9",
      "6868d38525214ba1a7d971878b349857",
      "e3fadde9e80e4adea656f20b3c8d5f76",
      "db05613fe5224fec853629fb30c0d2f8",
      "f00a493f053e4506bb6c614dabbf75d6"
     ]
    },
    "executionInfo": {
     "elapsed": 71261,
     "status": "ok",
     "timestamp": 1770115500375,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "298a2b9f",
    "outputId": "1dccce58-4362-4391-fc82-c52994fb1ce6"
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "from typing import Any, Annotated, Callable, Iterable\n",
    "import pandas as pd\n",
    "import re\n",
    "import openpyxl\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from dataclasses import asdict\n",
    "try:\n",
    "    import kaleido\n",
    "except Exception as e:\n",
    "    print(\"Es gibt fortlaufend Probleme mit Kaleido. Wenn es nicht geladen werden kann,\"\n",
    "    \" dann wird es übersprungen. Die Konsequenz ist, dass die Plots nicht als .png \"\n",
    "    \"gespeichert werden können.\")\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "from bertopic.representation import TextGeneration\n",
    "# from crewai import LLM\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(\"Pakete wurden importiert.\")\n",
    "\n",
    "# NLTK Wordnet Check und Load sowie Setzen der Environ_variables\n",
    "if not colab_active:\n",
    "    try:\n",
    "        nltk_path = Path(r\"C:\\Users\\felix\\AppData\\Roaming\\nltk_data\\corpora\\wordnet.zip\")\n",
    "        punkt_path = Path(r\"C:\\Users\\felix\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt_tab\")\n",
    "        stop_words_path = Path(r\"C:\\Users\\felix\\AppData\\Roaming\\nltk_data\\corpora\\stopwords.zip\")\n",
    "\n",
    "        if nltk_path.exists():\n",
    "            print(\"Wordnet-Datei ist schon vorhanden und muss nicht erneut geladen werden!\")\n",
    "        else:\n",
    "            print(\"Das NLTK-Paket konnte nicht gefunden werden und wird jetzt geladen!\")\n",
    "            nltk.download(\"wordnet\")\n",
    "\n",
    "        if punkt_path.exists():\n",
    "            print(\"Punkt-Datei ist schon vorhanden und muss nicht erneut geladen werden!\")\n",
    "        else:\n",
    "            print(\"Das Punkt-Paket konnte nicht gefunden werden und wird jetzt geladen!\")\n",
    "            nltk.download(\"punkt_tab\")\n",
    "\n",
    "        if stop_words_path.exists():\n",
    "            print(\"Stop-Word-Datei ist schon vorhanden und muss nicht erneut geladen werden!\")\n",
    "        else:\n",
    "            print(\"Das Stop-Word-Paket konnte nicht gefunden werden und wird jetzt geladen!\")\n",
    "            nltk.download(\"stopwords\")\n",
    "\n",
    "        # API KEYs\n",
    "        try:\n",
    "            MY_API_KEY = os.environ.get(\"openaikey1\")\n",
    "            if MY_API_KEY is None:\n",
    "                print(\"Der OpenAI-API Key wurde nicht gefunden.\")\n",
    "            else:\n",
    "                print(\"Der OpenAI-API Key wurde geladen.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden der API Keys: {e}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Es kam zu einem Fehler: {e}.\")\n",
    "\n",
    "elif colab_active:\n",
    "    print(\"Das NLTK- und Punkt-Paket wird geladen.\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"punkt_tab\")\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "    # API Key\n",
    "    MY_API_KEY = None\n",
    "\n",
    "#########################################################################################################\n",
    "# Alle wichtigen Vorbereitungsschritte werden hier schon ausgeführt:\n",
    "#########################################################################################################\n",
    "\n",
    "# Tagesdatum aktuell festlegen\n",
    "datum = datetime.datetime.now().strftime(\"%d.%m.%y\")\n",
    "\n",
    "# Dataclass nutzen, um Sentence-Transformer-Modelle zu organisieren\n",
    "# (Quelle: https://www.datacamp.com/tutorial/python-data-classes)\n",
    "@dataclass\n",
    "class Models:\n",
    "    raw_instance: SentenceTransformer\n",
    "    name: str\n",
    "    trained_instance: object | None = None\n",
    "    embeddings: np.ndarray | None = None\n",
    "    doc_topics_assignment: list[int] | None = None\n",
    "    final_topics_df: pd.DataFrame | None = None\n",
    "    umap_n_neighbors: int | None = None\n",
    "    hdbscan_min_cluster_size: int | None = None\n",
    "    hdbscan_min_samples: int | None = None\n",
    "    vectorizer_min_df: int | None = None\n",
    "    vectorizer_max_df: float | None = None\n",
    "\n",
    "if using_all_models is True and using_top_models is True:\n",
    "    raise ValueError(\"\\nEs kann nur eine der beiden Optionen auf True gesetzt werden!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if colab_active is True:\n",
    "    if using_all_models is True:\n",
    "\n",
    "        print(\"\\nColab ist aktiv -- Und: es werden alle Modelle (nicht nur die besten) geladen!\")\n",
    "\n",
    "        # Erstes Dict für die Publikationen\n",
    "        # model_dict = {\n",
    "        #     \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\"), str(\"all-MiniLM\")),\n",
    "        #     \"mpnet-base\": Models(SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=\"cuda\"), str(\"mpnet-base\")),\n",
    "        #     \"pubmed\": Models(SentenceTransformer(\"pritamdeka/S-PubMedBert-MS-MARCO\", device=\"cuda\"), str(\"pubmed\")),\n",
    "        #     \"specter\": Models(SentenceTransformer(\"sentence-transformers/allenai-specter\", device=\"cuda\"), str(\"specter\"))\n",
    "        # }\n",
    "\n",
    "        # Zweites Dict für Drittmittel\n",
    "        model_dict_tpf = {\n",
    "            \"multilingual-mpnet\": Models(SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", device=\"cuda\"), str(\"multilingual-mpnet\")),\n",
    "            \"multilingual-e5-large\": Models(SentenceTransformer(\"intfloat/multilingual-e5-large\", device=\"cuda\"), str(\"multilingual-e5-large\")),\n",
    "            \"LaBSE\": Models(SentenceTransformer(\"sentence-transformers/LaBSE\", device=\"cuda\"), str(\"LaBSE\"))\n",
    "        }\n",
    "\n",
    "    elif using_top_models is True:\n",
    "\n",
    "        print(\"\\nColab ist aktiv -- Und: es werden nur die besten Modelle geladen!\")\n",
    "\n",
    "        # Nur die beiden besten Modelle -- diese müssen manuell zugewiesen werden!\n",
    "        top_model_dict = {\n",
    "            \"LaBSE\": Models(SentenceTransformer(\"sentence-transformers/LaBSE\", device=\"cuda\"), str(\"LaBSE\")),\n",
    "        }\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Trainierte Modelle laden, falls vorhanden\n",
    "        if models_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach dem letzten Modellordner für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    folders = [f.name for f in models_dir.iterdir()]\n",
    "                    print(f\"Liste der Modell-Ordner:\\n{folders}\")\n",
    "                    model_folder = [f for f in folders if y.name+\"_\" in str(f) and \"publications\" in str(f)]\n",
    "                    print(f\"Ausgewählter Modellordner:\\n{model_folder}\")\n",
    "\n",
    "                    if model_folder:\n",
    "                        latest_folder_name = max(model_folder, key=lambda f: (models_dir / f).stat().st_mtime)\n",
    "                        latest_model_path = models_dir / latest_folder_name\n",
    "                        print(f\"\\nTrainiertes Modell für {y.name} wurde gefunden und wird geladen.\")\n",
    "                        y.trained_instance = BERTopic.load(latest_model_path)\n",
    "                    else:\n",
    "                        print(f\"\\nKein trainiertes Modell im Ordner \\\"{models_dir}\\\" für {y.name} gefunden.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden des neuesten {y}-Modellordners: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDer Modelle-Ordner \\\"{models_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "        # Document-Topic-Assignment laden, falls vorhanden\n",
    "        if topic_results_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach der letzten Doc-Topic-Datei für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    files = [f.name for f in topic_results_dir.glob(\"*\")]\n",
    "                    print(f\"Liste der Doc-Topic-Dateien:\\n{files}\")\n",
    "                    file_selection = [f for f in files if y.name+\"_\" in str(f) and \"publications\" in str(f)]\n",
    "                    print(f\"Dateiauswahl:\\n{file_selection}\")\n",
    "\n",
    "                    if file_selection:\n",
    "                        latest_file_name = max(file_selection, key=lambda f: (topic_results_dir / f).stat().st_mtime)\n",
    "                        latest_file_path = topic_results_dir / latest_file_name\n",
    "                        print(f\"\\nDocument-Topic-Assignment für {y.name} wurde gefunden und wird geladen.\")\n",
    "                        y.doc_topics_assignment = pd.read_csv(latest_file_path, encoding=\"utf-8\")[\"topics\"].tolist()\n",
    "                    else:\n",
    "                        print(f\"\\nKeine Doc-Topic-Datei im Ordner \\\"{topic_results_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden der letzten {y}-Doc-Topic_File: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDie Doc-Topic_Datei in \\\"{topic_results_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "\n",
    "elif colab_active is False:\n",
    "    if using_all_models is True:\n",
    "\n",
    "        print(\"\\nCode läuft lokal -- Und: es werden alle Modelle (nicht nur die besten) geladen!\")\n",
    "\n",
    "        # Erstes Dict für die Publikationen\n",
    "        # model_dict = {\n",
    "        #     \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\"), str(\"all-MiniLM\")),\n",
    "        #     \"mpnet-base\": Models(SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\"), str(\"mpnet-base\")),\n",
    "        #     \"pubmed\": Models(SentenceTransformer(\"pritamdeka/S-PubMedBert-MS-MARCO\"), str(\"pubmed\")),\n",
    "        #     \"specter\": Models(SentenceTransformer(\"sentence-transformers/allenai-specter\"), str(\"specter\"))\n",
    "        # }\n",
    "\n",
    "        # Zweites Dict für Drittmittel\n",
    "        model_dict_tpf = {\n",
    "            \"multilingual-mpnet\": Models(SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"), str(\"multilingual-mpnet\")),\n",
    "            \"multilingual-e5-small\": Models(SentenceTransformer(\"intfloat/multilingual-e5-small\"), str(\"multilingual-e5-small\")),\n",
    "            \"LaBSE\": Models(SentenceTransformer(\"sentence-transformers/LaBSE\"), str(\"LaBSE\"))\n",
    "        }\n",
    "\n",
    "    elif using_top_models is True:\n",
    "\n",
    "        print(\"\\nCode läuft lokal -- Und: es werden nur die besten Modelle geladen!\\n\")\n",
    "\n",
    "        # Nur die besten Modelle\n",
    "        top_model_dict = {\n",
    "            \"LaBSE\": Models(SentenceTransformer(\"sentence-transformers/LaBSE\"), str(\"LaBSE\"))\n",
    "        }\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Trainierte Modelle laden, falls vorhanden\n",
    "        if models_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach dem letzten Modellordner für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    folders = [f.name for f in models_dir.iterdir()]\n",
    "                    print(f\"Liste der Modell-Ordner:\\n{folders}\")\n",
    "                    model_folder = [f for f in folders if y.name+\"_\" in str(f) and \"drittmittel\" in str(f)]\n",
    "                    print(f\"Ausgewählter Modellordner:\\n{model_folder}\")\n",
    "\n",
    "                    if model_folder:\n",
    "                        latest_folder_name = max(model_folder, key=lambda f: (models_dir / f).stat().st_mtime)\n",
    "                        latest_model_path = models_dir / latest_folder_name\n",
    "                        print(f\"\\nTrainiertes Modell für {y.name} wurde gefunden und wird geladen.\\n\")\n",
    "                        y.trained_instance = BERTopic.load(latest_model_path)\n",
    "                    else:\n",
    "                        print(f\"\\nKein trainiertes Modell im Ordner \\\"{models_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden des neuesten Modellordners für das Modell {y.name}: {e}.\\n\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDer Modelle-Ordner \\\"{models_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Document-Topic-Assignment laden, falls vorhanden\n",
    "        if topic_results_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach der letzten Doc-Topic-Datei für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    files = [f.name for f in topic_results_dir.glob(\"*\")]\n",
    "                    print(f\"Liste der Doc-Topic-Dateien:\\n{files}\")\n",
    "                    file_selection = [f for f in files if y.name+\"_\" in str(f) and \"drittmittel\" in str(f) and \"doc_topics_assignment_\" in str(f)]\n",
    "                    print(f\"Dateiauswahl:\\n{file_selection}\")\n",
    "\n",
    "                    if file_selection:\n",
    "                        latest_file_name = max(file_selection, key=lambda f: (topic_results_dir / f).stat().st_mtime)\n",
    "                        latest_file_path = topic_results_dir / latest_file_name\n",
    "                        print(f\"\\nDocument-Topic-Assignment für {y.name} wurde gefunden und wird geladen.\\n\")\n",
    "                        y.doc_topics_assignment = pd.read_csv(latest_file_path, encoding=\"utf-8\")[\"topics\"].tolist()\n",
    "                    else:\n",
    "                        print(f\"\\nKeine Doc-Topic-Datei im Ordner \\\"{topic_results_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden der letzten Doc-Topic_File für das Modell {y.name}: {e}.\\n\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDie Doc-Topic_Datei in \\\"{topic_results_dir}\\\" konnte nicht gefunden werden.\\n\")\n",
    "\n",
    "        print(80*\"=\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5fa13",
   "metadata": {
    "id": "5fa5fa13"
   },
   "source": [
    "## Vorverarbeitung der Daten\n",
    "\n",
    "Die Publikationsdaten werden eingelesen und vorverarbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102f2e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3519,
     "status": "ok",
     "timestamp": 1770115503979,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "a102f2e7",
    "outputId": "90542078-a2db-4e16-ef03-7ccb58df55d0"
   },
   "outputs": [],
   "source": [
    "# Laden der Daten und Vorverarbeitung\n",
    "df_tpf_raw = pd.read_excel(f\"{data_dir_tpf}/raw_data_projects_2003-2025.xlsx\",\n",
    "                   engine=\"openpyxl\")\n",
    "\n",
    "# Features eingrenzen\n",
    "df_tpf_raw = df_tpf_raw[[\"Person: Nachname\", \"Projekt: Titel des Projekts Deutsch\", \"Projekt: Titel des Projekts Englisch (GB)\",\n",
    "\"Projekt: Stichwörter Deutsch\", \"Projekt: Stichwörter Englisch (GB)\", \"Projekt: Projektstart an der Universität Münster\",\n",
    "\"Projekt: Projektende an der Universität Münster\", \"Projekt: Kurzzusammenfassung Englisch (GB)\", \"Projekt: Kurzzusammenfassung Deutsch\", \"Projekt: Langbeschreibung Englisch (GB)\",\n",
    "\"Projekt: Langbeschreibung Deutsch\"]].copy()\n",
    "\n",
    "# Features umbenennen\n",
    "df_tpf_raw.rename(columns={\"Person: Nachname\":\"nachname\", \"Projekt: Titel des Projekts Deutsch\":\"title_de\",\n",
    "                        \"Projekt: Titel des Projekts Englisch (GB)\":\"titel_en\", \"Projekt: Stichwörter Deutsch\":\"keywords_de\",\n",
    "                        \"Projekt: Stichwörter Englisch (GB)\":\"keywords_en\", \"Projekt: Projektstart an der Universität Münster\":\"start_date\",\n",
    "                        \"Projekt: Projektende an der Universität Münster\":\"end_date\", \"Projekt: Kurzzusammenfassung Englisch (GB)\":\"short_abstract_en\",\n",
    "                        \"Projekt: Kurzzusammenfassung Deutsch\":\"short_abstract_de\", \"Projekt: Langbeschreibung Englisch (GB)\":\"long_abstract_en\",\n",
    "                        \"Projekt: Langbeschreibung Deutsch\":\"long_abstract_de\"}, inplace=True)\n",
    "\n",
    "# Check\n",
    "print(df_tpf_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f677770",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1770115504124,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "2f677770",
    "outputId": "8e9f32da-9c89-45aa-ec03-f4f9f869b5a9"
   },
   "outputs": [],
   "source": [
    "# Da so viele Daten fehlen und die Einschränkung auf eine Sprache den Datensatz weiter extrem reduzieren würde,\n",
    "# werden alle verfügbaren String-Daten bilingual zusammengestellt! Der Fokus liegt dabei indes auf den deutschen Angaben,\n",
    "# die mit den englischen komplementiert werden. Dafür sind auch Sentence-Transformer geladen, die multilingual arbeiten können.\n",
    "\n",
    "# Zunächst werden alle Duplikate in den Titeln entfernt\n",
    "df_tpf_processed = df_tpf_raw.drop_duplicates(subset=[\"title_de\", \"titel_en\"])\n",
    "\n",
    "# Alle Textdaten in einer Spalte kombinieren\n",
    "df_tpf_processed[\"all_combined\"] = (\n",
    "      df_tpf_processed[\"title_de\"].fillna(df_tpf_processed[\"titel_en\"]).fillna(\"\") + \" \" +            # deutsche Titel werden mit englischen angefüllt\n",
    "      df_tpf_processed[\"keywords_de\"].fillna(df_tpf_processed[\"keywords_en\"]).fillna(\"\") + \" \" +      # deutsche Keywords werden mit englischen angefüllt\n",
    "      df_tpf_processed[\"long_abstract_de\"].fillna(df_tpf_processed[\"long_abstract_en\"]).fillna(\"\")    # deutsche Langbeschreibungen werden mit englischen angefüllt\n",
    ")\n",
    "\n",
    "# Wörteranzahl ermitteln\n",
    "df_tpf_processed[\"word_count\"] = df_tpf_processed[\"all_combined\"].str.split().str.len()\n",
    "\n",
    "# Kurzer Check\n",
    "print(\"Vergleich des ursprünglichen zum vorverarbeiteten Dataframe:\\n\")\n",
    "print(\"\\tVerhältnis von neu zu alt = {} %.\".format(round((((len(df_tpf_processed) / len(df_tpf_raw))*100)), 0)))\n",
    "print(\"\\tAnzahl der Wörter insgesamt = {}.\".format(df_tpf_processed[\"word_count\"].sum()))\n",
    "print(\"\\tMedian der Anzahl der Wörter pro Projekt = {}.\".format(df_tpf_processed[\"all_combined\"].str.split().str.len().median()))\n",
    "print(80*\"=\")\n",
    "print(\"\\n\", \"Info ursprünglicher Dataframe:\", df_tpf_raw.info())\n",
    "print(80*\"=\")\n",
    "print(\"\\n\",\"Info vorverarbeiteter Dataframe:\", df_tpf_processed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bcf7b",
   "metadata": {
    "id": "7b1bcf7b"
   },
   "source": [
    "### Zwischenfazit zur Datenvorverarbeitung\n",
    "\n",
    "Es zeigt sich, dass 715 Datensäte erhalten bleiben, wenn man Duplikate entfernt und die Textdaten kombiniert.\n",
    "\n",
    "Allerdings können nicht alle Projekte auch einem PI zugeordnet werden, insgesamt nur 621. Zudem muss der Zeitrahmen von 2015 bis 2025 eingegrenzt werden.\n",
    "\n",
    "Darauf erfolgt nun ein weiteres _string preprocessing_, um Sonderzeichen und Abkürzungen zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5486b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1770115504421,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "82b5486b",
    "outputId": "f14d4e7c-9005-4f15-9ba3-6a314b5e74c0"
   },
   "outputs": [],
   "source": [
    "# Anzeigeoption einstellen\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "# Check\n",
    "print(df_tpf_processed[[\"start_date\", \"all_combined\", \"word_count\"]].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042cfd29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1770115504577,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "042cfd29",
    "outputId": "1257517e-6e00-4f8c-db69-552af422bf7b"
   },
   "outputs": [],
   "source": [
    "# Regex und Filtern sowie Drop der nicht zugeordneten PI-Projekte\n",
    "\n",
    "# Regex\n",
    "def clean_tpf_text(text: str) -> str:\n",
    "    \"\"\"Diese Funktion bereinigt den Text von HTML-Tags, Förderkennzeichen und\n",
    "    sonstigen, unbrauchbaren Textzeichen.\"\"\"\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    text = re.sub(r\"\\b[A-Z]{2,4}\\s+\\d+\\b\", \"\", text)\n",
    "    text = re.sub(r\"b[A-Z]+-\\d{4}-\\d+\\s*[–-]?\\s*\", \"\", text)\n",
    "    text = re.sub(r\"-?\\s*\\b[A-Z]{2,4}\\d+:?\\s*\", \"\", text)\n",
    "    text = re.sub(r\":\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df_tpf_processed[\"all_combined\"] = df_tpf_processed[\"all_combined\"].apply(clean_tpf_text)\n",
    "\n",
    "# Check\n",
    "print(\"Check der Regex-Anwendung:\\n\")\n",
    "print(df_tpf_processed[\"all_combined\"].head(50))\n",
    "print(80*\"=\")\n",
    "\n",
    "# Filtern und droppen\n",
    "bool_filter = (df_tpf_processed[\"start_date\"].dt.year >= 2015) & (df_tpf_processed[\"end_date\"].dt.year >= 2015)\n",
    "\n",
    "df_tpf_processed_filtered = df_tpf_processed[bool_filter]\n",
    "\n",
    "# Projekte ohne PI droppen\n",
    "df_tpf_processed_filtered.dropna(subset=[\"nachname\"], inplace=True)\n",
    "\n",
    "# Check\n",
    "print(\"Finaler Check des finalen TPF-DF:\\n\")\n",
    "print(df_tpf_processed_filtered.info())\n",
    "print(80*\"=\")\n",
    "print(\"Relative Anzahl der Projekte nach dem Preprocessing: {} %.\".format(round((len(df_tpf_processed_filtered)/len(df_tpf_raw))*100, 0)))\n",
    "print(\"Anzahl der verbleibenden Wörter insgesamt = {}.\".format(df_tpf_processed_filtered[\"word_count\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b27b59",
   "metadata": {
    "id": "a4b27b59"
   },
   "source": [
    "### Embeddings werden erstellt\n",
    "\n",
    "Da die Textvorverarbeitung stattgefunden hat, können jetzt die Embeddings mit den Sentence-Transformern erstellt und gespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79532a",
   "metadata": {
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1770115504718,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "4b79532a"
   },
   "outputs": [],
   "source": [
    "# Die folgende Funktion erstellt ODER lädt bestehende Embeddings der drei verwendeten Modelle\n",
    "# (Anm.: Da das Erstellen der Embeddings einige Zeit in Anspruch nimmt, wurden diese gespeichert und werden jedes Mal wieder geladen,\n",
    "# wenn man es so einstellt bzw. sie vorhanden sind. Dafür ist allerdings auch die richtige Ordnerstruktur entscheidend, damit diese\n",
    "# gespeichert und geladen werden können. )\n",
    "\n",
    "\n",
    "def create_or_load_embeddings(realm: Annotated[str, \"Entweder 'publications' oder 'tpf'\"],\n",
    "                              docs: list[str],\n",
    "                              model_dict: dict,\n",
    "                              # model_names: list[str] = [b.name for _,b in model_dict.items()],\n",
    "                              load_embeds: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Diese Funktion erstellt die Embeddings der Titel+Abstract-Kombinationen für Publikationen und Drittmitteldaten mit vier verschiedenen\n",
    "    Sentence-Transformer-Modellen:\n",
    "\n",
    "    1. Allgemeines Modell\n",
    "    2. PubMed-Modell\n",
    "    3. SciBERT\n",
    "    4. SPECTER2\n",
    "\n",
    "    Dafür werden nur die folgenden Argumente gebraucht:\n",
    "\n",
    "    Args:\n",
    "    - realm = \"publications\" oder \"tpf\"\n",
    "    - docs =\n",
    "    - model_dict =\n",
    "    - load_embedds =\n",
    "\n",
    "    Returns:\n",
    "    - es wird direkt nichts ausgegeben, wohl aber werden die Embeddings in der jeweiligen Model-Class gespeichert!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ###############################################\n",
    "    # 1. Teil: Embeddings **laden**\n",
    "    ###############################################\n",
    "    # Wenn Arg \"load_embeds\" == True (Standardwert), dann werden keine Embeddings erstellt, sondern lokal geladen! Es wird automatisch die\n",
    "    # zuletzt erstelle Datei gesucht\n",
    "\n",
    "    if load_embeds is True:\n",
    "        # Hier werden zunächst die jeweils *letzten* Embeddings identifiziert\n",
    "        embedding_folder_files = list(Path(embedds_dir).glob(\"*.npy\"))\n",
    "\n",
    "        # Schleife für alle Modelle\n",
    "        for x,y in model_dict.items():#\n",
    "            try:\n",
    "                files = [x for x in embedding_folder_files if y.name + \"_\" in str(x).lower()]\n",
    "                latest_file = max(files, key=lambda x: x.stat().st_mtime, default=None)\n",
    "\n",
    "                model_dict[x].embeddings = np.load(latest_file)\n",
    "\n",
    "                print(f\"Name der zuletzt gespeicherten Embeddings aus dem Modell \\\"{y.name}\\\": {latest_file}.\")\n",
    "                print(f\"Prüfung der Anzahl der Embeddings von {y.name} und ihrer Dimensionalität:\")\n",
    "                print(f\"{y.embeddings.shape[0]} Datensätze mit {y.embeddings.shape[1]} Dimensionen.\")\n",
    "                print(80*\"=\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Es konnte keine letzte Datei mit Embeddings zu diesem Modell ({y.name}) gefunden werden.\"\n",
    "                      f\" Es werden jetzt neue Embeddings erstellt. Fehler: {e}.\")\n",
    "                # return False\n",
    "\n",
    "                try:\n",
    "                    # Embeddings werden erstellt\n",
    "                    print(f\"Modell \\\"{y.name}\\\" startet.\")\n",
    "                    start = time.time()\n",
    "                    embeddings = y.raw_instance.encode(docs, batch_size=128, show_progress_bar=True)\n",
    "                    end = time.time()\n",
    "                    print(\"Die Embeddings mit {} sind mit einer Laufzeit von {} Minuten erstellt worden.\\n\".format(y.name, int((end-start)/60)))\n",
    "\n",
    "                    # Embedings werden gespeichert\n",
    "                    embeddings_df = pd.DataFrame(embeddings)\n",
    "                    embeddings_df.to_excel(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.xlsx\",\n",
    "                                        sheet_name=\"embeddings\", engine=\"openpyxl\")\n",
    "                    np.save(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.npy\", embeddings)\n",
    "\n",
    "                    # Embeddings zuweisen\n",
    "                    y.embeddings = embeddings\n",
    "\n",
    "                    # Überprüfung\n",
    "                    print(f\"Prüfung der Anzahl der Embeddings von {y.name} und ihrer Dimensionalität:\")\n",
    "                    print(f\"{y.embeddings.shape[0]} Datensätze mit {y.embeddings.shape[1]} Dimensionen.\")\n",
    "                    print(80*\"=\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Erstellen der Embeddings zum Modell \\\"{y.name}\\\": {e}.\")\n",
    "\n",
    "    ###############################################\n",
    "    # 2. Teil: Embeddings **erzeugen** und speichern (wenn so angegeben!)\n",
    "    ###############################################\n",
    "    # Wenn Arg \"load_embeds\" == False, dann werden keine Embeddings erstellt, sondern geladen.\n",
    "    # Das Erzeugen der Embeddings dauert je nach Kapazitäten und Modellen bis zu 30 Minuten\n",
    "\n",
    "    if load_embeds is False:\n",
    "\n",
    "        # Die Embedding-Objekte sind schon in der ersten Zelle definiert\n",
    "        for x,y in model_dict.items():\n",
    "\n",
    "            try:\n",
    "                # Embeddings werden erstellt\n",
    "                print(f\"Modell \\\"{y.name}\\\" startet.\")\n",
    "                start = time.time()\n",
    "                embeddings = y.raw_instance.encode(docs, batch_size=128, show_progress_bar=True)\n",
    "                end = time.time()\n",
    "                print(\"Die Embeddings mit {} sind mit einer Laufzeit von {} Minuten erstellt worden.\\n\".format(y.name, int((end-start)/60)))\n",
    "\n",
    "                # Embedings werden gespeichert\n",
    "                embeddings_df = pd.DataFrame(embeddings)\n",
    "                embeddings_df.to_excel(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.xlsx\",\n",
    "                                    sheet_name=\"embeddings\", engine=\"openpyxl\")\n",
    "                np.save(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.npy\", embeddings)\n",
    "\n",
    "                # Embeddings zuweisen\n",
    "                y.embeddings = embeddings\n",
    "\n",
    "                # Überprüfung\n",
    "                print(f\"Prüfung der Anzahl der Embeddings von {y.name} und ihrer Dimensionalität:\")\n",
    "                print(f\"{y.embeddings.shape[0]} Datensätze mit {y.embeddings.shape[1]} Dimensionen.\")\n",
    "                print(80*\"=\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Modell {y.name}: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a737874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1770115504922,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "4a737874",
    "outputId": "1fa08f79-d45b-4f1c-f8a6-b3288a3aca9a"
   },
   "outputs": [],
   "source": [
    "# Es verbleiben 38 % der ursprünglichen Datensätze mit etwa 45.000 Wörtern für das folgende Topic Modeling\n",
    "\n",
    "# Das Topic Modeling folgt diesem,. auch für die Publikationen angewendeten Aufbau:\n",
    "# 1. Dataframe laden\n",
    "# 2. Text-Features erstellen\n",
    "# 3. Embeddings erstellen und speichern\n",
    "# 4. Topic-Model trainieren, Topics generieren und beides speichern\n",
    "# 5. Auswertung der Topics und Speicherung der Ergebnisse\n",
    "\n",
    "###########################################################################\n",
    "# DF laden und Text-Feature erstellen -- als Liste\n",
    "###########################################################################\n",
    "tpf_cleaned_docs = df_tpf_processed_filtered[\"all_combined\"].tolist()\n",
    "\n",
    "# print(tpf_cleaned_docs)\n",
    "\n",
    "###########################################################################\n",
    "# Embeddings erstellen und speichern mit allen Modellen aus dem Model-Dict-TPF\n",
    "###########################################################################\n",
    "\n",
    "if using_all_models is True:    # Dieser Weg führt zum Grid Search, Embeddings werden neu erstellt und gespeichert\n",
    "    print(\"Es werden alle Modelle genutzt, für die die Embeddings **neu** erstellt werden.\\n\")\n",
    "    create_or_load_embeddings(\"drittmittel\", tpf_cleaned_docs, model_dict_tpf, load_embeds=False)\n",
    "else:\n",
    "    print(\"Embeddings werden hier nicht erstellt, da die Auswertung der besten Modelle folgt.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gf8-2anGnUeD",
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1770115505045,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "Gf8-2anGnUeD"
   },
   "outputs": [],
   "source": [
    "# Stopwörter definieren\n",
    "\n",
    "# Englische Stopwörter aus dem Skript für Publikationen\n",
    "custom_additions = [\n",
    "    \"the\", \"and\", \"of\", \"in\", \"to\", \"is\", \"for\", \"was\", \"we\", \"that\",\n",
    "    \"with\", \"by\", \"as\", \"are\", \"this\", \"it\", \"from\", \"on\", \"an\", \"be\",\n",
    "    \"were\", \"which\", \"or\", \"at\", \"can\", \"been\", \"has\", \"have\", \"had\",\n",
    "    \"they\", \"their\", \"these\", \"those\", \"than\", \"then\", \"them\", \"there\",\n",
    "    \"when\", \"where\", \"who\", \"will\", \"would\", \"should\", \"could\", \"may\",\n",
    "    \"might\", \"must\", \"our\", \"my\", \"your\", \"its\", \"his\", \"her\", \"into\",\n",
    "    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"up\", \"down\",\n",
    "    \"out\", \"off\", \"over\", \"under\", \"again\", \"further\", \"once\", \"here\",\n",
    "    \"also\", \"such\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\",\n",
    "    \"can\", \"just\", \"don\", \"now\", \"use\", \"using\", \"used\"\n",
    "]\n",
    "\n",
    "# Weitere spezifische Stopwörter\n",
    "academic_stopwords = [\n",
    "    \"study\", \"studies\", \"research\", \"article\", \"paper\", \"results\", \"data\",\n",
    "    \"analysis\", \"methods\", \"method\", \"approach\", \"examined\", \"investigated\",\n",
    "    \"findings\", \"conclusion\", \"conclusions\", \"present\", \"presented\",\n",
    "    \"show\", \"showed\", \"shown\", \"demonstrate\", \"demonstrated\", \"found\",\n",
    "    \"observed\", \"reported\", \"compared\", \"based\", \"studied\", \"analyzed\",\n",
    "    \"identified\", \"examined\", \"evaluated\", \"assessed\", \"determined\",\n",
    "    \"associated\", \"related\", \"significant\", \"ignificantly\", \"effects\",\n",
    "    \"effect\", \"between\", \"among\", \"across\", \"within\", \"using\", \"used\",\n",
    "    \"experiment\", \"experiments\", \"sample\", \"samples\", \"population\",\n",
    "    \"participants\", \"subjects\", \"variables\", \"variable\", \"measured\",\n",
    "    \"measurement\", \"results\", \"conclusions\", \"implications\", \"limitations\",\n",
    "    \"future\", \"directions\", \"introduction\", \"background\", \"literature\",\n",
    "    \"review\", \"theory\", \"theoretical\", \"framework\", \"model\", \"models\"\n",
    "]\n",
    "\n",
    "# Zusammenführen der Stop-Wörter in einer Liste\n",
    "comprehensive_stopwords = list(ENGLISH_STOP_WORDS) + custom_additions + academic_stopwords\n",
    "\n",
    "# Deutsche Stopwörter\n",
    "standard_german_stops = set(stopwords.words(\"german\"))\n",
    "\n",
    "scientific_custom_stops = {\n",
    "    \"beziehungsweise\", \"bzw\", \"sowie\", \"daher\", \"jedoch\", \"hinsichtlich\",\n",
    "    \"bezüglich\", \"innerhalb\", \"außerhalb\", \"aufgrund\", \"entsprechend\",\n",
    "    \"insbesondere\", \"einschließlich\", \"beidseitig\", \"unten\", \"oben\",\n",
    "    \"patient\", \"patienten\", \"abbildung\", \"abb\", \"tabelle\", \"tab\",\n",
    "    \"ergebnis\", \"ergebnisse\", \"methode\", \"methoden\", \"studie\", \"untersuchung\",\n",
    "    \"diskussion\", \"signifikant\", \"signifikanz\", \"fall\", \"falle\", \"prozent\",\n",
    "    \"gruppe\", \"gruppen\", \"vergleich\", \"vs\", \"et\", \"al\", \"ca\", \"mg\", \"ml\"\n",
    "}\n",
    "\n",
    "final_stop_words_ger = standard_german_stops.union(scientific_custom_stops)\n",
    "\n",
    "comprehensive_stopwords_copy = set(comprehensive_stopwords)\n",
    "\n",
    "final_final_stop_words = comprehensive_stopwords_copy.union(final_stop_words_ger)\n",
    "\n",
    "final_stop_words = list(final_final_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc2879",
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1770115505206,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "69dc2879"
   },
   "outputs": [],
   "source": [
    "# Lemmatization hinzufügen, um die KEywords der Topic Cluster zu verbessern, v.a. um doppelte Wörter zu vermeiden!\n",
    "# (Quelle: Dokumentation BERTopic unter: https://github.com/MaartenGr/BERTopic/issues/286)\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "###########################################################################################################\n",
    "# Funktion, um BERTopic zu initialisieren und das Clustering durchzuführen\n",
    "###########################################################################################################\n",
    "\n",
    "def topic_clustering(realm: str, sentence_transformer: SentenceTransformer, docs: list[str], embeddings: np.ndarray, hdbscan_min_cluster_size: int = 20, hdbscan_min_samples: int = 5,\n",
    "                     umap_n_neighbors: int = 15, vec_max_df: float = 0.95, vec_min_df: int = 2, stop_words: list = final_stop_words, save_xlsx: bool = False,\n",
    "                     model_nr_topics: int | None = None, ai_model: str | None = None, model_name: str | None = None, datum: str | None = None, save_model: bool = False):\n",
    "    \"\"\"\n",
    "    Diese Funktion führt ein Topic Modeling auf Basis von vorbearbeiteten Textdaten sowie bereits erstellen Embeddings durch und nimmt zudem\n",
    "    eine Liste mit Stop-Wörtern und Hyperparametern zu den Teilmodulen UMAP und HDBSCAN entgegen.\n",
    "\n",
    "    Args:\n",
    "    - embedding_model = Hier wird das gewählte Embedding Model übergeben.\n",
    "    - docs = Hier werden die Datensätze in Form einer Liste übergeben.\n",
    "    - embeddings = Hier werden die vorkalkulierten Embeddings in einem Array übergeben.\n",
    "    - hdbscan_min_cluster_size = Hier kann die Anzahl der Topics variiert werden (um die Granularität einzustellen). Standardmäßig ist der in dieser Arbeit beste Wert voreingestellt.\n",
    "    - umap_n_neighbors = Legt wiederum die Anzahl der Clustergrößen fest\n",
    "    - model_nr_topics = Hier kann man die Anzahl der Topics im Output direkt festlegen lassen, wenn man bspw. weiß, wie viele es sein sollen.\n",
    "    - stop_words = Hier wird die erweiterte Stopwörterliste übergeben.\n",
    "\n",
    "    Returns:\n",
    "    - Einen Dataframe mit den Ergebnissen des Topic Clusterings.\n",
    "    - Das trainierte Topic Model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Zeit nehmen\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # UMAP zur Dimensionsreduktion mit den Paramtern:\n",
    "        umap_model = UMAP(n_neighbors=umap_n_neighbors, # legt die Anzahl der Clustergröße fest\n",
    "                        n_components=5, # legt die Anzahl der Zieldimension fest, auf die reduziert werden soll\n",
    "                        min_dist=0.0, # legt den Abstand der dimensionreduzierten Clusterpunkte im Raum fest (Unschärfe)\n",
    "                        metric=\"cosine\", # Metrik zur Bestimmung der Abweichungen/Distanzen\n",
    "                        random_state=42 # Sorgt für die Reproduzierbarkeit der Ergebnisse\n",
    "                        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im UMAP-Algorithmus für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # HDBSCAN zum Clustering der Dokumente mit den Parametern\n",
    "        hdbscan_model = HDBSCAN(min_cluster_size=hdbscan_min_cluster_size, # Minimum an Dokumenten für ein Cluster\n",
    "                                min_samples=hdbscan_min_samples, # Dichte der Elemente eines Clusters\n",
    "                                metric=\"euclidean\", # Standardmetrik, passend für wenige Dimensionen\n",
    "                                cluster_selection_method=\"eom\", # Clusterauswahl; Alternative: leaf\n",
    "                                prediction_data=True # ermöglicht neue Vorhersagen für neue Dokumente\n",
    "                            )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im HDBSCAN-Algorithmus für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Vec-Model für stop-word-removal und Erstellung von N-Grammen mit den Parametern:\n",
    "        vectorizer_model = CountVectorizer(stop_words=stop_words, # Übergabe der definierten Stopwörterliste\n",
    "                                        tokenizer=LemmaTokenizer(),\n",
    "                                        min_df=vec_min_df, # wie oft ein Term in den Dokumenten vorkommen **muss**\n",
    "                                        max_df=vec_max_df, # wie oft ein Term in den Dokumenten vorkommen **darf**\n",
    "                                        ngram_range=(1, 2), # Angabe der N-Gramme (hier: Ein- bis einschl. Zwei-Wort-Paare)\n",
    "                                        token_pattern=r\"\\b[a-zA-Z]{3,}\\b\" # Akzeptiert werden nur Wörter mit mind. 3 Buchstaben\n",
    "                                        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im CountVectorizer für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Representation Model (Empfehlung aus der Dokumentation) -- kann man mit OpenAI machen, muss man aber nicht\n",
    "\n",
    "    # gpt_5_1 = LLM(\n",
    "    #         model=\"gpt-5.1\",\n",
    "    #         drop_params=True,\n",
    "    #         additional_drop_params=[\"stop\"]\n",
    "    #     )\n",
    "\n",
    "    representation_model = None\n",
    "    if ai_model is None:\n",
    "        print(\"Es wird kein LLM für die Repräsentationen verwendet!\")\n",
    "        representation_model = KeyBERTInspired()\n",
    "    elif ai_model == \"open_ai\":\n",
    "        print(\"\\nOpenAI soll für das Representation Model genutzt werden.\")\n",
    "        if MY_API_KEY:\n",
    "            print(\"\\nAPI-Key konnte gefunden werden!\")\n",
    "            client = openai.OpenAI(api_key=MY_API_KEY)\n",
    "\n",
    "            # Erstellung der Prompts nach Dokumentation von Grootendorst!\n",
    "            summarization_prompt = \"\"\"\n",
    "            I have a topic that is described by the following keywords: [KEYWORDS]\n",
    "            In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
    "            [DOCUMENTS]\n",
    "\n",
    "            Based on the information above, please give a description of this topic in the following format:\n",
    "            topic: <description>\n",
    "            \"\"\"\n",
    "            title_prompt= \"\"\"\n",
    "            I have a topic that contains the following documents:\n",
    "            [DOCUMENTS]\n",
    "            The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "            Based on the information above, extract a short topic label in the following format:\n",
    "            topic: <topic label>\n",
    "            \"\"\"\n",
    "\n",
    "            #Modeldefinition\n",
    "            representation_model = {\n",
    "                \"Main\": KeyBERTInspired(),\n",
    "                \"ChatGPT\": OpenAI(client, model=\"gpt-4o\",\n",
    "                                  prompt=summarization_prompt,\n",
    "                                  nr_docs=5,\n",
    "                                  delay_in_seconds=10 #,\n",
    "                                  #generator_kwargs={\"stop\": None}\n",
    "                                  ),\n",
    "                \"ChatGPT_titles\": OpenAI(client, model=\"gpt-4o\",\n",
    "                                         prompt=title_prompt,\n",
    "                                         nr_docs=5,\n",
    "                                         delay_in_seconds=4)\n",
    "            }\n",
    "        else:\n",
    "            print(\"Kein OpenAI-API-Key vorhanden! KeyBERTInspired wird genommen!\")\n",
    "            representation_model = KeyBERTInspired()\n",
    "\n",
    "    if representation_model is None:\n",
    "        raise ValueError(\"Aufgrund eines Fehlers wurde kein Representation Model geladen!\")\n",
    "\n",
    "    try:\n",
    "        # BERTopic starten mit den Parametern:\n",
    "        topic_model = BERTopic(embedding_model=sentence_transformer,        # Sentence-Transformer-Modell\n",
    "                            umap_model=umap_model,                          # Modell zur Dimensreduktion\n",
    "                            hdbscan_model=hdbscan_model,                    # Clusteringmodell\n",
    "                            vectorizer_model=vectorizer_model,              # Vectorizer\n",
    "                            representation_model=representation_model,      # zwei Representation Models\n",
    "                            nr_topics=model_nr_topics,                      # Festlegung auf Zielwert der Topic-Anzahl\n",
    "                            verbose=True,                                   # Fortschrittsanzeige\n",
    "                            calculate_probabilities=True,                   # Topic-Wahrscheinlichkeiten\n",
    "                            )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im Aufruf des BERTopic-Moduls für das Modell \\\"{model_name}\\\": {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Beginn des Clusterings der Themen\n",
    "    topics = None\n",
    "    probs = None\n",
    "    try:\n",
    "        print(f\"\\nDas Topic Modeling wird jetzt für das Modell \\\"{model_name}\\\" initiiert.\\n\")\n",
    "        topics, probs = topic_model.fit_transform(docs, embeddings=embeddings)\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"max_df corresponds to < documents than min_df\" in str(e):\n",
    "            print(80*\"=\", f\"\\nBeim Model \\\"{model_name}\\\" ist in diesem Durchlauf der bekannte Fehler aufgetreten\"\n",
    "                  f\": {e}.\\nDie Funktion wird weiter ausgeführt.\\n\", 80*\"=\")\n",
    "        else:\n",
    "            print(f\"Fehler im Topic Modeling für das Modell \\\"{model_name}\\\": {e}.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Outlier autom. reduzieren lassen im Sinne einer nachträglichen Clusterzuordnung\n",
    "    if topics is not None:\n",
    "        try:\n",
    "            new_topics = topic_model.reduce_outliers(docs, topics, strategy=\"distributions\")\n",
    "            topic_model.update_topics(docs, topics=new_topics, representation_model=representation_model)\n",
    "            topics = new_topics\n",
    "\n",
    "            # Speichern\n",
    "            df_doc_topics = pd.DataFrame({\"topics\": topics})\n",
    "            df_doc_topics.to_csv(topic_results_dir / f\"doc_topics_assignment_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "            print(\"\\nTopic-Dokumenten-Zuordnung wurde erfolgreich gespeichert.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Fehler in der Reduzierung der Outlier-Themen beim Modell \\\"{model_name}\\\": {e}.\")\n",
    "            new_topics = topics if topics is not None else None\n",
    "            # Speichern\n",
    "            df_doc_topics = pd.DataFrame({\"topics\": new_topics})\n",
    "            df_doc_topics.to_csv(topic_results_dir / f\"doc_topics_assignment_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "            print(\"Fehler! Die Topic-Dokumenten-Zuordnung wurde dennoch erfolgreich gespeichert.\")\n",
    "    elif topics is None:\n",
    "            new_topics = None\n",
    "            print(f\"Das Topic Modeling für das Modell \\\"{model_name}\\\" konnte nicht durchgeführt werden. Die Topics sind None.\")\n",
    "\n",
    "    # Ergebnisse der Topics als Df einer Variable zuweisen\n",
    "    topics_summary = topic_model.get_topic_info()\n",
    "\n",
    "    # Zeit nehmen\n",
    "    end_time = time.time()\n",
    "    duration = round(int(((end_time - start_time)/60)), 0)\n",
    "\n",
    "    # Kurze Auswertungen pro Durchgang ausgeben\n",
    "    print(80*\"=\")\n",
    "    print(f\"\\nAnalyseergebnisse für das Modell \\\"{str(model_name)}\\\" bei einer Laufzeit von {duration if duration > 0 else 1} Minuten:\\n\")\n",
    "    print(f\"1. Parameter:\\n1.1 HDBSCAN min_cluster_size = {hdbscan_min_cluster_size},\\n1.1 HDBSCAN min_sample_size ={hdbscan_min_samples},\"\n",
    "        f\"\\n1.2 UMAP n_neighbors = {umap_n_neighbors},\"\n",
    "        f\"\\n1.3 Vectorizer max_df = {vec_max_df},\"\n",
    "        f\"\\n1.4 Vectorizer min_df = {vec_min_df},\\n1.5 BERTopic Model min_nr_topics = {model_nr_topics},\\n1.6 AI Model = {ai_model}\")\n",
    "    print(f\"2. Anzahl der gefundenen Topics = {len(topics_summary)-1}.\") # Outlier werden nicht mit angegeben!\n",
    "    print(f\"3. Mittelwert der Publikationen pro Topic = {topics_summary[\"Count\"].mean():.0f}\")\n",
    "    print(f\"4. Relation der Outliers am Gesamtkorpus = {((topics_summary[\"Count\"].iloc[0] / topics_summary[\"Count\"].sum())*100):.2f} %.\")\n",
    "    print(f\"5. Die Variable \\\"topics\\\" enthält die Topic-Zuordnungen pro Dokument und war nicht leer = {topics is not None}.\")\n",
    "    print(80*\"=\")\n",
    "\n",
    "    # Ergebnisse pro Durchgang in xlsx und csv lokal speichern\n",
    "    if save_xlsx is True:\n",
    "        df = pd.DataFrame(topics_summary)\n",
    "        df.to_excel(rf\"{topic_results_dir}/topic_results_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.xlsx\", sheet_name=\"daten\", engine=\"openpyxl\")\n",
    "        df.to_csv(rf\"{topic_results_dir}/topic_results_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "        #os.startfile(rf\"C:\\Users\\felix\\OneDrive\\Desktop\\masterarbeit\\01_data\\03_topic_modeling\\topic_results_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.xlsx\")\n",
    "\n",
    "    # Das trainierte Modell ggf. speichern, damit es immer wieder geladen werden kann\n",
    "    full_path = models_dir / f\"{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}\"\n",
    "\n",
    "    # Modell speichern\n",
    "    if save_model is True:\n",
    "        try:\n",
    "            topic_model.save(full_path,\n",
    "                            serialization=\"safetensors\",\n",
    "                            save_ctfidf=True,\n",
    "                            save_embedding_model=sentence_transformer)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern des trainierten Modells {model_name}: {e}.\")\n",
    "            pass\n",
    "\n",
    "    return probs, topics, topics_summary, topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb241eb",
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1770115505800,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "fdb241eb"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Definition zweier Gensim-Coherence-Score-Funktionen als eines zentralen Gütekriterium für die Topic-Modelle\n",
    "# (vgl. Röder Röder, Michael, Andreas Both, und Alexander Hinneburg. „Exploring the space of topic coherence measures“.\n",
    "# Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, 2015)\n",
    "###########################################################################\n",
    "# Dieser Code wurde mit Hilfe von Copilot vervollständigt [KI]\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def gensim_coherence(trained_topic_model: SentenceTransformer, documents: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet den C-V-Score für ein trainiertes BERTopic-Modell.\n",
    "    \"\"\"\n",
    "\n",
    "    topics = trained_topic_model.get_topics()\n",
    "\n",
    "    topic_words = []\n",
    "    for topic_id in topics:\n",
    "        if topic_id != -1:\n",
    "            words = [word for word, _ in trained_topic_model.get_topic(topic_id)[:10]]\n",
    "            topic_words.append(words)\n",
    "\n",
    "    splitted_docs = [doc.lower().split() for doc in documents]\n",
    "\n",
    "    dict = Dictionary(splitted_docs)\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=splitted_docs,\n",
    "        dictionary=dict,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "\n",
    "    score = coherence_model.get_coherence()\n",
    "\n",
    "    return score\n",
    "\n",
    "def gensim_coherence_npmi(trained_topic_model: SentenceTransformer, documents: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet den C-NPMI-Score für ein trainiertes BERTopic-Modell.\n",
    "    \"\"\"\n",
    "\n",
    "    topics = trained_topic_model.get_topics()\n",
    "\n",
    "    topic_words = []\n",
    "    for topic_id in topics:\n",
    "        if topic_id != -1:\n",
    "            words = [word for word, _ in trained_topic_model.get_topic(topic_id)[:10]]\n",
    "            topic_words.append(words)\n",
    "\n",
    "    splitted_docs = [doc.lower().split() for doc in documents]\n",
    "\n",
    "    dict = Dictionary(splitted_docs)\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=splitted_docs,\n",
    "        dictionary=dict,\n",
    "        coherence=\"c_npmi\"\n",
    "    )\n",
    "\n",
    "    score = coherence_model.get_coherence()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510ed7f",
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1770115506018,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "e510ed7f"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Topics erstellen\n",
    "###########################################################################\n",
    "\n",
    "# Funktion aufrufen, aber mit leicht anderen Baseline-Parametern aufgrund der neuen Daten\n",
    "# for key, value in model_dict_tpf.items():\n",
    "#     print(f\"Topics werden erstellt mit dem Modell \\\"{value.name}\\\".\")\n",
    "#     _, model_dict_tpf[key].doc_topics_assignment, model_dict_tpf[key].final_topics_df, model_dict_tpf[key].trained_instance = topic_clustering(\n",
    "#         realm=\"drittmittel\",\n",
    "#         sentence_transformer=model_dict_tpf[key].raw_instance,\n",
    "#         docs=tpf_cleaned_docs,\n",
    "#         embeddings=model_dict_tpf[key].embeddings,\n",
    "#         hdbscan_min_cluster_size=5,\n",
    "#         hdbscan_min_samples=3,\n",
    "#         umap_n_neighbors=10,\n",
    "#         vec_max_df=1.0,\n",
    "#         vec_min_df=4,\n",
    "#         stop_words=final_stop_words,\n",
    "#         model_name=model_dict_tpf[key].name,\n",
    "#         save_xlsx=True)\n",
    "#     print(90*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b007163",
   "metadata": {
    "id": "5b007163"
   },
   "source": [
    "## Hyperparameter-Tuning im Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U5GcnJ2kpkpm",
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1770115506198,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "U5GcnJ2kpkpm"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Hyperparameter-Tuning\n",
    "###########################################################################\n",
    "\n",
    "#########################################################\n",
    "# Hyperparameter-Tuning-Funktion\n",
    "#########################################################\n",
    "\n",
    "def hyperp_tuning(tuple_list: Annotated[tuple, \"Hier werden fünf Variablen übergeben: embedding_model, docs, embeddings, model_name, datum\"],\n",
    "                  hdbscan_cluster_range: list[int] = [15],\n",
    "                  hdbscan_sample_range: list[int] = [5],\n",
    "                  umap_neighbor_range: list[int] = [10],\n",
    "                  cv_mindf_range: list[int] = [4],\n",
    "                  cv_maxdf_range: list[float] = [0.9]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Diese Funktion ist ein systematisches Hyperparamter-Tuning für die drei ausgewählten Sentence-Transformer und verschiedene\n",
    "    Hyperparameter in den folgenden Algorithmen: HDBSCAN, UMAP.\n",
    "\n",
    "    Args:\n",
    "    -\n",
    "\n",
    "    Returns:\n",
    "    - Dataframe mit den Ergebnissen für alle Modelle und Hyperparameter-Ranges\n",
    "    \"\"\"\n",
    "\n",
    "    for a,b,c,d,e in tuple_list:\n",
    "\n",
    "        for umap in umap_neighbor_range:                    # UMAP n-neighbors alternieren lassen\n",
    "\n",
    "            for hdbscan_cluster in hdbscan_cluster_range:   # HDBSCAN min_cluster_size alternieren lassen\n",
    "\n",
    "                for hdbscan_sample in hdbscan_sample_range: # HDBSCAN sample_size alternieren lassen\n",
    "\n",
    "                    for cv_mindf in cv_mindf_range:         # CountVectorizer alternieren lassen\n",
    "\n",
    "                        for cv_maxdf in cv_maxdf_range:     # CountVectorizer alternieren lassen\n",
    "\n",
    "                            probs, topics_all, topics, topic_model = topic_clustering(\n",
    "                                                                                    realm=\"drittmittel\",\n",
    "                                                                                    sentence_transformer=a,\n",
    "                                                                                    docs=b,\n",
    "                                                                                    embeddings=c,\n",
    "                                                                                    stop_words=comprehensive_stopwords,\n",
    "                                                                                    umap_n_neighbors=umap,\n",
    "                                                                                    hdbscan_min_cluster_size=hdbscan_cluster,\n",
    "                                                                                    hdbscan_min_samples=hdbscan_sample,\n",
    "                                                                                    vec_min_df=cv_mindf,\n",
    "                                                                                    vec_max_df=cv_maxdf,\n",
    "                                                                                    save_xlsx = True,\n",
    "                                                                                    save_model=False,\n",
    "                                                                                    model_name=d,\n",
    "                                                                                    datum=e)\n",
    "                            if topics is not None:\n",
    "                                try:\n",
    "                                    ergebnisse.append({\n",
    "                                        \"model\": str(d),\n",
    "                                        \"umap_n_neighbors\": umap,\n",
    "                                        \"hdbscan_min_cluster_size\": hdbscan_cluster,\n",
    "                                        \"hdbscan_min_samples_size\": hdbscan_sample,\n",
    "                                        \"vectorizer_mind_df\": cv_mindf,\n",
    "                                        \"vectorizer_max_df\":cv_maxdf,\n",
    "                                        \"count_topics\": (len(topics)-1),\n",
    "                                        \"relation_outliers\": topics[\"Count\"].iloc[0] / topics[\"Count\"].sum(),\n",
    "                                        \"median_topic_cluster\": topics[\"Count\"][1:].median(),\n",
    "                                        \"average_topic_cluster\": topics[\"Count\"][1:].mean(),\n",
    "                                        \"topic_cluster_sizes\": topics[\"Count\"][1:].tolist(),\n",
    "                                        \"keywords_list\": topics[\"Representation\"][1:].tolist(),\n",
    "                                        \"topic_names\": topics[\"Name\"][1:].tolist(),\n",
    "                                        \"c_v_score\": gensim_coherence(topic_model, b),\n",
    "                                        \"c_npmi_score\": gensim_coherence_npmi(topic_model, b)\n",
    "                                    })\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Fehler bei Modell {str(d)} während des Speicherns der Ergebnisse: {e}.\")\n",
    "                                    pass\n",
    "                            else:\n",
    "                                print(\"Die Topics sind leer oder fehlerhaft. Die Funktion geht zum nächsten Durchlauf.\")\n",
    "\n",
    "                                ergebnisse.append({\n",
    "                                        \"model\": str(d),\n",
    "                                        \"umap_n_neighbors\": umap,\n",
    "                                        \"hdbscan_min_cluster_size\": hdbscan_cluster,\n",
    "                                        \"hdbscan_min_samples_size\": hdbscan_sample,\n",
    "                                        \"vectorizer_mind_df\": cv_mindf,\n",
    "                                        \"vectorizer_max_df\":cv_maxdf,\n",
    "                                        \"count_topics\": 0,\n",
    "                                        \"relation_outliers\": 0,\n",
    "                                        \"median_topic_cluster\": 0,\n",
    "                                        \"average_topic_cluster\": 0,\n",
    "                                        \"topic_cluster_sizes\": 0,\n",
    "                                        \"keywords_list\": 0,\n",
    "                                        \"topic_names\": 0,\n",
    "                                        \"c_v_score\": 0,\n",
    "                                        \"c_npmi_score\": 0\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4956d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1770115506374,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "28c4956d",
    "outputId": "83402f4f-6fbd-4dea-856f-10e8c8f0d40d"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Hyperparameter-Tuning für Drittmitteldaten\n",
    "###########################################################################\n",
    "\n",
    "# Erstellung der Ergebnisliste\n",
    "ergebnisse = []\n",
    "\n",
    "#############################################################################################\n",
    "# Funktion aufrufen für Grid-Search\n",
    "#############################################################################################\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"Es wird das Hyperparameter-Tuning (Grid-Search) für die Drittmitteldaten gestartet.\\n\")\n",
    "\n",
    "    tuples_models = []\n",
    "    for x,y in model_dict_tpf.items():\n",
    "        tuples_models.append((y.raw_instance, tpf_cleaned_docs, y.embeddings, y.name, datum))\n",
    "\n",
    "    #############################################################################################\n",
    "    # Grid-Search durchführen für 3 Modelle mit 5 Parametern und je 3 Werten (3*3*3*3*3*3 = 729 Loops!)\n",
    "    #############################################################################################\n",
    "\n",
    "    try:\n",
    "        start_point = time.time()\n",
    "\n",
    "        hyperp_tuning(\n",
    "            tuple_list = tuples_models,\n",
    "            hdbscan_cluster_range=[10, 15, 20],\n",
    "            hdbscan_sample_range=[2, 5, 10],\n",
    "            umap_neighbor_range= [10, 20, 30],\n",
    "            cv_mindf_range= [2, 3, 4],\n",
    "            cv_maxdf_range = [0.75, 0.85, 0.90]\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFehler: {e}.\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # Ergebnisliste als Dataframe speichern und öffnen\n",
    "        df_ergebnisse_tpf = pd.DataFrame(ergebnisse)\n",
    "\n",
    "        df_ergebnisse_tpf.to_excel(rf\"{grid_search_dir}/grid_search_results_tpf_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"tuning_results\")\n",
    "        df_ergebnisse_tpf.to_csv(rf\"{grid_search_dir}/grid_search_results_tpf_{datum}.csv\", encoding=\"utf-8\")\n",
    "        try:\n",
    "            os.startfile(rf\"{grid_search_dir}/grid_search_results_tpf_{datum}.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(\"Die Exceldatei konnte nicht geöffnet werden.\")\n",
    "\n",
    "        # Laufzeit final ausgeben\n",
    "        end_point = time.time()\n",
    "        dur = round(int((end_point-start_point)/60), 0)\n",
    "        print(f\"Laufzeit des Grid-Search insgesamt {dur} Minuten.\")\n",
    "else:\n",
    "    print(\"Das Hyperparameter-Tuning (Grid-Search) für die Drittmitteldaten wird hier nicht durchgeführt.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40928aaf",
   "metadata": {
    "id": "40928aaf"
   },
   "source": [
    "## Auswertung der Grid-Search-Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a052fc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1770115506510,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "4a052fc0",
    "outputId": "c0217d23-3ba2-437f-ffc1-39b9f0eba8e6"
   },
   "outputs": [],
   "source": [
    "if grid_search_pipeline is True:\n",
    "    print(\"Es wird die Ausgabedatei der Grid-Search für die Publikationsdaten eingelesen und ausgewertet.\\n\")\n",
    "\n",
    "    # Letzte Grid-Search-Datei finden\n",
    "    grid_files_tpf = [x for x in grid_search_dir.glob(\"*\") if x.name.startswith(\"grid_search_results_tpf_\")]\n",
    "\n",
    "    # Nur gültige Excel-Dateien berücksichtigen\n",
    "    valid_grid_files_tpf = []\n",
    "    for file in grid_files_tpf:\n",
    "        try:\n",
    "            pd.read_excel(file, engine=\"openpyxl\", nrows=1)\n",
    "            valid_grid_files_tpf.append(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Warnung: Datei {file.name} konnte nicht gelesen werden ({e}). Sie wird übersprungen.\")\n",
    "\n",
    "    if not valid_grid_files_tpf:\n",
    "        print(\"Fehler: Keine gültigen Grid-Search-Dateien gefunden.\")\n",
    "    else:\n",
    "        latest_grid_file_tpf = max(valid_grid_files_tpf, key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "        df_grid_search_tpf = pd.read_excel(latest_grid_file_tpf, engine=\"openpyxl\")\n",
    "\n",
    "        # Checks\n",
    "        print(f\"Spalten des DataFrames: {df_grid_search_tpf.columns.tolist()}\")\n",
    "        print(\"Länge des Dataframes: \", len(df_grid_search_tpf))\n",
    "\n",
    "        # Auswertung des Grid-Search in einigen Kennzahlen nach folgenden Überlegungen:\n",
    "        # 1. Zentral sind die verschiedenen Modelle\n",
    "        # 2. Die Hyperparameter spielen zunächst keine primäre Rolle, sondern nur die Themenergebnisse\n",
    "        # 3. count_topics: Anzahl der Topics ist kritisch und ein Gütemaß für das Modell\n",
    "        # 4. relation_outliers: Ebenfalls kritisch, da das Ausmaß von them. Außenseitern Auskunft über die Breite der Thmene gibt\n",
    "        # 5. topic_cluster_sizes: Werden genutzt, um zu überprüfen, wie gleichverteilt die Themen sind, was die Dokumente angeht\n",
    "        # 6. keywords_list und topic_names: Werden genutzt, um zu überprüfen, wie viele wörtliche Überschneidungen es zwischen den Themen gibt\n",
    "\n",
    "        df_tpf_grouped = df_grid_search_tpf.groupby(\"model\").agg({\n",
    "            \"count_topics\":\"mean\",\n",
    "            \"relation_outliers\":\"mean\",\n",
    "            #\"topic_cluster_sizes\":\"modus\",\n",
    "            \"c_v_score\": \"mean\",\n",
    "            \"average_topic_cluster\": [\"mean\", \"min\", \"max\"]\n",
    "        })\n",
    "\n",
    "        # Check\n",
    "        print(df_tpf_grouped)\n",
    "\n",
    "        # Umwandlung der Keywords-Listen von Strings in Listen-Objekte\n",
    "        def list_conversion(x):\n",
    "            \"\"\"Liest die Strings aus und wandelt sie in verschachtelte Listen um.\"\"\"\n",
    "\n",
    "            if pd.isna(x) or x is None:\n",
    "                return []\n",
    "\n",
    "            if isinstance(x, str):\n",
    "                return ast.literal_eval(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        ###############################################\n",
    "        # Anwendung der Funktion auf die Keyword-Spalte\n",
    "        ###############################################\n",
    "        try:\n",
    "            df_grid_search_tpf[\"keywords_list\"] = df_grid_search_tpf[\"keywords_list\"].apply(list_conversion)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Umwandlung der Keywords-Listen: {e}.\")\n",
    "            pass\n",
    "\n",
    "        def uniqueness_of_keywords(keywords_list: list[list[str]]) -> float:\n",
    "            \"\"\"\n",
    "            Diese Funktion berechnet den Anteil einzigartiger Keywords in einer Liste von Keyword-Listen.\n",
    "\n",
    "            Args:\n",
    "            - keywords_list = Liste von Listen mit Keywords pro Topic\n",
    "\n",
    "            Returns:\n",
    "            - Anteil einzigartiger Keywords als Float\n",
    "            \"\"\"\n",
    "\n",
    "            if not isinstance(keywords_list, list):     # Sollte durch Vorverarbeitung mit \"list_conversion\" ausgeschlossen sein!\n",
    "                return 0.0\n",
    "\n",
    "            all_keywords = [x for sublist in keywords_list for x in sublist]\n",
    "            unique_keywords = set(all_keywords)\n",
    "\n",
    "            uniqueness_ratio = len(unique_keywords) / len(all_keywords) if all_keywords else 0\n",
    "\n",
    "            return uniqueness_ratio\n",
    "\n",
    "        ###############################################\n",
    "        # Anwendung der Funktion auf die Keywords-Spalte\n",
    "        ###############################################\n",
    "        try:\n",
    "            df_grid_search_tpf[\"keyword_uniqueness\"] = df_grid_search_tpf[\"keywords_list\"].apply(uniqueness_of_keywords)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Berechnung der Keyword-Einzigartigkeit: {e}.\")\n",
    "            pass\n",
    "\n",
    "        # Finaler Check der Ergebnisse\n",
    "        try:\n",
    "            print(\"Kurzer Check des finalen Df mit den neu erstellten Features.\\n\")\n",
    "\n",
    "            # Auswertung des Grid-Search in einigen Kennzahlen nach folgenden Überlegungen:\n",
    "            # 1. Zentral sind die verschiedenen Modelle\n",
    "            # 2. Die Hyperparameter spielen zunächst keine primäre Rolle, sondern nur die Themenergebnisse\n",
    "            # 3. count_topics: Anzahl der Topics ist kritisch und ein Gütemaß für das Modell\n",
    "            # 4. relation_outliers: Ebenfalls kritisch, da das Ausmaß von them. Außenseitern Auskunft über die Breite der Thmene gibt\n",
    "            # 5. topic_cluster_sizes: Werden genutzt, um zu überprüfen, wie gleichverteilt die Themen sind, was die Dokumente angeht\n",
    "            # 6. keywords_list und topic_names: Werden genutzt, um zu überprüfen, wie viele wörtliche Überschneidungen es zwischen den Themen gibt\n",
    "\n",
    "            df_grouped = df_grid_search_tpf.groupby(\"model\").agg({\n",
    "                \"count_topics\":[\"mean\", \"min\", \"max\"],\n",
    "                \"relation_outliers\":[\"mean\", \"min\", \"max\"],\n",
    "                #\"topic_cluster_sizes\":\"modus\",\n",
    "                \"c_v_score\": [\"mean\", \"min\", \"max\"],\n",
    "                \"c_npmi_score\": [\"mean\", \"min\", \"max\"],\n",
    "                \"average_topic_cluster\": [\"mean\", \"min\", \"max\"],\n",
    "                \"keyword_uniqueness\": [\"mean\", \"min\", \"max\"]\n",
    "            })\n",
    "\n",
    "            print(f\"Es folgt eine aggregierte Übersicht der Ergebnisse nach den benutzten Modellen:\\n\\n{df_grouped}\")\n",
    "            print(80*\"=\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Ausgabe der Ergebnisse: {e}.\")\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    print(\"Die Ausgabedatei der Grid-Search für die Publikationsdaten wird hier nicht eingelesen und ausgewertet.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce964342",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1770115506634,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "ce964342",
    "outputId": "7b90e5a8-8b8b-4b76-9b55-c97f2fde24bb"
   },
   "outputs": [],
   "source": [
    "# Auswertung durchführen mit einer Filterung nach den oben benannten Kriterien in zwei Schritten\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"\\nEs wird die Auswertung der Grid-Search-Ergebnisse mit Filterkriterien durchgeführt.\\n\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        df_grid_search_tpf_filtered_strong = df_grid_search_tpf[(df_grid_search_tpf[\"count_topics\"] > 10) &     # Die Anzahl der Themencluster sollte über 13 liegen\n",
    "                                                (df_grid_search_tpf[\"keyword_uniqueness\"] > 0.80) &    # Die Keywords sollten einen hohen Grad an Einzigartigkeit aufweisen\n",
    "                                                (df_grid_search_tpf[\"relation_outliers\"] < 0.05) &     # Die Relation der Outlier sollte unter 10 % liegen\n",
    "                                                (df_grid_search_tpf[\"c_v_score\"] > 0.38)               # Der c_v-Score sollte im oberen Bereich liegen, hier über 0.5\n",
    "                                                ]\n",
    "\n",
    "        a1 = len(df_grid_search_tpf_filtered_strong[[\"model\", \"count_topics\", \"relation_outliers\", \"c_v_score\", \"keyword_uniqueness\", \"average_topic_cluster\"]])\n",
    "        print(f\"Anzahl der verbleibenden Modelle nach Anwendung der Filterkriterien: {a1}.\\n\")\n",
    "        print(df_grid_search_tpf_filtered_strong[\"model\"].value_counts())\n",
    "\n",
    "        # Zum Gegentesten: Leichte Lockerung der Filterkriterien, um zu sehen, wie sich das auf die Modelle auswirkt\n",
    "        df_grid_search_tpf_filtered_weak = df_grid_search_tpf[\n",
    "                                                (df_grid_search_tpf[\"count_topics\"] > 10) &             # Reduziert auf 10 Themen\n",
    "                                                (df_grid_search_tpf[\"keyword_uniqueness\"] > 0.50) &     # Reduziert auf 0.75\n",
    "                                                (df_grid_search_tpf[\"relation_outliers\"] < 0.2) &       # Reduziert auf 20 % Outlier\n",
    "                                                (df_grid_search_tpf[\"c_v_score\"] > 0.30)                # Ein hoher c_v-Score ist relevant!\n",
    "                                            ]\n",
    "\n",
    "        print(f\"\\nModelle mit gelockerten Kriterien: insgesamt {len(df_grid_search_tpf_filtered_weak)} Modelle übrig.\\n\")\n",
    "        print(df_grid_search_tpf_filtered_weak[\"model\"].value_counts())\n",
    "\n",
    "        # # Ranking der verbleibenden Modelle basierend auf dem c_v_score\n",
    "        print(\"\\nWenn bei einer Lockerung der Filterkriterien viele Modelle übrig bleiben, wird nach dem c_v_score absteigend sortiert,\"\n",
    "            \" um zu erkennen, welche Modelle die Top 5 sind:\\n\")\n",
    "        df_grid_search_tpf_filtered_weak_sorted = df_grid_search_tpf_filtered_weak.sort_values(by=[\"c_v_score\"], ascending=False)\n",
    "        print(df_grid_search_tpf_filtered_weak_sorted.head(5))\n",
    "\n",
    "    except Exception as e:\n",
    "            print(f\"Fehler bei der Filterung der Grid-Search-Ergebnisse: {e}.\")\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    print(\"Die Auswertung der Grid-Search-Ergebnisse mit Filterkriterien wird hier nicht durchgeführt.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bcd2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1770115506761,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "632bcd2c",
    "outputId": "d0305a1a-c9d1-492b-a086-0468225e9f31"
   },
   "outputs": [],
   "source": [
    "# Die Top-Modelle sind deutlich erkennbar\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"\\nDas beste Modell wird jetzt für die finale Analyse gespeichert.\\n\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        top_models_tpf = df_grid_search_tpf_filtered_weak_sorted.iloc[[0]]    # Erstes Modell\n",
    "        top_models_tpf.to_excel(rf\"{grid_search_dir}/top_models_overview_tpf_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"top_models_tpf\")\n",
    "        top_models_tpf.to_csv(rf\"{grid_search_dir}/top_models_overview_tpf_{datum}.csv\",\n",
    "                              encoding=\"utf-8\")\n",
    "\n",
    "        print(\"\\nTop-Modell(e) bei den Drittmitteln:\")\n",
    "        print(top_models_tpf)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Speichern der Top-Modelle nach Excel: {e}.\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Das beste Modell für die finale Analyse wird hier nicht gespeichert.\\n\")\n",
    "\n",
    "print(\"\\n=========== Stop ===========\")\n",
    "print(\"An dieser Stelle muss entweder die Evaluationspipeline gestartet werden oder \"\n",
    "\"das beste Modell wird neu gewählt (immer daran denken, dass es am Anfang des Notebooks\"\n",
    "\" in die Dataclass geladen werden muss!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506578d7",
   "metadata": {
    "id": "506578d7"
   },
   "source": [
    "### Entscheidung über das beste Modell\n",
    "\n",
    "An dieser Stelle muss entschieden werden, ob das beste Modell, wie es hier gefiltert wurde, in die Modellklasse geladen werden soll. Dieser Schritt ist deswegen nicht automatisiert.\n",
    "\n",
    "Dafür muss man in Zelle 3 im top_model_dict das entsprechende Modell eingeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fsY4I8BvBwx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1770115506938,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "6fsY4I8BvBwx",
    "outputId": "9dfb69c3-2977-46ea-cfb0-5fc90db46935"
   },
   "outputs": [],
   "source": [
    "# Check der Werteauslese der besten Modelle\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Hyperparameter der/des Top-Modelle/Top-Modells werden jetzt ausgegeben.\\n\")\n",
    "\n",
    "    #Finden der zuletzt gespeicherten Datei mit den Top-Modellen\n",
    "    try:\n",
    "        top_model_files = [x for x in grid_search_dir.glob(\"*\") if x.name.startswith(\"top_models_overview_tpf\")]\n",
    "        # print(top_model_files)\n",
    "        latest_top_model_file = max(top_model_files, key=lambda x: x.stat().st_mtime, default=None)\n",
    "        # print(latest_top_model_file)\n",
    "\n",
    "        # csv einlesen\n",
    "        top_models = pd.read_csv(latest_top_model_file, encoding=\"utf-8\")\n",
    "\n",
    "        print(\"\\nTop-Modell bei den Drittmitteln:\")\n",
    "        print(top_models.columns)\n",
    "        print(top_models)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim finden der der letzten Top-Modelle in Excel: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for x in top_models[\"model\"].values:\n",
    "            aa=int(top_models[top_models[\"model\"] == x][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "            bb=int(top_models[top_models[\"model\"] == x][\"hdbscan_min_samples_size\"].values[0]),\n",
    "            cc=int(top_models[top_models[\"model\"] == x][\"umap_n_neighbors\"].values[0]),\n",
    "            dd=int(top_models[top_models[\"model\"] == x][\"vectorizer_mind_df\"].values[0]),\n",
    "            ee=float(top_models[top_models[\"model\"] == x][\"vectorizer_max_df\"].values[0])\n",
    "            print(f\"\\n{x}: HDBSCAN min_cluster_size = {aa},\"\n",
    "            f\" HDBSCAN min_sample_size = {bb}, UMAP n_neighbors = {cc},\"\n",
    "            f\" Vectorizer min_df = {dd}, Vectorizer max_df = {ee}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Ausgabe der Hyperparameter der Top-Modelle: {e}.\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Da die grid-search-pipeline aktiviert ist, wird hier aktuell nicht ausgewertet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2UVQcc4MvmXf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "4207784a6fe34faf8bfc4caacb4ac2e9",
      "85a5d9a9f7e345d0942a20bcd7953787",
      "f576d4ecc6f94c79919104b3ca75bc0d",
      "42679d939f164850a3fc1b29d47429ae",
      "1163341e8adb448f8ade3c2320c139ca",
      "2e36c6225de042bc8cd960c2d7fe5740",
      "84367b108e9a4c8bbad1cb7f177bc4a3",
      "847c46638a9e4e079f5cbc813762eb45",
      "8a4cd0b2375448899c5d3946ce59e7e6",
      "ecdabbd9458f4d3fa025af51a5db7b4d",
      "839b47db3303465ca9e2078871d0bb17"
     ]
    },
    "executionInfo": {
     "elapsed": 4274,
     "status": "ok",
     "timestamp": 1770115511261,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "2UVQcc4MvmXf",
    "outputId": "c31a55b4-786f-487a-aca2-b475dc11d8ba"
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Prüfung der Top-Modell-Dataclass mit anschließendem Aufruf der Embeddings\n",
    "#######################################################################\n",
    "\n",
    "if using_top_models is True:\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"Die Top-Modell-Dataclass hält aktuell folgende Modelle:\\n\")\n",
    "        print(y.name, \"\\n\")\n",
    "\n",
    "# Suchen und Laden der Embeddings -- falls vorhanden, ansonsten werden diese noch einmal\n",
    "# erstellt\n",
    "\n",
    "##########################################\n",
    "# Funktion zum Check auf lokale Embeddings\n",
    "##########################################\n",
    "\n",
    "def check_local_embeddings_list(model_dict: dict) -> list:\n",
    "    \"\"\"Diese Funktion checkt, ob für alle Modelle im übergebenen Dict Embeddings\n",
    "    lokal vorhanden sind.\n",
    "\n",
    "    Args:\n",
    "    - model_dict = Dict mit den Modellen\n",
    "\n",
    "    Returns:\n",
    "    - list: Gibt eine Liste der Modelle zurück, für die keine Embeddings gefunden werden\n",
    "    konnten.\n",
    "    \"\"\"\n",
    "\n",
    "    not_exist = []\n",
    "\n",
    "    for x,y in model_dict.items():\n",
    "        if y.embeddings is None:\n",
    "            print(f\"Für das Modell {y.name} sind keine lokalen Embeddings vorhanden.\")\n",
    "            not_exist.append(y.name)\n",
    "        else:\n",
    "            print(f\"Für das Modell {y.name} sind lokale Embeddings vorhanden.\")\n",
    "\n",
    "    return not_exist\n",
    "\n",
    "# Funktionsaufruf\n",
    "if using_top_models is True:\n",
    "    list_no_embedds = check_local_embeddings_list(top_model_dict)\n",
    "\n",
    "    if not list_no_embedds:\n",
    "        print(\"Alle Top-Modelle aus der Data Class haben lokale Embeddings geladen.\")\n",
    "    else:\n",
    "        print(\"\\nFolgende Modelle haben keine geladenen Embeddings: {}.\".format(str(list_no_embedds)))\n",
    "        print(\"\\nDiese Embeddings werden noch einmal erstellt!\")\n",
    "\n",
    "        # Funktinausfruf zum Erstellen und Speichern der Embeddings oder zum Laden, falls Datei vorhanden\n",
    "        create_or_load_embeddings(\"drittmittel\", tpf_cleaned_docs, top_model_dict, True) # Wert sollte immer auf True stehen, falls keine Embeddings gefunden werden können, werden sie erstellt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UPgZA-yDxWpK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "error",
     "timestamp": 1770115511413,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "UPgZA-yDxWpK",
    "outputId": "a0706739-db8d-49fd-86be-2b8ab2655a24"
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Funktionsuafurf des Topic CLusterings mit Einbindung von ChatGPT im Representation-Model\n",
    "# Quelle: https://maartengr.github.io/BERTopic/getting_started/representation/llm.html#litellm\n",
    "# (Anm.: Der Api-Key wird oben schon definiert!)\n",
    "#######################################################################\n",
    "# Folgende Schritte werden durchlaufen:\n",
    "# 1. Modelle werden trainiert und gespeichert -- mit den besten Parametern aus dem Grid-Search und Anthropic als LLM im representation model\n",
    "# 2. Grafische Auswertung der Topic Clusterings mithilfe der in Bertopic integrierten Visualisierungsfunktionen\n",
    "# 3. Detaillierte Analyse der Topic Clusterings und deren Keywords\n",
    "\n",
    "# Funktionsaufruf mit den besten Parametern und den beiden besten Modellen\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "\n",
    "    # Liste zur Speicherung der Ergebnisse der besten Modelle und Entscheidung über die Nutzung von OpenAI-Einbindung\n",
    "    ergebnisse_best_models = []\n",
    "    ai_model = \"open_ai\"   # \"open_ai\" oder None\n",
    "\n",
    "    if using_top_models is True:                # Nur, wenn die besten Modelle genutzt werden sollen\n",
    "\n",
    "        for x, y in top_model_dict.items():\n",
    "\n",
    "            if y.embeddings is not None:        # Check, ob die Embeddings geladen wurden\n",
    "\n",
    "                print(f\"\\nDas Topic Modeling wird jetzt mit dem Modell \\\"{y.name}\\\" und ChatGPT als LLM im Representation-Model durchgeführt.\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    _, y.doc_topics_assignment, y.final_topics_df, y.trained_instance = topic_clustering(\n",
    "                                                                                                realm=\"drittmittel\",\n",
    "                                                                                                sentence_transformer=y.raw_instance,\n",
    "                                                                                                docs=tpf_cleaned_docs,\n",
    "                                                                                                embeddings=y.embeddings,\n",
    "                                                                                                stop_words=comprehensive_stopwords,\n",
    "                                                                                                hdbscan_min_cluster_size=int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                                                                                                hdbscan_min_samples=int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                                                                                                umap_n_neighbors=int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                                                                                                vec_min_df=int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                                                                                                vec_max_df=float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                                                                                                save_xlsx=True,\n",
    "                                                                                                model_name=y.name,\n",
    "                                                                                                datum=datum,\n",
    "                                                                                                ai_model=ai_model,\n",
    "                                                                                                save_model=True)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Topic Modeling mit dem Modell {y.name} und ChatGPT als LLM: {e}.\")\n",
    "                    pass\n",
    "\n",
    "                if y.final_topics_df is not None:\n",
    "                    try:\n",
    "                        ergebnisse_best_models.append({\n",
    "                            \"model\": str(y.name),\n",
    "                            \"umap_n_neighbors\": int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                            \"hdbscan_min_cluster_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                            \"hdbscan_min_samples_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                            \"vectorizer_mind_df\": int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                            \"vectorizer_max_df\": float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                            \"count_topics\": (len(y.final_topics_df)-1),\n",
    "                            \"relation_outliers\": y.final_topics_df[\"Count\"].iloc[0] / y.final_topics_df[\"Count\"].sum(),\n",
    "                            \"median_topic_cluster\": y.final_topics_df[\"Count\"][1:].median(),\n",
    "                            \"average_topic_cluster\": y.final_topics_df[\"Count\"][1:].mean(),\n",
    "                            \"topic_cluster_sizes\": y.final_topics_df[\"Count\"][1:].tolist(),\n",
    "                            \"keywords_list\": y.final_topics_df[\"Representation\"][1:].tolist(),\n",
    "                            \"topic_names\": y.final_topics_df[\"Name\"][1:].tolist(),\n",
    "                            \"topic_names_AI\": y.final_topics_df[\"ChatGPT_titles\"][1:].tolist() if ai_model == \"open_ai\" else None,\n",
    "                            \"topic_summaries_AI\": y.final_topics_df[\"ChatGPT\"][1:].tolist() if ai_model == \"open_ai\" else None,\n",
    "                            # \"topic_names_KeyBERT\": y.final_topics_df[\"Main\"][1:].tolist(),\n",
    "                            \"c_v_score\": gensim_coherence(y.trained_instance, tpf_cleaned_docs),\n",
    "                            \"c_npmi_score\": gensim_coherence_npmi(y.trained_instance, tpf_cleaned_docs)\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Fehler bei Modell {str(y.name)} während des Speicherns der Ergebnisse: {e}.\")\n",
    "                        pass\n",
    "                else:\n",
    "                    print(\"Die Topics sind leer oder fehlerhaft. Die Funktion geht zum nächsten Durchlauf.\")\n",
    "\n",
    "                    ergebnisse_best_models.append({\n",
    "                            \"model\": str(y.name),\n",
    "                            \"umap_n_neighbors\": int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                            \"hdbscan_min_cluster_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                            \"hdbscan_min_samples_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                            \"vectorizer_mind_df\": int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                            \"vectorizer_max_df\": float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                            \"count_topics\": 0,\n",
    "                            \"relation_outliers\": 0,\n",
    "                            \"median_topic_cluster\": 0,\n",
    "                            \"average_topic_cluster\": 0,\n",
    "                            \"topic_cluster_sizes\": 0,\n",
    "                            \"keywords_list\": 0,\n",
    "                            \"topic_names\": 0,\n",
    "                            \"topic_names_AI\": 0,\n",
    "                            \"topic_summaries_AI\": 0,\n",
    "                            # \"topic_names_KeyBERT\": 0,\n",
    "                            \"c_v_score\": 0,\n",
    "                            \"c_npmi_score\": 0\n",
    "                        })\n",
    "\n",
    "                print(80*\"=\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Die Embeddings für das Modell {y.name} wurden nicht geladen.\")\n",
    "                pass\n",
    "\n",
    "        # Ergebnisse der besten Modelle speichern\n",
    "        df_ergebnisse_best_models = pd.DataFrame(ergebnisse_best_models)\n",
    "        df_ergebnisse_best_models.to_excel(rf\"{grid_search_dir}/best_models_results_tpf_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"best_model_results\")\n",
    "        try:\n",
    "            os.startfile(rf\"{grid_search_dir}/best_models_results_tpf_{datum}.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Öffnen der Exceldatei! Evtl. OS-Modul vorhanden.\")\n",
    "    else:\n",
    "        print(\"Die besten Modelle wurden nicht geladen! BItte erste Zelle prüfen.\")\n",
    "\n",
    "    # Checks\n",
    "    print(f\"Länge der Docs: {len(tpf_cleaned_docs)}.\")\n",
    "    for x,y in top_model_dict.items():\n",
    "        try:\n",
    "            print(f\"Länge der Topics: {len(y.doc_topics_assignment)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler in der Auswertung der Länge: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2JgHzDiWxoS-",
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "aborted",
     "timestamp": 1770115511911,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "2JgHzDiWxoS-"
   },
   "outputs": [],
   "source": [
    "# Check auf korrekte befüllte Modellklassen\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nEs wird ein Check der befüllten Modellklassen der Top-Modelle durchgeführt.\\n\")\n",
    "\n",
    "    try:\n",
    "        for x, y in top_model_dict.items():\n",
    "            print(f\"\\nModell: {y.name}\")\n",
    "            print(f\"Document-Topic-Zuweisungen: {type(y.doc_topics_assignment)}\")\n",
    "            print(f\"Länge der Document-Topic-Zuweisung: {len(y.doc_topics_assignment)}\")\n",
    "            print(f\"Finales Topic-Df: {type(y.final_topics_df)}\")\n",
    "            print(f\"Länge des finalen Topic-Df: {len(y.final_topics_df)-1}\") # Outlier müssen herausgenommen werden!\n",
    "            print(f\"Trainiertes Modell: {type(y.trained_instance)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Check der Modellklassen: {e}.\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f9e5d",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "aborted",
     "timestamp": 1770115512037,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "e94f9e5d"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Funktion definieren für insg. sieben Visualisierungen\n",
    "###########################################################\n",
    "\n",
    "def visuals_per_topic_model(\n",
    "    realm: str,\n",
    "    topic_model: Annotated[object, \"Hier muss das trainierte topic.model übergeben werden\"],\n",
    "    docs: list[str],\n",
    "    top_n_topics: int = 10,\n",
    "    n_words: int = 10,\n",
    "    model_name: str | None = None,\n",
    "    embeddings: np.ndarray | None = None,\n",
    "    sample_documents: list | None = None,\n",
    "    visualizations: Annotated[list[str], \"Eine Auswahl aus heatmap, topics, barchart, term_rank, hierarchy, documents, hierarchical_documents]\"] = None,\n",
    "    show_visuals: bool = False\n",
    ") -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Sammelfunktion, um die graphischen Auswertungen zu den Topic-Clustern zu erstellen und lokal zu speichern!\n",
    "\n",
    "    Args:\n",
    "    - ...\n",
    "\n",
    "    Returns:\n",
    "    - Dict der erstellen Plots\n",
    "    \"\"\"\n",
    "\n",
    "    # Ordner Set Up mit Pathlib\n",
    "    current_dir = Path.cwd()\n",
    "    target_folder = current_dir.parent / \"01_data\" / \"03_topic_modeling\"\n",
    "    topic_visuals_folder = target_folder / \"03_topic_visuals\"\n",
    "\n",
    "    # Zielordner checken (relativ zum Notebook)\n",
    "    try:\n",
    "        if Path(topic_visuals_folder).exists():\n",
    "            print(f\"Ordner \\\"{str(topic_visuals_folder)}\\\" vorhanden.\")\n",
    "        else:\n",
    "            print(f\"Ordner \\\"{str(topic_visuals_folder)}\\\" nicht vorhanden. Der Ordner wird im folgenden Schritt erstellt werden.\")\n",
    "            topic_visuals_folder.mkdir(parents=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Aufgrund eines Fehlers konnte nicht weiter verfahren werden: {e}.\")\n",
    "    print(80*\"=\")\n",
    "\n",
    "    # Dict initialisieren, um die Visualisierungen zu speichern!\n",
    "    figures = {}\n",
    "\n",
    "    if visualizations is None:\n",
    "        visualizations = [\"heatmap\", \"topics\", \"barchart\", \"term_rank\",\n",
    "                         \"hierarchy\", \"documents\", \"hierarchical_documents\"]\n",
    "\n",
    "    ###########################################################################\n",
    "    # 1. Topic Heatmap\n",
    "    ###########################################################################\n",
    "    if \"heatmap\" in visualizations:\n",
    "        try:\n",
    "            print(\"1. Topic Heatmap erstellen.\")\n",
    "\n",
    "            # Plot erstellen!\n",
    "            fig = topic_model.visualize_heatmap()\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"heatmap\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/heatmap_{realm}_{model_name}_{datum}\"\n",
    "            fig.write_html(rf\"{path}.html\")\n",
    "            try:\n",
    "                fig.write_image(rf\"{path}.png\")\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido Version ist vorhanden!): {e}\")\n",
    "            # Plot ausgeben lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 2. 2D Topic Map\n",
    "    ###########################################################################\n",
    "    if \"topics\" in visualizations:\n",
    "        try:\n",
    "            print(\"2. Topic Map erstellen.\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_topics(width=1200, height=800)\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"topics\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/topic-map_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 3. Topic Words Bar Chart\n",
    "    ###########################################################################\n",
    "    if \"barchart\" in visualizations:\n",
    "        try:\n",
    "            print(\"3. Topic Barchart erstellen.\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_barchart(\n",
    "                top_n_topics=top_n_topics,\n",
    "                n_words=n_words,\n",
    "                height=500\n",
    "            )\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"barchart\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/bar-chart-words_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 4. Term Rank Plot\n",
    "    ###########################################################################\n",
    "    if \"term_rank\" in visualizations:\n",
    "        try:\n",
    "            print(\"4. Term Ranking erstellen\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_term_rank(log_scale=True)\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"term_rank\"] = fig\n",
    "\n",
    "            # Plot speichern und anzeigen lassen\n",
    "            path = rf\"{topic_visuals_folder}/term-rank_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 5. Hierarchical Topic Structure\n",
    "    ###########################################################################\n",
    "    if \"hierarchy\" in visualizations:\n",
    "        try:\n",
    "            print(\"5. Topic Hierarchy erstellen.\")\n",
    "\n",
    "            # Hierarchie erzeugen\n",
    "            hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "            # Plot erstellen lassen\n",
    "            fig = topic_model.visualize_hierarchy(\n",
    "                hierarchical_topics=hierarchical_topics,\n",
    "                width=1200,\n",
    "                height=800\n",
    "            )\n",
    "\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"hierarchy\"] = fig\n",
    "\n",
    "            path = rf\"{topic_visuals_folder}/hierarchy_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            # Speichern:\n",
    "            tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "            tree_path = rf\"{topic_visuals_folder}/topic-tree_{realm}_{model_name}_{datum}.html\"\n",
    "            with open(tree_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(tree)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "            print(f\"Gespeichert: \\\"{tree_path}\\\".\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler: {e}\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 6. Document Distribution\n",
    "    ###########################################################################\n",
    "    if \"documents\" in visualizations:\n",
    "        if embeddings is not None:\n",
    "            try:\n",
    "                print(\"6. Dokumenten-Karte erstellen.\")\n",
    "\n",
    "                # Plot erstellen\n",
    "                fig = topic_model.visualize_documents(\n",
    "                    docs,\n",
    "                    embeddings=embeddings,\n",
    "                    sample=sample_documents,\n",
    "                    width=1500,\n",
    "                    height=1000\n",
    "                )\n",
    "\n",
    "                # Plot dem Dict zuweisen\n",
    "                figures[\"documents\"] = fig\n",
    "\n",
    "                path = rf\"{topic_visuals_folder}/doc-map-2D_{realm}_{model_name}_{datum}.html\"\n",
    "                fig.write_html(path)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "                # Plot anzeigen lassen\n",
    "                if show_visuals is True:\n",
    "                    fig.show()\n",
    "\n",
    "                print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler: {e}\")\n",
    "        else:\n",
    "            print(\"6. Da keine Embeddings übergeben wurden, konnte nicht geplottet werden.\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 7. Hierarchical Document Visualization\n",
    "    ###########################################################################\n",
    "    if \"hierarchical_documents\" in visualizations:\n",
    "        if embeddings is not None:\n",
    "            try:\n",
    "                print(\"7. Dokumenten-Karte in 2D nach Hierarchie erstellen.\")\n",
    "\n",
    "                # Check, ob die Hierarchie schon erstellt wurde\n",
    "                if \"hierarchy\" not in figures:\n",
    "                    hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "                # Plot erstellen\n",
    "                fig = topic_model.visualize_hierarchical_documents(\n",
    "                    docs,\n",
    "                    hierarchical_topics=hierarchical_topics,\n",
    "                    embeddings=embeddings,\n",
    "                    sample=sample_documents,\n",
    "                    width=1500,\n",
    "                    height=1000\n",
    "                )\n",
    "\n",
    "                # Plot dem Dict zuweisen\n",
    "                figures[\"hierarchical_documents\"] = fig\n",
    "\n",
    "                # Plotten und anzeigen lassen\n",
    "                path = rf\"{topic_visuals_folder}/hier-doc-map-2D_{realm}_{model_name}_{datum}.html\"\n",
    "                fig.write_html(path)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido >=1.0.0 ist aber vorhanden!): {e}\")\n",
    "\n",
    "                # Plot anzeigen lassen\n",
    "                if show_visuals is True:\n",
    "                    fig.show()\n",
    "\n",
    "                # Speichern\n",
    "                print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler: \\\"{e}\\\".\")\n",
    "\n",
    "        else:\n",
    "            print(\"7. Da keine Embeddings übergeben wurden, konnte nicht geplottet werden.\")\n",
    "\n",
    "    print(f\"\\nAuswertung: Es wurden insgesamt {len(figures)} Plots erstellen und in folgendem Ordner gespeichert: {topic_visuals_folder}.\\n\")\n",
    "\n",
    "    return figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcb94f",
   "metadata": {
    "executionInfo": {
     "elapsed": 132796,
     "status": "aborted",
     "timestamp": 1770115512108,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "55bcb94f"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Auswertung der Ergebnisse in Plots und Graphiken\n",
    "###########################################################################\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Visualisierungen für die Top-Modelle werden jetzt erstellt und gespeichert.\\n\")\n",
    "\n",
    "    figures_dict = {}\n",
    "\n",
    "    for x,y in top_model_dict.items():\n",
    "\n",
    "        figures_pubs = visuals_per_topic_model(\n",
    "                                                realm=\"drittmittel\",\n",
    "                                                topic_model=y.trained_instance,\n",
    "                                                docs=tpf_cleaned_docs,\n",
    "                                                model_name=y.name,\n",
    "                                                embeddings=y.embeddings,\n",
    "                                                show_visuals=True\n",
    "                                            )\n",
    "\n",
    "        figures_dict[y.name] = figures_pubs\n",
    "\n",
    "else:\n",
    "    print(\"Da die grid-search-pipeline aktiv ist, wird hier nicht ausgewertet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1118b5",
   "metadata": {
    "id": "8e1118b5"
   },
   "source": [
    "## Dynamisches Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4365a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 132844,
     "status": "aborted",
     "timestamp": 1770115512161,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "5b4365a8"
   },
   "outputs": [],
   "source": [
    "print(df_tpf_processed_filtered[\"start_date\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a985f37",
   "metadata": {
    "executionInfo": {
     "elapsed": 132917,
     "status": "aborted",
     "timestamp": 1770115512239,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "2a985f37"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Dynamisches Topic Modeling nach Jahren\n",
    "# Quelle: https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#bins\n",
    "###########################################################\n",
    "\n",
    "# Datenvorvereitung mit den Jahresdaten mit dem ursprünglichen Dataframe\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Jahresdaten für das dynamische Topic Modeling werden jetzt vorbereitet.\\n\")\n",
    "\n",
    "    date_list = df_tpf_processed_filtered[\"start_date\"].dt.year.tolist()\n",
    "\n",
    "    df_aggre = df_tpf_processed_filtered.groupby(\"start_date\")[\"title_de\"].count()\n",
    "    print(df_aggre)\n",
    "\n",
    "    # Check der Längen\n",
    "    print(f\"Dokumente zu Datumsangaben passend = {len(date_list) == len(tpf_cleaned_docs)}.\")\n",
    "\n",
    "    print(f\"Länge der Jahresangaben = {len(date_list)}.\")\n",
    "    print(f\"Jahreszeitraum: {min(date_list)} - {max(date_list)}\")\n",
    "    print(f\"Verteilung der Jahresdaten:\\n{sorted(set(date_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0aac2",
   "metadata": {
    "executionInfo": {
     "elapsed": 133003,
     "status": "aborted",
     "timestamp": 1770115512330,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "12c0aac2"
   },
   "outputs": [],
   "source": [
    "# Aufruf der BERTopic-Funktion für dynamisches Topic Modeling mit den besten Modellen\n",
    "# (Anm.: Die Berechnung dauert bis zu 25 Minuten für zwei Graphen!)\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDas dynamische Topic Modeling für die Top-Modelle wird jetzt durchgeführt und die Graphen werden ausgegeben.\\n\")\n",
    "\n",
    "    for x, y in top_model_dict.items():\n",
    "        topics_over_time = y.trained_instance.topics_over_time(\n",
    "                                                        docs=tpf_cleaned_docs,\n",
    "                                                        timestamps=date_list,\n",
    "                                                        #datetime_format=\"%Y\",\n",
    "                                                        nr_bins=len(set(date_list))\n",
    "                                                        )\n",
    "\n",
    "        fig = y.trained_instance.visualize_topics_over_time(topics_over_time)\n",
    "        fig.write_html(rf\"{topic_visuals_dir}/dynamic_topic_modeling_{y.name}_{datum}.html\")\n",
    "        try:\n",
    "            fig.write_image(rf\"{topic_visuals_dir}/dynamic_topic_modeling_{y.name}_{datum}.png\")\n",
    "            fig.show()\n",
    "        except Exception as e:\n",
    "            print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9899f",
   "metadata": {
    "id": "4af9899f"
   },
   "source": [
    "## Rückschreibung der Ergebnisse an die PIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786367c",
   "metadata": {
    "executionInfo": {
     "elapsed": 133083,
     "status": "aborted",
     "timestamp": 1770115512414,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "9786367c"
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Drittmittel\n",
    "##########################################################################################\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie erstellten Topics der Top-Modelle werden jetzt den Drittmitteln zugeordnet.\\n\")\n",
    "\n",
    "    # 2.1 Themencluster für Drittmittel zuordnen in den ursprünglichen Dataframe\n",
    "    print(df_tpf_processed_filtered.columns)\n",
    "    print(f\"Länge des Dataframes: {len(df_tpf_processed_filtered)}.\")\n",
    "    print(f\"Länge der Dokumente: {len(tpf_cleaned_docs)}.\")\n",
    "\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"\\nDokument-Topic-Zuweisungen für Modell \\\"{y.name}\\\" werden dem Dataframe hinzugefügt.\")\n",
    "        df_tpf_processed_filtered[f\"topic_assignment_{y.name}\"] = y.doc_topics_assignment\n",
    "\n",
    "    # 2.2 Themen und Keywords zuordnen in den ursprünglichen Dataframe\n",
    "    for x,y in top_model_dict.items():\n",
    "\n",
    "        y.final_topics_df = y.trained_instance.get_topic_info()\n",
    "\n",
    "        print(f\"\\nThemen und Keywords für Modell \\\"{y.name}\\\" werden dem Dataframe hinzugefügt.\")\n",
    "        topic_names = y.final_topics_df.set_index(\"Topic\")[\"Name\"].to_dict()\n",
    "        topic_keywords = y.final_topics_df.set_index(\"Topic\")[\"Representation\"].to_dict()\n",
    "\n",
    "        df_tpf_processed_filtered[f\"topic_name_{y.name}\"] = df_tpf_processed_filtered[f\"topic_assignment_{y.name}\"].map(topic_names)\n",
    "        df_tpf_processed_filtered[f\"topic_keywords_{y.name}\"] = df_tpf_processed_filtered[f\"topic_assignment_{y.name}\"].map(topic_keywords)\n",
    "\n",
    "    print(f\"\\nNeue Spalten Drittmittel: {df_tpf_processed_filtered.columns}.\")\n",
    "    df_tpf_processed_filtered.head()\n",
    "\n",
    "else:\n",
    "    print(\"Die erstellten Topics der Top-Modelle werden hier nicht den Drittmitteln zugeordnet. Dafür muss die \"\n",
    "          \"evaluation_pipeline Variable auf True gesetzt werden.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d125a0f",
   "metadata": {
    "executionInfo": {
     "elapsed": 133162,
     "status": "aborted",
     "timestamp": 1770115512498,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "3d125a0f"
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Drittmittel\n",
    "##########################################################################################\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie aggregierten Metriken für PIs aus Drittmitteln werden jetzt erstellt.\\n\")\n",
    "\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"\\nAggregierte Metriken für PIs aus Drittmitteln werden für Modell \\\"{y.name}\\\" erstellt.\")\n",
    "\n",
    "        # Anonymisierung der PI-Namen im Dataframe\n",
    "        pi_df = pd.read_csv(rf\"{base_dir}/01_data/01_csv_data/00_pi_basics/FINALLY_ALL_pi_data.csv\", encoding=\"utf-8\")\n",
    "        pi_hash_dict = pi_df.set_index(\"nachname\")[\"pi_name_hashed\"].to_dict()\n",
    "\n",
    "        df_tpf_processed_filtered[\"nachname\"] = df_tpf_processed_filtered[\"nachname\"].map(pi_hash_dict)\n",
    "\n",
    "        pi_metrics_tpf = df_tpf_processed_filtered.groupby(\"nachname\").agg(\n",
    "            topic_count=(f\"topic_assignment_{y.name}\", \"nunique\"),\n",
    "            total_tpfs=(f\"topic_assignment_{y.name}\", \"size\")\n",
    "        ).reset_index()\n",
    "\n",
    "        # Top 3 topics\n",
    "        pi_metrics_tpf[\"top3_topics_nr\"] = df_tpf_processed_filtered.groupby(\"nachname\")[f\"topic_assignment_{y.name}\"].apply(\n",
    "            lambda x: x.value_counts().head(3).index.tolist()).values\n",
    "        pi_metrics_tpf[\"top3_topics_title\"] = df_tpf_processed_filtered.groupby(\"nachname\")[f\"topic_name_{y.name}\"].apply(\n",
    "            lambda x: [x for x in x.value_counts().head(3).index.tolist()]).values\n",
    "\n",
    "        # Speichern als csv\n",
    "        pi_metrics_tpf.to_csv(rf\"{topic_results_dir}/pi_tpf_metrics_{y.name}_{datum}.csv\", index=False, encoding=\"utf-8\")\n",
    "        pi_metrics_tpf.to_excel(rf\"{topic_results_dir}/pi_tpf_metrics_{y.name}_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"pi_metrics\")\n",
    "\n",
    "    # Check\n",
    "    print(pi_metrics_tpf)\n",
    "\n",
    "else:\n",
    "    print(\"Die aggregierten Metriken für PIs aus Drittmitteln werden hier nicht erstellt. Dafür muss die \"\n",
    "            \"evaluation_pipeline Variable auf True gesetzt werden.\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0250a5ec04e54d1e8b5a68ac68d4f790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64ee00cae2e4404791ee0ef5cd79ec31",
       "IPY_MODEL_60f94fd1fb254ef7bd7654f4eee5fdab",
       "IPY_MODEL_8efbaba7e0f94fd594254bbcf6c088c0"
      ],
      "layout": "IPY_MODEL_4e3f9444d1f4439cbb7b9b894a96c686"
     }
    },
    "0338d0c0695246828bf4ee93602890b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03c42540727047f2a0a1a5fd34bb358a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367c615de6e14621a7ab694a650f49e8",
      "placeholder": "​",
      "style": "IPY_MODEL_b99c7b37393c4386a2a66d1bad9ee709",
      "value": " 53.0/53.0 [00:00&lt;00:00, 5.55kB/s]"
     }
    },
    "0432f94f452349a2859a7b1cfcdcf177": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db05613fe5224fec853629fb30c0d2f8",
      "placeholder": "​",
      "style": "IPY_MODEL_f00a493f053e4506bb6c614dabbf75d6",
      "value": " 2.36M/2.36M [00:00&lt;00:00, 4.31MB/s]"
     }
    },
    "045980e5cb9547f5871e1ec1f0f30f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ad5ce92b0314cb79519e7232a6beea3",
      "placeholder": "​",
      "style": "IPY_MODEL_67f8310afe20421aa206872bf2ba0a0c",
      "value": " 1.88G/1.88G [00:04&lt;00:00, 637MB/s]"
     }
    },
    "05b3f6b2ac1b40569becb81aebbcbc62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "069d134611b84fa18f31c06262462ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07c4d556b4114c10a65726f706d92b99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c0ec007ddff4b0c85751df8b5684048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cdc9e59d19149d592d9de079bafe54a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1163341e8adb448f8ade3c2320c139ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "154fe608b8bc46dabe08e7cb13b9b0ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52e6941390e546feadc0d81b1e419bba",
      "max": 122,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ace86caa9df4e3eb3409c8fb6dd6377",
      "value": 122
     }
    },
    "17f0aaceef114fad8d265f53959985e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1843b22a228e468ebaa0193788c0d89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1926dc4eaac34de7a3428b5bd975b222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a15c1bdf69b4cc4a335b69cdfe1a41c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ace86caa9df4e3eb3409c8fb6dd6377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ce3b302cd4848c896f0a22adbf46423": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0338d0c0695246828bf4ee93602890b0",
      "placeholder": "​",
      "style": "IPY_MODEL_deb985de79814f58944e546b3fbaf5a5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "2b610c5053134144ac725aaa23be9238": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b8b531e0e2c44cbaabc2ef631218872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c19f380213e449b874c8c3fceef1e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdf7ca8289334785845cfb46238b9964",
      "placeholder": "​",
      "style": "IPY_MODEL_7fd676037a494d86b6520f49755cf6bf",
      "value": "config.json: 100%"
     }
    },
    "2ccf9f02ebe3414d862cee82130ce434": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d4762a6854144d1a82025b4e2e81b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2deabf501ad34d7880c796f2351661e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_badd13bf50f74daea98ec30117760bd0",
      "placeholder": "​",
      "style": "IPY_MODEL_5a310bcda62b4975a79e4e7576df95ee",
      "value": " 461/461 [00:00&lt;00:00, 55.7kB/s]"
     }
    },
    "2e36c6225de042bc8cd960c2d7fe5740": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325a847296e64ed3a7a3f319007f7db6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34098022c10e4c83a2e36d7b3d4f31f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "367c615de6e14621a7ab694a650f49e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3901cad0a4384702b8f2f1d9eb2f7266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a9e302c22874a4386f2f94ccd4b84a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3acd71a663ea4c6794aab8f6370a907c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ed0a719afcc4f619a06e0a3c4de4c4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c19f380213e449b874c8c3fceef1e32",
       "IPY_MODEL_541370bc6b0e4bb19f48a5a63b218f4a",
       "IPY_MODEL_4f669de56ee14a8d9c759c4d86a8ebad"
      ],
      "layout": "IPY_MODEL_719fef3d5d2e403292ed2c5f9d803ef1"
     }
    },
    "3ef89ab12d1f450c83cf8b9897559c37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4207784a6fe34faf8bfc4caacb4ac2e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85a5d9a9f7e345d0942a20bcd7953787",
       "IPY_MODEL_f576d4ecc6f94c79919104b3ca75bc0d",
       "IPY_MODEL_42679d939f164850a3fc1b29d47429ae"
      ],
      "layout": "IPY_MODEL_1163341e8adb448f8ade3c2320c139ca"
     }
    },
    "42679d939f164850a3fc1b29d47429ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecdabbd9458f4d3fa025af51a5db7b4d",
      "placeholder": "​",
      "style": "IPY_MODEL_839b47db3303465ca9e2078871d0bb17",
      "value": " 3/3 [00:01&lt;00:00,  1.56it/s]"
     }
    },
    "46d7adf58e604993bb6b9f263b3764ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "491f0b6b537341bd88dcb37651b9710c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ef89ab12d1f450c83cf8b9897559c37",
      "placeholder": "​",
      "style": "IPY_MODEL_e33d32d06d5746438f81b247844a0050",
      "value": "config.json: 100%"
     }
    },
    "499c0e24c8bf440daa039697e953e6ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b838bf95f1b4f7a93c66b57682bfaa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_491f0b6b537341bd88dcb37651b9710c",
       "IPY_MODEL_4ec5b294f961472197a8236bce505f22",
       "IPY_MODEL_c66befef6e334a1cab45ac3b80e4d519"
      ],
      "layout": "IPY_MODEL_87278e020087405cb66f83f253cfefd4"
     }
    },
    "4bf9b18876b64b4da4c623b11941a496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e3f9444d1f4439cbb7b9b894a96c686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ec5b294f961472197a8236bce505f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edf5adec5a9b4dc08503eafd2164fd38",
      "max": 114,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cdc9e59d19149d592d9de079bafe54a",
      "value": 114
     }
    },
    "4f230da6255a4b618eb1ee55fd7fc2e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f669de56ee14a8d9c759c4d86a8ebad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c91a43472ec458499243b2984f28a82",
      "placeholder": "​",
      "style": "IPY_MODEL_fcca2944f98549c2b5a3607c52937305",
      "value": " 804/804 [00:00&lt;00:00, 101kB/s]"
     }
    },
    "52e6941390e546feadc0d81b1e419bba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538ee7bfce224409b827307c36c98b91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "541370bc6b0e4bb19f48a5a63b218f4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f6f01aa2e634c95b810e0ff0933e5b6",
      "max": 804,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0e1e22cf25c43e2b2ad16a703c014b0",
      "value": 804
     }
    },
    "5493bd1152ea493689eb334ed4b3bdb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54c458d22e5b48d9b6076a7e8290a17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dde8d44b8324277bf5d7e54f37d4bb5",
      "placeholder": "​",
      "style": "IPY_MODEL_1926dc4eaac34de7a3428b5bd975b222",
      "value": "modules.json: 100%"
     }
    },
    "59865b29541f419382c801ff83cfd31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59c34cf0825441a7a14f0c8326661dc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f230da6255a4b618eb1ee55fd7fc2e7",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5236047b0eb4f978f323b97a1280bd5",
      "value": 112
     }
    },
    "5a310bcda62b4975a79e4e7576df95ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a3d9742e75841e4bc20d76e0d683822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b92bb94d3164fccb3be1c641915b191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cbe145e524c4777b97a60cefdca99a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_723acf2274aa4bf19ddcc0276ffff623",
       "IPY_MODEL_e04ec7394acc403bafd0ed6814f770d9",
       "IPY_MODEL_f61209bbbd7241e4b178ec8d423cd6a7"
      ],
      "layout": "IPY_MODEL_fd388ef36dcc43f68ca1cd4edf393314"
     }
    },
    "60f94fd1fb254ef7bd7654f4eee5fdab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_895f3ad0a960416482be655f52793755",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_325a847296e64ed3a7a3f319007f7db6",
      "value": 1
     }
    },
    "61b5144cceab4b00898cb7d6e6c09392": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61ccf37f3c684838b703c3eeb2a9e11c",
      "max": 199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5493bd1152ea493689eb334ed4b3bdb0",
      "value": 199
     }
    },
    "61ccf37f3c684838b703c3eeb2a9e11c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "626bdf7941f446039af4f8a87811f1e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64ee00cae2e4404791ee0ef5cd79ec31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f093dc4510c646f893df6ae5c6d9f8fd",
      "placeholder": "​",
      "style": "IPY_MODEL_1843b22a228e468ebaa0193788c0d89b",
      "value": "README.md: "
     }
    },
    "67f8310afe20421aa206872bf2ba0a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6868d38525214ba1a7d971878b349857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ad5ce92b0314cb79519e7232a6beea3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bc43cec0256494ea91ba6b78caaef3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e251c68f90e8438a99e3241a1895e4ca",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c0ec007ddff4b0c85751df8b5684048",
      "value": 53
     }
    },
    "6c8ab0ed8d0e4957a6163aab50b169e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34098022c10e4c83a2e36d7b3d4f31f7",
      "placeholder": "​",
      "style": "IPY_MODEL_5b92bb94d3164fccb3be1c641915b191",
      "value": "Loading weights: 100%"
     }
    },
    "6dde8d44b8324277bf5d7e54f37d4bb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f6f01aa2e634c95b810e0ff0933e5b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "719fef3d5d2e403292ed2c5f9d803ef1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "723acf2274aa4bf19ddcc0276ffff623": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a9e302c22874a4386f2f94ccd4b84a2",
      "placeholder": "​",
      "style": "IPY_MODEL_c5df148d36634c18a80ac36aeb140fda",
      "value": "tokenizer.json: "
     }
    },
    "72cacfb1ba8542bd821299c89efc163e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74759cf91ee5482ab71b0a98baa160ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5445aeb3b6a4c0b9d7b7e2beb5c2f9a",
      "placeholder": "​",
      "style": "IPY_MODEL_3901cad0a4384702b8f2f1d9eb2f7266",
      "value": " 199/199 [00:00&lt;00:00, 968.54it/s, Materializing param=pooler.dense.weight]"
     }
    },
    "77c42501265e4e148a3e3590990b4c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_069d134611b84fa18f31c06262462ca0",
      "placeholder": "​",
      "style": "IPY_MODEL_a5c87dad2c814e41802b6857e47be487",
      "value": "config.json: 100%"
     }
    },
    "7aacc98a0e7f45ea959599097cf1f289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7eee9fbcde0043a79b2414a8628023db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ef66a9cdbd041cd9418ea6bbc098248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e369b271a0b9416da04146de02a751d0",
      "max": 461,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7aacc98a0e7f45ea959599097cf1f289",
      "value": 461
     }
    },
    "7fd676037a494d86b6520f49755cf6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80364989a05741e386ea547a2b077b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5331f08b43e410bbd8c0ffda2f178de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd00855985084bf8b22438a34ffda085",
      "value": 1
     }
    },
    "839b47db3303465ca9e2078871d0bb17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84367b108e9a4c8bbad1cb7f177bc4a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "847c46638a9e4e079f5cbc813762eb45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85a5d9a9f7e345d0942a20bcd7953787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e36c6225de042bc8cd960c2d7fe5740",
      "placeholder": "​",
      "style": "IPY_MODEL_84367b108e9a4c8bbad1cb7f177bc4a3",
      "value": "Batches: 100%"
     }
    },
    "87278e020087405cb66f83f253cfefd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ca2a1d2142458aa67cc7b6bf1877b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54c458d22e5b48d9b6076a7e8290a17e",
       "IPY_MODEL_7ef66a9cdbd041cd9418ea6bbc098248",
       "IPY_MODEL_2deabf501ad34d7880c796f2351661e2"
      ],
      "layout": "IPY_MODEL_b09542177d384088946a2514f73b5273"
     }
    },
    "895f3ad0a960416482be655f52793755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "8a4cd0b2375448899c5d3946ce59e7e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c91a43472ec458499243b2984f28a82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8efbaba7e0f94fd594254bbcf6c088c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c779aa914545456aa91dff11eadfd429",
      "placeholder": "​",
      "style": "IPY_MODEL_5a3d9742e75841e4bc20d76e0d683822",
      "value": " 2.02k/? [00:00&lt;00:00, 237kB/s]"
     }
    },
    "8fb72d05a2144849a675c9917df6ef86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c8ab0ed8d0e4957a6163aab50b169e7",
       "IPY_MODEL_61b5144cceab4b00898cb7d6e6c09392",
       "IPY_MODEL_74759cf91ee5482ab71b0a98baa160ac"
      ],
      "layout": "IPY_MODEL_f092fc9995944ef189cb19f49ce50879"
     }
    },
    "92ca06d258164d7ba6b0f7466804e62f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2bd9e5e29e04f95bfc83cb729afd3cd",
       "IPY_MODEL_b90ff5d2fb8e4c2baae7b28f9b30a2d6",
       "IPY_MODEL_045980e5cb9547f5871e1ec1f0f30f8d"
      ],
      "layout": "IPY_MODEL_d6e50a7795da44d2b30509ab326a8f4d"
     }
    },
    "9baaf73fc2934c84b7b7c95661c217a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fa21ad3b4064f01bb08bee790c13228": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ccf9f02ebe3414d862cee82130ce434",
      "placeholder": "​",
      "style": "IPY_MODEL_72cacfb1ba8542bd821299c89efc163e",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "a0c6d52f6b144580bc92a73c1689acc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_499c0e24c8bf440daa039697e953e6ca",
      "placeholder": "​",
      "style": "IPY_MODEL_2b8b531e0e2c44cbaabc2ef631218872",
      "value": " 190/190 [00:00&lt;00:00, 22.8kB/s]"
     }
    },
    "a27813e949f14558a8d3c364dab3b354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a30d18c9e23a4a55b5d7d7014f35873d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4a36e8d477d496ea7d0d8f01c30f8c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_626bdf7941f446039af4f8a87811f1e5",
      "placeholder": "​",
      "style": "IPY_MODEL_ec7ce21b3ba647fbba22a11bd7ea16fc",
      "value": " 397/397 [00:00&lt;00:00, 47.8kB/s]"
     }
    },
    "a50c60a9ee5348f090c71b07649d6667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5a4ba7078e5485db52efac6b016ed72",
       "IPY_MODEL_b443af609c7c49c2a9895ae6353e9220",
       "IPY_MODEL_0432f94f452349a2859a7b1cfcdcf177"
      ],
      "layout": "IPY_MODEL_3acd71a663ea4c6794aab8f6370a907c"
     }
    },
    "a5236047b0eb4f978f323b97a1280bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5c87dad2c814e41802b6857e47be487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a89de9e0c29e4694b9f3d1fbc604f5b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a96d34f47b14489ca901f9d16d66d7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa77323699f8418e83d977cd54f35e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_538ee7bfce224409b827307c36c98b91",
      "placeholder": "​",
      "style": "IPY_MODEL_4bf9b18876b64b4da4c623b11941a496",
      "value": " 5.22M/? [00:00&lt;00:00, 21.7MB/s]"
     }
    },
    "ab1bf9ef7eac47068bdace45606462df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ade1d69902d4485798961b2596c079f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc2e48fbb35c414e9af669078dbafd82",
      "placeholder": "​",
      "style": "IPY_MODEL_1a15c1bdf69b4cc4a335b69cdfe1a41c",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "aff08fda42ab4c77b7f300f24fbb266c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b09542177d384088946a2514f73b5273": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b443af609c7c49c2a9895ae6353e9220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6868d38525214ba1a7d971878b349857",
      "max": 2362528,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3fadde9e80e4adea656f20b3c8d5f76",
      "value": 2362528
     }
    },
    "b4c2b67218f2411fb0413bbc1ea45103": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b52c0834ec4348d293162315d2109e70",
      "max": 397,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb89652940a1400d978fb4c8223630d0",
      "value": 397
     }
    },
    "b52c0834ec4348d293162315d2109e70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5a4ba7078e5485db52efac6b016ed72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aff08fda42ab4c77b7f300f24fbb266c",
      "placeholder": "​",
      "style": "IPY_MODEL_a96d34f47b14489ca901f9d16d66d7e9",
      "value": "2_Dense/model.safetensors: 100%"
     }
    },
    "b742487a29f9417f95d3f4b13bfb6647": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8d39a5d6fff4fbca0950ef049caba07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b90ff5d2fb8e4c2baae7b28f9b30a2d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea95716334b942ce9c7da6d1e6d40502",
      "max": 1883734344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d4762a6854144d1a82025b4e2e81b95",
      "value": 1883734344
     }
    },
    "b99c7b37393c4386a2a66d1bad9ee709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "badd13bf50f74daea98ec30117760bd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc2e48fbb35c414e9af669078dbafd82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0e1e22cf25c43e2b2ad16a703c014b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5331f08b43e410bbd8c0ffda2f178de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c5445aeb3b6a4c0b9d7b7e2beb5c2f9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5df148d36634c18a80ac36aeb140fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c66befef6e334a1cab45ac3b80e4d519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a27813e949f14558a8d3c364dab3b354",
      "placeholder": "​",
      "style": "IPY_MODEL_d0027c0566364ca2af5254d74d332ff5",
      "value": " 114/114 [00:00&lt;00:00, 15.4kB/s]"
     }
    },
    "c779aa914545456aa91dff11eadfd429": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7c7a898a8324444a1905f12861326f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ce3b302cd4848c896f0a22adbf46423",
       "IPY_MODEL_b4c2b67218f2411fb0413bbc1ea45103",
       "IPY_MODEL_a4a36e8d477d496ea7d0d8f01c30f8c7"
      ],
      "layout": "IPY_MODEL_b8d39a5d6fff4fbca0950ef049caba07"
     }
    },
    "c93218adea794435ab2852f09a4bedef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3194b9892e64cf9ac9418226ee49623",
      "placeholder": "​",
      "style": "IPY_MODEL_9baaf73fc2934c84b7b7c95661c217a3",
      "value": " 122/122 [00:00&lt;00:00, 16.5kB/s]"
     }
    },
    "ca64367fa92b413fa54faa79349d4e17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ade1d69902d4485798961b2596c079f7",
       "IPY_MODEL_6bc43cec0256494ea91ba6b78caaef3b",
       "IPY_MODEL_03c42540727047f2a0a1a5fd34bb358a"
      ],
      "layout": "IPY_MODEL_46d7adf58e604993bb6b9f263b3764ab"
     }
    },
    "cc25f73156394f1d874945a38d75684d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccb939f3c8d64a738e11bd1734a9b558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcaf4105e9414b0787a46ef626a3d943",
       "IPY_MODEL_59c34cf0825441a7a14f0c8326661dc1",
       "IPY_MODEL_eec5410a441847879a2477b78965138e"
      ],
      "layout": "IPY_MODEL_17f0aaceef114fad8d265f53959985e4"
     }
    },
    "cdf7ca8289334785845cfb46238b9964": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce0947d352f444c48677ddcd807abe41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f44d40fe895b4081b49b094f15dc8817",
       "IPY_MODEL_80364989a05741e386ea547a2b077b06",
       "IPY_MODEL_aa77323699f8418e83d977cd54f35e44"
      ],
      "layout": "IPY_MODEL_e468222ccabe420db0b086252f08af39"
     }
    },
    "ce8ca22d7fd84306b0c9f43e96fbd25e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d0027c0566364ca2af5254d74d332ff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2b3dfffc8404349b213e810415e325a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77c42501265e4e148a3e3590990b4c82",
       "IPY_MODEL_fb516bb5ed7f42448f0c3102222c712a",
       "IPY_MODEL_a0c6d52f6b144580bc92a73c1689acc1"
      ],
      "layout": "IPY_MODEL_cc25f73156394f1d874945a38d75684d"
     }
    },
    "d3194b9892e64cf9ac9418226ee49623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e50a7795da44d2b30509ab326a8f4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d99810bca8a742be8bc4070c263f8525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db05613fe5224fec853629fb30c0d2f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbde198bf627403e93c98543f5786fb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd00855985084bf8b22438a34ffda085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "deb985de79814f58944e546b3fbaf5a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e04ec7394acc403bafd0ed6814f770d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce8ca22d7fd84306b0c9f43e96fbd25e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59865b29541f419382c801ff83cfd31c",
      "value": 1
     }
    },
    "e251c68f90e8438a99e3241a1895e4ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e33d32d06d5746438f81b247844a0050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e369b271a0b9416da04146de02a751d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3fadde9e80e4adea656f20b3c8d5f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e468222ccabe420db0b086252f08af39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea95716334b942ce9c7da6d1e6d40502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb89652940a1400d978fb4c8223630d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec7ce21b3ba647fbba22a11bd7ea16fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecdabbd9458f4d3fa025af51a5db7b4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf5adec5a9b4dc08503eafd2164fd38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eec5410a441847879a2477b78965138e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbde198bf627403e93c98543f5786fb3",
      "placeholder": "​",
      "style": "IPY_MODEL_2b610c5053134144ac725aaa23be9238",
      "value": " 112/112 [00:00&lt;00:00, 15.4kB/s]"
     }
    },
    "f00a493f053e4506bb6c614dabbf75d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f092fc9995944ef189cb19f49ce50879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f093dc4510c646f893df6ae5c6d9f8fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f281923e9d9c4b3b9106387b315839e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2bd9e5e29e04f95bfc83cb729afd3cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab1bf9ef7eac47068bdace45606462df",
      "placeholder": "​",
      "style": "IPY_MODEL_b742487a29f9417f95d3f4b13bfb6647",
      "value": "model.safetensors: 100%"
     }
    },
    "f41575d0024a4ac992ac53148560e48c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa21ad3b4064f01bb08bee790c13228",
       "IPY_MODEL_154fe608b8bc46dabe08e7cb13b9b0ed",
       "IPY_MODEL_c93218adea794435ab2852f09a4bedef"
      ],
      "layout": "IPY_MODEL_07c4d556b4114c10a65726f706d92b99"
     }
    },
    "f44d40fe895b4081b49b094f15dc8817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a30d18c9e23a4a55b5d7d7014f35873d",
      "placeholder": "​",
      "style": "IPY_MODEL_05b3f6b2ac1b40569becb81aebbcbc62",
      "value": "vocab.txt: "
     }
    },
    "f4f2dfb3ced44c44905abf7cc2b1350b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f576d4ecc6f94c79919104b3ca75bc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_847c46638a9e4e079f5cbc813762eb45",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a4cd0b2375448899c5d3946ce59e7e6",
      "value": 3
     }
    },
    "f61209bbbd7241e4b178ec8d423cd6a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4f2dfb3ced44c44905abf7cc2b1350b",
      "placeholder": "​",
      "style": "IPY_MODEL_d99810bca8a742be8bc4070c263f8525",
      "value": " 9.62M/? [00:00&lt;00:00, 99.6MB/s]"
     }
    },
    "fa759f9ec867412b8cf46d2af8a20ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb516bb5ed7f42448f0c3102222c712a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f281923e9d9c4b3b9106387b315839e1",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa759f9ec867412b8cf46d2af8a20ff1",
      "value": 190
     }
    },
    "fcaf4105e9414b0787a46ef626a3d943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a89de9e0c29e4694b9f3d1fbc604f5b9",
      "placeholder": "​",
      "style": "IPY_MODEL_7eee9fbcde0043a79b2414a8628023db",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "fcca2944f98549c2b5a3607c52937305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd388ef36dcc43f68ca1cd4edf393314": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
