{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014250b1",
   "metadata": {},
   "source": [
    "Als dritte Alternative neben Scholar und Pubmed versuche ich hier, S2 zu nutzen.\n",
    "\n",
    "Ergebnis: Das funktioniert, aber die DAtenqualität in Bezug auf die Abstracts und KEywords ist nicht so umfassend wie bei Pubmed! Das ist max. als Ergänzung zu denken! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284991265\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_author_id(author_name: str, api_key: str = None) -> str:\n",
    "    \n",
    "    url = \"https://api.semanticscholar.org/graph/v1/author/search\"\n",
    "    headers = {\"x-api-key\": api_key} if api_key else {}\n",
    "    \n",
    "    response = requests.get(\n",
    "        url,\n",
    "        params={\"query\": author_name, \"limit\": 1},\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"data\", [])\n",
    "        if data:\n",
    "            return data[0][\"authorId\"]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Beispiel\n",
    "author_id = get_author_id(\"Marcus Hammann\")\n",
    "# Output: \"2108028474\" (oder ähnlich)\n",
    "\n",
    "print(author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test um die Publikationen zu bekommen von der S2-API\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_semantic_scholar_papers(author_id: str, api_key: str = None) -> pd.DataFrame:\n",
    "    \"\"\"Holt alle Papers eines Autors von Semantic Scholar über Author ID\"\"\"\n",
    "    \n",
    "    base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    headers = {\"x-api-key\": api_key} if api_key else {}\n",
    "    \n",
    "    fields = \"paperId,title,year,abstract,citationCount,authors,fieldsOfStudy\"\n",
    "    response = requests.get(\n",
    "        f\"{base_url}/author/{author_id}/papers\",\n",
    "        params={\"fields\": fields, \"limit\": 100},\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    papers = response.json().get(\"data\", [])\n",
    "    \n",
    "    processed = []\n",
    "    for paper in papers:\n",
    "        processed.append({\n",
    "            \"paper_id\": paper.get(\"paperId\"),\n",
    "            \"title\": paper.get(\"title\"),\n",
    "            \"year\": paper.get(\"year\"),\n",
    "            \"abstract\": paper.get(\"abstract\"),\n",
    "            \"citation_count\": paper.get(\"citationCount\", 0),\n",
    "            \"authors\": [a[\"name\"] for a in paper.get(\"authors\", [])],\n",
    "            \"keywords\": paper.get(\"fieldsOfStudy\", []),\n",
    "            \"source\": \"semantic_scholar\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(processed)\n",
    "\n",
    "# Einen einzelnen Autoren fetchen mit der Author ID\n",
    "papers = get_semantic_scholar_papers(\"2080244021\")\n",
    "\n",
    "papers.to_csv(r\"/project/01_data/01_csv_data/99_pubmed/publications_Heuckmann_2015-3000.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Mehrere Autoren fetchen \n",
    "# author_ids = [\"2108028474\", \"1234567890\"]\n",
    "# all_papers = pd.concat([\n",
    "#     get_semantic_scholar_papers(aid) for aid in author_ids\n",
    "# ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0533deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': None, 'h-Index': 35, 'Zitationen_Gesamt': 5651, 'Publikationen_Gesamt': 117}\n"
     ]
    }
   ],
   "source": [
    "def get_author_metrics(author_id: str, high_impact_threshold: int = 50, api_key: str = None):\n",
    "    \"\"\"\n",
    "    Holt nur die Metriken eines Autors.\n",
    "    high_impact_threshold: Ab wie vielen Zitationen gilt ein Paper als 'hochrangig'?\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    \n",
    "    # 1. Wir bestellen nur die nackten Zahlen und für die Berechnung \n",
    "    # die Zitationen pro Paper. Keine Titel, keine Abstracts!\n",
    "    fields = \"hIndex,citationCount,paperCount,papers.citationCount\"\n",
    "    \n",
    "    headers = {\"x-api-key\": api_key} if api_key else {}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{base_url}/author/{author_id}\",\n",
    "            params={\"fields\": fields},\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Fehler: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        data = response.json()\n",
    "        \n",
    "        # 2. Die direkten Metriken auslesen\n",
    "        metrics = {\n",
    "            \"Name\": data.get(\"name\"),\n",
    "            \"h-Index\": data.get(\"hIndex\"),\n",
    "            \"Zitationen_Gesamt\": data.get(\"citationCount\"),\n",
    "            \"Publikationen_Gesamt\": data.get(\"paperCount\")\n",
    "        }\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(f\"Fehler {e}\")\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "test = get_author_metrics(\"3653894\")\n",
    "\n",
    "print(test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a35249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author_id  h_index  zitationen_gesamt  publikationen_gesamt\n",
      "0      1692564       23               1705                    79\n",
      "1    145491092        0                  0                     0\n",
      "2    144945538       46               7116                   215\n",
      "3      3725749        0                  0                     0\n",
      "4     48411399       30               4474                    85\n",
      "5      4296195        0                  0                     0\n",
      "6      6401561       38               7564                   115\n",
      "7   1393698484        0                  0                     0\n",
      "8      5373662       25               2126                    53\n",
      "9      3804059       50               7364                   146\n",
      "10     5418704       71              23986                   154\n",
      "11     3358527       57              13348                   218\n",
      "12    46892632       24               2073                    77\n",
      "13     6103758       44               6956                   146\n",
      "14   144357511        0                  0                     0\n",
      "15     6214482        0                  0                     0\n",
      "16     3653894        0                  0                     0\n",
      "17     4690880        0                  0                     0\n",
      "18    40564829       22               4593                    56\n",
      "19     8369839        0                  0                     0\n",
      "20    31574936        0                  0                     0\n",
      "21     4031956       27               5346                    47\n",
      "22     5488888        0                  0                     0\n",
      "23     6220450       33               3172                   138\n",
      "24     4731016        0                  0                     0\n",
      "25     4376355       43               7168                    81\n",
      "26    34995473       23               1889                    62\n",
      "27     4958172        0                  0                     0\n",
      "28    48863863        0                  0                     0\n",
      "29    49061847        0                  0                     0\n",
      "30     6880354       33               4488                   147\n",
      "31     5750388        0                  0                     0\n",
      "32     4529999       24               2729                    41\n",
      "33     2894309        0                  0                     0\n",
      "34    46786657       11                517                    23\n",
      "35     3681289        0                  0                     0\n",
      "36  2080244021        7                133                    15\n",
      "37    69869191       15                593                    57\n",
      "38    12980976       12                327                    34\n",
      "39     5312334       21               1216                    58\n",
      "40    34496939       24               1654                    65\n",
      "41     6650716       96              32974                   582\n",
      "42     5381495       33               4091                   164\n",
      "43     5517965       17               1056                    45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Local\\Temp\\ipykernel_19008\\3552544355.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1 = pd.DataFrame.from_dict(data).fillna(0).T.reset_index().rename(columns={\"index\": \"author_id\"})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data =  {1692564: {'h_index': 23, 'zitationen_gesamt': 1705, 'publikationen_gesamt': 79}, 145491092: None, 144945538: {'h_index': 46, 'zitationen_gesamt': 7116, 'publikationen_gesamt': 215}, 3725749: None, 48411399: {'h_index': 30, 'zitationen_gesamt': 4474, 'publikationen_gesamt': 85}, 4296195: None, 6401561: {'h_index': 38, 'zitationen_gesamt': 7564, 'publikationen_gesamt': 115}, 1393698484: None, 5373662: {'h_index': 25, 'zitationen_gesamt': 2126, 'publikationen_gesamt': 53}, 3804059: {'h_index': 50, 'zitationen_gesamt': 7364, 'publikationen_gesamt': 146}, 5418704: {'h_index': 71, 'zitationen_gesamt': 23986, 'publikationen_gesamt': 154}, 3358527: {'h_index': 57, 'zitationen_gesamt': 13348, 'publikationen_gesamt': 218}, 46892632: {'h_index': 24, 'zitationen_gesamt': 2073, 'publikationen_gesamt': 77}, 6103758: {'h_index': 44, 'zitationen_gesamt': 6956, 'publikationen_gesamt': 146}, 144357511: None, 6214482: None, 3653894: None, 4690880: None, 40564829: {'h_index': 22, 'zitationen_gesamt': 4593, 'publikationen_gesamt': 56}, 8369839: None, 31574936: None, 4031956: {'h_index': 27, 'zitationen_gesamt': 5346, 'publikationen_gesamt': 47}, 5488888: None, 6220450: {'h_index': 33, 'zitationen_gesamt': 3172, 'publikationen_gesamt': 138}, 4731016: None, 4376355: {'h_index': 43, 'zitationen_gesamt': 7168, 'publikationen_gesamt': 81}, 34995473: {'h_index': 23, 'zitationen_gesamt': 1889, 'publikationen_gesamt': 62}, 4958172: None, 48863863: None, 49061847: None, 6880354: {'h_index': 33, 'zitationen_gesamt': 4488, 'publikationen_gesamt': 147}, 5750388: None, 4529999: {'h_index': 24, 'zitationen_gesamt': 2729, 'publikationen_gesamt': 41}, 2894309: None, 46786657: {'h_index': 11, 'zitationen_gesamt': 517, 'publikationen_gesamt': 23}, 3681289: None, 2080244021: {'h_index': 7, 'zitationen_gesamt': 133, 'publikationen_gesamt': 15}, 69869191: {'h_index': 15, 'zitationen_gesamt': 593, 'publikationen_gesamt': 57}, 12980976: {'h_index': 12, 'zitationen_gesamt': 327, 'publikationen_gesamt': 34}, 5312334: {'h_index': 21, 'zitationen_gesamt': 1216, 'publikationen_gesamt': 58}, 34496939: {'h_index': 24, 'zitationen_gesamt': 1654, 'publikationen_gesamt': 65}, 6650716: {'h_index': 96, 'zitationen_gesamt': 32974, 'publikationen_gesamt': 582}, 5381495: {'h_index': 33, 'zitationen_gesamt': 4091, 'publikationen_gesamt': 164}, 5517965: {'h_index': 17, 'zitationen_gesamt': 1056, 'publikationen_gesamt': 45}}\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(data).fillna(0).T.reset_index().rename(columns={\"index\": \"author_id\"})\n",
    "print(df1)\n",
    "#df2 = df1.reset_index().rename(columns={\"index\": \"author_id\"})\n",
    "#print(df2)\n",
    "#exit()\n",
    "\n",
    "#df2.to_csv(r\"/project/01_data/01_csv_data/00_pi_basics/02_pi_pub_metrics.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f780ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autorendaten für 1692564 erfolgreich geholt!\n",
      "Autorendaten für 145491092 erfolgreich geholt!\n",
      "Autorendaten für 144945538 erfolgreich geholt!\n",
      "Gesamtes Dict: \n",
      " {1692564: {'h-Index': 23, 'Zitationen_Gesamt': 1705, 'Publikationen_Gesamt': 79}, 145491092: {'h-Index': 24, 'Zitationen_Gesamt': 2010, 'Publikationen_Gesamt': 71}, 144945538: {'h-Index': 46, 'Zitationen_Gesamt': 7116, 'Publikationen_Gesamt': 215}}\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "all = {}\n",
    "\n",
    "# Funktion zum Fetchen der Daten basierend auf der AutorenIDs \n",
    "def get_author_metrics(author_id, api_key = None):\n",
    "    \n",
    "    base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    fields = \"hIndex,citationCount,paperCount,papers.citationCount\"\n",
    "    headers = {\"x-api-key\": api_key} if api_key else {}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{base_url}/author/{author_id}\",\n",
    "            params={\"fields\": fields},\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Fehler bei {author_id}!\")\n",
    "            logging.error(f\"Fehler bei {author_id}!\")\n",
    "            return None\n",
    "\n",
    "        data = response.json()\n",
    "        \n",
    "        daten = {\n",
    "            \"h-Index\": data.get(\"hIndex\"),\n",
    "            \"Zitationen_Gesamt\": data.get(\"citationCount\"),\n",
    "            \"Publikationen_Gesamt\": data.get(\"paperCount\")\n",
    "        }\n",
    "        \n",
    "        # logging.info(f\"Autorendaten für {author_id} erfolgreich geholt!\")\n",
    "        print(f\"Autorendaten für {author_id} erfolgreich geholt!\")\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(f\"Fehler {e}\")\n",
    "        # logging.error(f\"Fehler bei {author_id}!\")\n",
    "    \n",
    "    finally: \n",
    "        time.sleep(1.5)\n",
    "    \n",
    "    return daten\n",
    "\n",
    "# Daten einlesen und Funktion aufrufen \n",
    "\n",
    "df0 = pd.read_csv(r\"/project/01_data/01_csv_data/00_pi_basics/01_pi_final_final.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "s2_ids = df0[\"s2_id\"].tolist()\n",
    "\n",
    "for x in s2_ids[:3]:\n",
    "    daten = get_author_metrics(x)\n",
    "    all[x] = daten\n",
    "\n",
    "print(\"Gesamtes Dict:\", \"\\n\", all)\n",
    "print(40*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1af176c6-a32f-4557-8ab0-99ce8d4eb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'pi_id', 'nach_und_vorname', 'scholar_id', 'vorname',\n",
      "       'nachname', 'start_date', 'end_date', 's2_id', 's2_citations',\n",
      "       'author_id', 'h_index', 'zitationen_gesamt', 'publikationen_gesamt'],\n",
      "      dtype='object')\n",
      "Index(['pi_id', 'nach_und_vorname', 'scholar_id', 'vorname', 'nachname',\n",
      "       'start_date', 'end_date', 's2_id', 's2_citations', 'h_index',\n",
      "       'publikationen_gesamt'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['institute', 'drittmittel_gesamt'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m df2\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzitationen_gesamt\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df2\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 16\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpi_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscholar_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms2_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvorname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnachname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnach_und_vorname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstitute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms2_citations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublikationen_gesamt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrittmittel_gesamt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(df2\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#print(df2)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#print(df2['publikationen_gesamt'].sum())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#os.startfile(r'C:\\Users\\felix\\OneDrive\\Desktop\\test_merge.csv')\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['institute', 'drittmittel_gesamt'] not in index\""
     ]
    }
   ],
   "source": [
    "# Test für das mergen von zwei csv \n",
    "import os \n",
    "df = pd.read_csv(r'C:\\Users\\felix\\OneDrive\\Desktop\\masterarbeit\\01_data\\01_csv_data\\00_pi_basics\\01_pi_final_final.csv', sep=\",\", encoding='utf-8')\n",
    "df1 = pd.read_csv(r'C:\\Users\\felix\\OneDrive\\Desktop\\masterarbeit\\01_data\\01_csv_data\\00_pi_basics\\02_pi_pub_metrics.csv', sep=\";\", encoding='utf-8')\n",
    "\n",
    "#print(df.columns, \"\\t\", df1.columns)\n",
    "\n",
    "df2 = df.merge(df1, left_on='s2_id', right_on='author_id', how='left')\n",
    "\n",
    "print(df2.columns)\n",
    "\n",
    "df2.drop(['Unnamed: 0', 'author_id', 'zitationen_gesamt'], axis=1, inplace=True)\n",
    "\n",
    "print(df2.columns)\n",
    "\n",
    "df2 = df2[['pi_id', 'scholar_id', 's2_id', 'vorname', 'nachname', 'nach_und_vorname','start_date', 'end_date', 's2_citations', 'h_index',\n",
    "       'publikationen_gesamt']]\n",
    "\n",
    "print(df2.columns)\n",
    "\n",
    "#print(df2)\n",
    "\n",
    "#print(df2['publikationen_gesamt'].sum())\n",
    "\n",
    "#df2.to_csv(r'C:\\Users\\felix\\OneDrive\\Desktop\\test_merge.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "#os.startfile(r'C:\\Users\\felix\\OneDrive\\Desktop\\test_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202277bb-f40f-457a-923b-08c4aa62059b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
