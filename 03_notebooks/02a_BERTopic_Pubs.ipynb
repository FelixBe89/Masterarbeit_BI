{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3580264",
   "metadata": {
    "id": "a3580264"
   },
   "source": [
    "# Notebook BERTopic (Publikationsdaten)\n",
    "\n",
    "> Dieses ist das erste von zwei Notebooks mit dem gesamten Code zum _topic modeling_ im Bereich der Publikationsdaten.\n",
    "\n",
    "Das Notebook folgt einem bestimmten Aufbau:\n",
    "1. Die einzelnen Zellen müssen sequentiell, also in Reihe, durchlaufen werden.\n",
    "2. Die einzelnen Schritte des Codes werden jeder für sich erläutert und dann aufbgebaut, durch Variablen und Funktionen, sodass nachfolgende Zellen von vorherigen Zellen abhängen.\n",
    "3. Das Notebook kann dabei zwei verschiedene Ziele verfolgen, (i) Durchführung des _grid search_ und mit dem Ziel der Auswahl eines besten Modells, (ii) Auswertung des _topic modeling_ mit dem vorher eruierten, besten Modell. Es ist darauf zu achten, dass der zweite Schritt nur vollzogen werden kann, wenn der erste zumindest einmal durchgeführt wurde, da auf das gespeicherte, beste Modell zugegriffen werden muss.\n",
    "  3.1 Um das einzustellen, gibt es in Zelle 3 zwei Variablen, die entsprechend zu steuern sind. Alles Weitere passiert dann automatisch.\n",
    "4. Da insb. der _grid search_ nicht lokal durchgeführt werden konnte, gibt es in der ersten Zelle eine automatische Umgebungserkennung, die registrieren kann, ob man lokal oder in Google Colab arbeitet. In Google Colab wurde mit gekauften Recheneinheiten verfahren und einer A100 gearbeitet.\n",
    "\n",
    "> Abschließend ist noch anzumerken, dass alle Stellen, die mit der Hilfe moderner KI-Unterstützung überarbeitet wurden, z. B. aufgrund von Fehlerhaftigkeit oder schlechter Funktionalität, als solche gekennzeichnet sind (zum Suchen: \"**[KI]**\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb7e8f",
   "metadata": {
    "id": "64cb7e8f"
   },
   "source": [
    "## Festlegung der _Pipeline_ (_Grid Search_ oder Modellauswertung)\n",
    "\n",
    "Im Folgenden muss festgelegt werden, welche Pipeline genommen werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9efd36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1770112495274,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "4e9efd36",
    "outputId": "728b11dd-523a-44dd-b024-e52b347153f8"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##############################################################################\n",
    "grid_search_pipeline = False\n",
    "evaluation_pipeline = True if grid_search_pipeline is False else False\n",
    "\n",
    "using_all_models = True if grid_search_pipeline is True else False  # Wenn True, werden alle Modelle genutzt, die für das Grid Search gebraucht werden! Embeddings werden neu erstellt und gespeichert!\n",
    "using_top_models = False if grid_search_pipeline is True else True  # Wenn True, werden nur die beiden besten Modelle genutzt, basierend auf der Grid-Search-Auswertung! Embeddings werden geladen!\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "print(f\"Grid Search: {grid_search_pipeline}\\nEvaluation: {evaluation_pipeline}\\n\"\n",
    "f\"Alle Modelle einbeziehen: {using_all_models}\\nNur beste Modelle: {using_top_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c45db3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8951,
     "status": "ok",
     "timestamp": 1770112504321,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "f4c45db3",
    "outputId": "eb8d5c9b-ff0a-498f-be5f-4b915aadc8bf"
   },
   "outputs": [],
   "source": [
    "# Diese erste Zeile prüft automatisch, ob in Colab oder lokal gearbeitet wird und setzt die Pfade\n",
    "# entsprechend zu den unterschiedlichen Verzeichnissen! Außerdem importiert sie die wichtigsten\n",
    "# Module!\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Erkennungsvariable als bool setzen\n",
    "colab_active = \"google.colab\" in sys.modules\n",
    "\n",
    "# print(colab_active)\n",
    "\n",
    "if colab_active is True:\n",
    "    print(\"Notebook befindet sich in Colab-Env. Drive wird gemountet und die nötigen\"\n",
    "    \" Pakete werden installiert.\")\n",
    "\n",
    "    print(\"\\nDrive wird verbunden.\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    base_dir = Path(\"/content/drive/Othercomputers/laptop/masterarbeit\")\n",
    "\n",
    "    # cuML GPU Beschleunigung: Import der anderen UMAP und HDBSCAN Module!\n",
    "    # (Quellen:\n",
    "    # https://odsc.medium.com/accelerating-umap-processing-10-million-records-in-under-a-minute-with-no-code-changes-5d580deb05a7\n",
    "    # https://docs.rapids.ai/api/cuml/stable/\n",
    "    # https://docs.rapids.ai/install/#selector)\n",
    "\n",
    "    print(\"\\ncuML-Pakete werden importiert.\")\n",
    "    from cuml.manifold import UMAP\n",
    "    from cuml.cluster import HDBSCAN\n",
    "\n",
    "    # Installation weiterer Packages für das Colab-Environment\n",
    "    print(\"\\nInstallation weiterer Pakete.\")\n",
    "    %pip install -q bertopic sentence-transformers hdbscan anthropic --upgrade gensim litellm\n",
    "\n",
    "    # Pfade werden definiert\n",
    "    data_dir_pubs = base_dir / \"01_data\" / \"01_csv_data\" / \"99_pubmed\"  # nur PubMed!\n",
    "    data_dir_tpf = base_dir / \"01_data\" / \"01_csv_data\"                 # hier liegen tpf Daten\n",
    "\n",
    "    embedds_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"01_embeddings\"\n",
    "    topic_results_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"02_topic_results\"\n",
    "    topic_visuals_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"03_topic_visuals\"\n",
    "    grid_search_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"04_grid_search\"\n",
    "    models_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"05_models\"\n",
    "\n",
    "    # Check auf erreichbare Pfade\n",
    "    all_paths = [base_dir, data_dir_pubs, data_dir_tpf, embedds_dir, topic_results_dir,\n",
    "                 topic_visuals_dir, grid_search_dir, models_dir]\n",
    "\n",
    "    no_paths = [x for x in all_paths if not x.exists()]\n",
    "\n",
    "    if no_paths:\n",
    "        print(f\"Folgende Pfade konnten nicht erreicht werden:\\n{no_paths}.\")\n",
    "    else:\n",
    "        print(\"\\nAlle Pfade konnten gesetzt und gefunden werden!\")\n",
    "\n",
    "else:\n",
    "    print(\"Notebook ist lokal! Pfade werden entsprechend der Ordnerstruktur\"\n",
    "          \" geprüft und ggf. gesetzt.\")\n",
    "\n",
    "    # Import der nicht-GPU-optimierten Module von UMAP und HDBSCAN\n",
    "    print(\"\\nImport der UMAP- und HDBSCAN-Module (nicht-GPU-optimiert).\")\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "\n",
    "    # Ordnerpfade definieren\n",
    "    print(\"\\nAufsetzen und Prüfung der Ordnerpfade in lokaler Umgebung.\")\n",
    "    base_dir = Path.cwd().parent # entspricht dem Ordner \"masterarbeit\"\n",
    "\n",
    "    # Pfade werden definiert\n",
    "    data_dir_pubs = base_dir / \"01_data\" / \"01_csv_data\" / \"99_pubmed\"  # nur PubMed!\n",
    "    data_dir_tpf = base_dir / \"01_data\" / \"01_csv_data\"                 # hier liegen tpf Daten\n",
    "\n",
    "    embedds_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"01_embeddings\"\n",
    "    topic_results_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"02_topic_results\"\n",
    "    topic_visuals_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"03_topic_visuals\"\n",
    "    grid_search_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"04_grid_search\"\n",
    "    models_dir = base_dir / \"01_data\" / \"03_topic_modeling\" / \"05_models\"\n",
    "\n",
    "    # Check auf erreichbare Pfade\n",
    "    all_paths = [base_dir, data_dir_pubs, data_dir_tpf, embedds_dir, topic_results_dir,\n",
    "                 topic_visuals_dir, grid_search_dir, models_dir]\n",
    "\n",
    "    no_paths = [x for x in all_paths if not x.exists()]\n",
    "\n",
    "    if no_paths:\n",
    "        print(f\"\\nFolgende Pfade konnten nicht erreicht werden:\\n{no_paths}.\")\n",
    "    else:\n",
    "        print(\"\\nAlle Pfade konnten gesetzt und gefunden werden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94199d38",
   "metadata": {
    "id": "94199d38"
   },
   "source": [
    "## Alle Importe und Laden der _Transformer Model_\n",
    "\n",
    "Folgend werden alle notwendigen Importe durchgeführt. Außerdem werden die verschiedenen Transformer-Modelle in einer Dataclass geladen -- je nach Pipeline und Umgebung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99ad0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6ac84be5507f436ca96c66adf0530af8",
      "c738b9eb27b244bab71e8dd53835c53e",
      "06dc79abdaf54fd4874a95e8b15b10a7",
      "70387217e487473d9f5f7130099dc544",
      "54ba441a824e41989771538ba067f285",
      "773e6fdb95054b5f9861bc25bfda4f6f",
      "bc825ca42a804ce4b6ba7d678a0af366",
      "547516fa6c814160a671ce5e21855c4f",
      "4a72773701f54e2cad530f409c5cd1c3",
      "fe9d1835c02845f4adc03a3adea46f27",
      "3ddebb3f8c5c4c0cad2a3070699eb247",
      "6fd4206a037f4d74a838c6a1b6a9e8cd",
      "a67b41eee7104c8ea686f56951975700",
      "b2e542f080f24845893b78ccd8e4d2fc",
      "44cf97cf9a474d09855eaa91f811a047",
      "321ea8ba5190492fabe1bf8b16f59641",
      "006294675d3941458f54fd12cf2826af",
      "9d1be63d01e4447a8095784ed07a1e34",
      "e5a32f1579ff4b378706fc5816642cc8",
      "bd64bfa0c0474aa1a112f1dbe3842dc7",
      "bc34adb28cd84ddda931c28b6a02d560",
      "48073bc8273c4319863d29acac30a449",
      "6e266059709c4e8da76ac8b432aebb2a",
      "952865af8cc14f8fada9d67fd1c387cc",
      "0fd1bf10997c4caba64f121bce009a08",
      "5b555ba2b2bf4db5842b7470b26463f9",
      "4617358298a04411805432945806ee5e",
      "8d62d68952e140afbadb2c65c17a5f2b",
      "103b02dda6f94a0e88785e639aea0322",
      "24fc139b1443486195f3bbc93f6812cb",
      "7d99fdbc5a364e90b4389468c93886cc",
      "c7cc3a5746d8410ba233fdffda6b43c6",
      "0361a1cbed894fe49e47b5a1164250f8",
      "d85311b89c014e8686d788c11bbf5563",
      "fab4221220d64df6bc706b88446f9c34",
      "0a7006b93aa644caa1f830486a38f2e2",
      "d73ab88a270441bdb0cbf99c840db267",
      "5aaaae36ac2a4f7b86cd49a7f60a2823",
      "a7357d54281d4641957f974737e7e84f",
      "63167ce30aa24b338ab4738822a66a5e",
      "50ee3feb8a5d4914beadc9799e7483aa",
      "a69e6ccd2a4a406c91b0a26e57b0ec30",
      "e202b6bda6d6476b807ecd6f53acf532",
      "48d1d887b7e54414b101f1843c155d66",
      "89ec2573750c4e7d9c5fb18871dc3cdc",
      "184ddc3a33274d70a3775b52f6d7a919",
      "8aa9e93254344b30a5040956a5320ea3",
      "100a230e69e1495cb5393b2223585653",
      "400f2572c3834034899c92a0699127b0",
      "7e5a0261dc96455ea16067b137522190",
      "421211f2d5d24c9d91771923a1d48422",
      "0ba29c6cac854f64baf07d40e0803895",
      "df68c0b1156f4d40b719c68cdc28b493",
      "3ed61e1e6f714b15a6b118f2bbef4c47",
      "49fd834ce84c45558e08b2db3d4fa4b3",
      "78e4b7f0cb254069820a1e45ba5485a2",
      "4a35e599e8694e758a426185da996848",
      "954d6b552e624d85819cdd5b5781ace3",
      "21aee6958542461e89270e438540b1d1",
      "ea2408f84e09467da81c4b80a943c602",
      "d8448aee8f874ecc9f44ae1b2f76d826",
      "eb7de8020b7b4d6f8ce01f1c7f9fc5bb",
      "6b755017e21248939d01df24bda77c61",
      "203c31490aff4bffb223f91fadb277a8",
      "e18a139aa1184d4c970d6a32e3e1ce72",
      "124d802d693b4f6dbfe00c7a37d59307",
      "adab518d679242f88115f919206df001",
      "45324baa7d0f46c6b92547973f405533",
      "b5552eceab5145daa640df28a3bf88f5",
      "4a7c31a76fc9493daab759b2ae55773e",
      "c97304670cf74c70808911e048c5fe19",
      "8f3e9fd338c945a7bb090e9b85efd654",
      "f76ce00e79e64372b633da51f8fcfedc",
      "be397afe174b4c9cafb6a69317e96416",
      "cf909adfbdca48909350450e471a7e8a",
      "80374424dcde493ebca4faba22dd60b8",
      "9d47580c2cc4429a9d2587eb0f65f63f",
      "388a0c605c234e80816750a072531667",
      "9b64fde42b614b0384901deaae1e7309",
      "a00852d5c2a7431f8d780f141f47dc2c",
      "7f12fe9381b04e37bc215ef0f69600be",
      "0f23f43179604143b51146b7d3198607",
      "bfade998fc6c4824be853e595ed107dd",
      "0aee7c0e3acb4db393b1aa3d64440b6c",
      "d5cc9cd9d9334da6933eb33117913f0a",
      "e6eace21bfc549989e84e4a1e7f34533",
      "dcf464f966234150a0ebfab001017465",
      "e8beb0303ce847379c8de7bd89bba663",
      "73060e4d9a5740fc83c43b17a3d27926",
      "ec9ee1e6da94496aaa424ada2c2cb6a9",
      "948a95f038304279804e902c66ca985c",
      "966c55f7933e4568ba729df29d395f08",
      "a9a6595e66b24c7392fd289b4ec4e834",
      "c8a381a0f75244efac263d955feaa61a",
      "10836b558e1a443c892ef53f413bfcd1",
      "001e44680e4c4fae87ea4ae9e0323227",
      "a0820732b1eb4c9c9f50d2f6f8db3a2b",
      "531c26f657d842378324b1a20e919fd8",
      "6b4a78bccc534f23aa139843cf7825d0",
      "b569672b051d4ef9b6dd250328a2a2cd",
      "685d82f06451494eabaae8708d90d9c9",
      "b54cfd03086c4c8e878bdfd2c5ce9c21",
      "843ef5a9d5054ed486b2cac12d5e4943",
      "ef27c2f15b1c4472b215973097858ba5",
      "750b4d5a3ebe48f890c88967466ba8c0",
      "1953357f073c4c9c831f549c50c4649c",
      "e7dfc341b9f2467d9bf71b14feac176d",
      "152a45558f8b4c9eaa99a6d918746f6e",
      "5dad3f51c5704ca481349958262c6755",
      "c941a4f50962445aa187619d9343fcaa",
      "52c06a3b4212423380622b21a6bdd16b",
      "86ecd893c2524304bb1b8caa821dde20",
      "09c2ed0a73064af0aded60394b07bd45",
      "f60acf6d13cb44098eb12aa0deb028eb",
      "fc0da9e60b1e47f18f569eef7449716f",
      "da06737b4e294ebd8bae23fd72e8206e",
      "0ceb23b8ae894d85ba7ce4fa27bd0648",
      "e3c58e28774a440588a562b82ff44737",
      "9f4f6b7d495e441bb59313720b79e9a4",
      "7386d0c375694f0b9c3ce6f74568e37f",
      "12320e5f2798412c8d626f4d564a9afe",
      "7419de8221bc4ff0b47c494fe9e69cf7",
      "fd769ee14ae44ff687f217a5fb66959f",
      "85a899b958c04ff2a7160ddcf1639e38",
      "092f642e4feb48b58db627031c80a5ca",
      "b692ae2291324c03bb7710e10eb4d30e",
      "75f905f415e045f5a979ac3d110a0625",
      "5ae637d714ba442a8dac72629842bb7f",
      "5b64a5b176984b3bbb38e59760eb2bcc",
      "711d899c4510446e8a30a5c1f03af7c2",
      "0f07c489ee664a4d8ffbbe92ac969cab",
      "5cd3bf01885d4e73abafdca6030ddc69"
     ]
    },
    "executionInfo": {
     "elapsed": 68328,
     "status": "ok",
     "timestamp": 1770112572749,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "3f99ad0b",
    "outputId": "cc945c3e-37fb-409f-ac8b-d53adaf3504d"
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "from typing import Any, Annotated, Callable, Iterable\n",
    "import pandas as pd\n",
    "import re\n",
    "import openpyxl\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from dataclasses import asdict\n",
    "try:\n",
    "    import kaleido\n",
    "except Exception as e:\n",
    "    print(f\"Fehler im Modul Kaleido...: {e}. Der Code kann trotzdem durchlaufen,\"\n",
    "    \" es werden nur keine png-Exporte erstellt.\")\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "from bertopic.representation import TextGeneration\n",
    "# from crewai import LLM\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(\"Pakete wurden importiert.\")\n",
    "\n",
    "# NLTK Wordnet Check und Load sowie Setzen der Environ_variables\n",
    "if not colab_active:\n",
    "    try:\n",
    "        nltk_path = Path(r\"C:\\Users\\felix\\AppData\\Roaming\\nltk_data\\corpora\\wordnet.zip\")\n",
    "        punkt_path = Path(r\"C:\\Users\\felix\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt_tab\")\n",
    "\n",
    "        if nltk_path.exists():\n",
    "            print(\"Wordnet-Datei ist schon vorhanden und muss nicht erneut geladen werden!\")\n",
    "        else:\n",
    "            print(\"Das NLTK-Paket konnte nicht gefunden werden und wird jetzt geladen!\")\n",
    "            nltk.download(\"wordnet\")\n",
    "\n",
    "        if punkt_path.exists():\n",
    "            print(\"Punkt-Datei ist schon vorhanden und muss nicht erneut geladen werden!\")\n",
    "        else:\n",
    "            print(\"Das Punkt-Paket konnte nicht gefunden werden und wird jetzt geladen!\")\n",
    "            nltk.download(\"punkt_tab\")\n",
    "\n",
    "        # API KEYs\n",
    "        try:\n",
    "            MY_API_KEY = os.environ.get(\"openaikey1\")\n",
    "            if MY_API_KEY is None:\n",
    "                print(\"Der OpenAI-API Key wurde nicht gefunden.\")\n",
    "            else:\n",
    "                print(\"Der OpenAI-API Key wurde geladen.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden der API Keys: {e}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Es kam zu einem Fehler: {e}.\")\n",
    "\n",
    "elif colab_active:\n",
    "    print(\"Das NLTK- und Punkt-Paket wird geladen.\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"punkt_tab\")\n",
    "\n",
    "    # API Key\n",
    "    MY_API_KEY = None\n",
    "\n",
    "#########################################################################################################\n",
    "# Alle wichtigen Vorbereitungsschritte werden hier schon ausgeführt:\n",
    "#########################################################################################################\n",
    "\n",
    "# Tagesdatum aktuell festlegen\n",
    "datum = datetime.datetime.now().strftime(\"%d.%m.%y\")\n",
    "\n",
    "# Dataclass nutzen, um Sentence-Transformer-Modelle zu organisieren\n",
    "# (Quelle: https://www.datacamp.com/tutorial/python-data-classes)\n",
    "@dataclass\n",
    "class Models:\n",
    "    raw_instance: SentenceTransformer\n",
    "    name: str\n",
    "    trained_instance: object | None = None\n",
    "    embeddings: np.ndarray | None = None\n",
    "    doc_topics_assignment: list[int] | None = None\n",
    "    final_topics_df: pd.DataFrame | None = None\n",
    "    umap_n_neighbors: int | None = None\n",
    "    hdbscan_min_cluster_size: int | None = None\n",
    "    hdbscan_min_samples: int | None = None\n",
    "    vectorizer_min_df: int | None = None\n",
    "    vectorizer_max_df: float | None = None\n",
    "\n",
    "if using_all_models is True and using_top_models is True:\n",
    "    raise ValueError(\"\\nEs kann nur eine der beiden Optionen auf True gesetzt werden!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if colab_active is True:\n",
    "    if using_all_models is True:\n",
    "\n",
    "        print(\"\\nColab ist aktiv -- Und: es werden alle Modelle (nicht nur die besten) geladen!\")\n",
    "\n",
    "        # Erstes Dict für die Publikationen\n",
    "        model_dict = {\n",
    "            \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\"), str(\"all-MiniLM\")),\n",
    "            \"mpnet-base\": Models(SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=\"cuda\"), str(\"mpnet-base\")),\n",
    "            \"pubmed\": Models(SentenceTransformer(\"pritamdeka/S-PubMedBert-MS-MARCO\", device=\"cuda\"), str(\"pubmed\")),\n",
    "            \"specter\": Models(SentenceTransformer(\"sentence-transformers/allenai-specter\", device=\"cuda\"), str(\"specter\"))\n",
    "        }\n",
    "\n",
    "        # Zweites Dict für Drittmittel\n",
    "        # model_dict_tpf = {\n",
    "        #     \"allgemein_ml\": Models(SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", device=\"cuda\"), str(\"allgemein_ml\")),\n",
    "        #     \"allgemein_ml_2\": Models(SentenceTransformer(\"intfloat/multilingual-e5-large\", device=\"cuda\"), str(\"allgemein_ml_2\")),\n",
    "        #     \"allgemein_ml_3\": Models(SentenceTransformer(\"sentence-transformers/LaBSE\", device=\"cuda\"), str(\"allgemein_ml_3\"))\n",
    "        # }\n",
    "\n",
    "    elif using_top_models is True:\n",
    "\n",
    "        print(\"\\nColab ist aktiv -- Und: es werden nur die besten Modelle geladen!\")\n",
    "\n",
    "        # Nur die beiden besten Modelle -- diese müssen manuell zugewiesen werden!\n",
    "        top_model_dict = {\n",
    "            \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\"), str(\"all-MiniLM\"))\n",
    "        }\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Trainierte Modelle laden, falls vorhanden\n",
    "        if models_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach dem letzten Modellordner für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    folders = [f.name for f in models_dir.iterdir()]\n",
    "                    print(f\"Liste der Modell-Ordner:\\n{folders}\")\n",
    "                    model_folder = [f for f in folders if y.name+\"_\" in str(f) and \"publications\" in str(f)]\n",
    "                    print(f\"Ausgewählter Modellordner:\\n{model_folder}\")\n",
    "\n",
    "                    if model_folder:\n",
    "                        latest_folder_name = max(model_folder, key=lambda f: (models_dir / f).stat().st_mtime)\n",
    "                        latest_model_path = models_dir / latest_folder_name\n",
    "                        print(f\"\\nTrainiertes Modell für {y.name} wurde gefunden und wird geladen.\")\n",
    "                        y.trained_instance = BERTopic.load(latest_model_path)\n",
    "                    else:\n",
    "                        print(f\"\\nKein trainiertes Modell im Ordner \\\"{models_dir}\\\" für {y.name} gefunden.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden des neuesten {y}-Modellordners: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDer Modelle-Ordner \\\"{models_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "        # Document-Topic-Assignment laden, falls vorhanden\n",
    "        if topic_results_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach der letzten Doc-Topic-Datei für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    files = [f.name for f in topic_results_dir.glob(\"*\")]\n",
    "                    print(f\"Liste der Doc-Topic-Dateien:\\n{files}\")\n",
    "                    file_selection = [f for f in files if y.name+\"_\" in str(f) and \"publications\" in str(f)]\n",
    "                    print(f\"Dateiauswahl:\\n{file_selection}\")\n",
    "\n",
    "                    if file_selection:\n",
    "                        latest_file_name = max(file_selection, key=lambda f: (topic_results_dir / f).stat().st_mtime)\n",
    "                        latest_file_path = topic_results_dir / latest_file_name\n",
    "                        print(f\"\\nDocument-Topic-Assignment für {y.name} wurde gefunden und wird geladen.\")\n",
    "                        y.doc_topics_assignment = pd.read_csv(latest_file_path, encoding=\"utf-8\")[\"topics\"].tolist()\n",
    "                    else:\n",
    "                        print(f\"\\nKeine Doc-Topic-Datei im Ordner \\\"{topic_results_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden der letzten {y}-Doc-Topic_File: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDie Doc-Topic_Datei in \\\"{topic_results_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "\n",
    "elif colab_active is False:\n",
    "    if using_all_models is True:\n",
    "\n",
    "        print(\"\\nCode läuft lokal -- Und: es werden alle Modelle (nicht nur die besten) geladen!\")\n",
    "\n",
    "        # Erstes Dict für die Publikationen\n",
    "        model_dict = {\n",
    "            \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\"), str(\"all-MiniLM\")),\n",
    "            \"mpnet-base\": Models(SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\"), str(\"mpnet-base\")),\n",
    "            \"pubmed\": Models(SentenceTransformer(\"pritamdeka/S-PubMedBert-MS-MARCO\"), str(\"pubmed\")),\n",
    "            \"specter\": Models(SentenceTransformer(\"sentence-transformers/allenai-specter\"), str(\"specter\"))\n",
    "        }\n",
    "\n",
    "        # Zweites Dict für Drittmittel\n",
    "        # model_dict_tpf = {\n",
    "        #     \"tpf1\": Models(SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"), str(\"tpf1\")),\n",
    "        #     \"tpf2\": Models(SentenceTransformer(\"intfloat/multilingual-e5-large\"), str(\"tpf2\")),\n",
    "        #     # \"tpf3\": Models(SentenceTransformer(\"LaBSE\"), str(\"tpf3\"))\n",
    "        # }\n",
    "\n",
    "    elif using_top_models is True:\n",
    "\n",
    "        print(\"\\nCode läuft lokal -- Und: es werden nur die besten Modelle geladen!\\n\")\n",
    "\n",
    "        # Nur die beiden besten Modelle\n",
    "        top_model_dict = {\n",
    "            \"all-MiniLM\": Models(SentenceTransformer(\"all-MiniLM-L6-v2\"), str(\"all-MiniLM\"))\n",
    "        }\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Trainierte Modelle laden, falls vorhanden\n",
    "        if models_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach dem letzten Modellordner für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    folders = [f.name for f in models_dir.iterdir()]\n",
    "                    print(f\"Liste der Modell-Ordner:\\n{folders}\")\n",
    "                    model_folder = [f for f in folders if y.name+\"_\" in str(f) and \"publications\" in str(f)]\n",
    "                    print(f\"Ausgewählter Modellordner:\\n{model_folder}\")\n",
    "\n",
    "                    if model_folder:\n",
    "                        latest_folder_name = max(model_folder, key=lambda f: (models_dir / f).stat().st_mtime)\n",
    "                        latest_model_path = models_dir / latest_folder_name\n",
    "                        print(f\"\\nTrainiertes Modell für {y.name} wurde gefunden und wird geladen.\\n\")\n",
    "                        y.trained_instance = BERTopic.load(latest_model_path)\n",
    "                    else:\n",
    "                        print(f\"\\nKein trainiertes Modell im Ordner \\\"{models_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden des neuesten Modellordners für das Modell {y.name}: {e}.\\n\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDer Modelle-Ordner \\\"{models_dir}\\\" konnte nicht gefunden werden.\")\n",
    "\n",
    "        print(80*\"=\")\n",
    "\n",
    "        # Document-Topic-Assignment laden, falls vorhanden\n",
    "        if topic_results_dir.exists():\n",
    "            for x,y in top_model_dict.items():\n",
    "                print(f\"\\nStart der Suche nach der letzten Doc-Topic-Datei für das Modell {y.name}.\")\n",
    "                try:\n",
    "                    files = [f.name for f in topic_results_dir.glob(\"*\")]\n",
    "                    print(f\"Liste der Doc-Topic-Dateien:\\n{files}\")\n",
    "                    file_selection = [f for f in files if y.name+\"_\" in str(f) and \"publications\" in str(f) and \"doc_topics_assignment_\" in str(f)]\n",
    "                    print(f\"Dateiauswahl:\\n{file_selection}\")\n",
    "\n",
    "                    if file_selection:\n",
    "                        latest_file_name = max(file_selection, key=lambda f: (topic_results_dir / f).stat().st_mtime)\n",
    "                        latest_file_path = topic_results_dir / latest_file_name\n",
    "                        print(f\"\\nDocument-Topic-Assignment für {y.name} wurde gefunden und wird geladen.\\n\")\n",
    "                        y.doc_topics_assignment = pd.read_csv(latest_file_path, encoding=\"utf-8\")[\"topics\"].tolist()\n",
    "                    else:\n",
    "                        print(f\"\\nKeine Doc-Topic-Datei im Ordner \\\"{topic_results_dir}\\\" für {y.name} gefunden.\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFehler beim Finden der letzten Doc-Topic_File für das Modell {y.name}: {e}.\\n\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nDie Doc-Topic_Datei in \\\"{topic_results_dir}\\\" konnte nicht gefunden werden.\\n\")\n",
    "\n",
    "        print(80*\"=\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f66bb",
   "metadata": {
    "id": "ac1f66bb"
   },
   "source": [
    "## Vorverarbeitung der Daten\n",
    "\n",
    "Die Publikationsdaten werden eingelesen und vorverarbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a1e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13351,
     "status": "ok",
     "timestamp": 1770112585993,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "a59a1e62",
    "outputId": "c3c9a0a3-872d-460a-edb4-0fe61a4ec4ea"
   },
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Datenvorverarbeitung der Publikationsdaten\n",
    "#########################################################################################################\n",
    "\n",
    "# Ordner einlesen, in die Dateien liegen\n",
    "folder = data_dir_pubs\n",
    "\n",
    "# Einzelne Csv-Dateien in Liste packen\n",
    "concat_list = [pd.read_csv(x, encoding=\"utf-8\") for x in folder.glob(\"*.csv\")]\n",
    "\n",
    "#print(concat_list)\n",
    "\n",
    "# Finalen Dataframe aller Publikationen konkatenieren\n",
    "df_all = pd.concat(concat_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Check\n",
    "print(80*\"=\")\n",
    "print(\"Shape des Gesamtdf:\")\n",
    "print(df_all.shape)\n",
    "print(80*\"=\")\n",
    "print(\"Spalten des Gesamtdf:\")\n",
    "print(df_all.columns)\n",
    "print(80*\"=\")\n",
    "print(\"Übersicht zu den Werten:\")\n",
    "print(df_all.info())\n",
    "print(80*\"=\")\n",
    "\n",
    "#########################################################################################################\n",
    "# Erstes Preprocessing der Titel+Abstract-Strings\n",
    "#########################################################################################################\n",
    "\n",
    "# Leere und unvollständige Titel u/o Abstracts entfernen\n",
    "df_all = df_all.dropna(subset=[\"abstract\", \"title\"])\n",
    "df_all = df_all[~(df_all[\"abstract\"] == \"no abstract\")]\n",
    "\n",
    "# Titel und Abstracts aufteilen\n",
    "docs_titles = df_all[\"title\"] #.tolist()\n",
    "docs_abstracts = df_all[\"abstract\"]# .tolist()\n",
    "#docs_keywords = df_all[\"keywords\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\") #.tolist()\n",
    "\n",
    "# Kurze Überprüfungen\n",
    "#print([len(x) for x in [docs_titles, docs_abstracts, docs_keywords]])\n",
    "#print(len(df_all[df_all[\"abstract\"].str.lower().isin([\"no\"])]))\n",
    "#print(docs_abstracts)\n",
    "\n",
    "# Erstellung der Dokumentenliste\n",
    "processed_docs = [title + \"|\" + abstract for title, abstract in zip(docs_titles, docs_abstracts)]\n",
    "\n",
    "# Check\n",
    "print(\"Anzahl der Einträge der processed docs nach dem Entfernen von Leerzeilen bzw. falsch befüllten Zeilen:\")\n",
    "print(len(processed_docs))\n",
    "print(80*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5e881",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1770112586314,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "34e5e881"
   },
   "outputs": [],
   "source": [
    "# Die folgenden Funktion ist ein kurzes, textuelles Preprocessing der Titel+Absttract-Strings\n",
    "# (Anm.: Die Dokumentation erwähnt explizit, dass die Stopwörter hier noch nicht entfernt\n",
    "# werden sollen. Das erfolgt erst im eigentlichen Modellaufruf durch ein CountVectorizer-Modell)\n",
    "\n",
    "def preprocessed_text(text: str) -> str:\n",
    "    \"\"\"Die Strings aus Titeln und Abstracts werden leicht vorverarbeitet mit üblichen Stringoperationen und Regexfunktionen.\n",
    "\n",
    "    Args:\n",
    "    - Text als String\n",
    "\n",
    "    Returns:\n",
    "    - Bearbeiteten Text\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s|]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Funtkionsaufruf für jedes Item aus preprocessed_docs\n",
    "cleaned_docs = [preprocessed_text(x) for x in processed_docs]\n",
    "\n",
    "# Check\n",
    "def preprocessing_check(processed_list: list[str], realm: Annotated[str, \"Entweder Publikationen oder Drittmitteldaten\"]):\n",
    "    \"\"\"Diese kleine Funktion checkt die Ergebnisse der Vorverarbeitungen der Textdaten.\n",
    "\n",
    "    Args:\n",
    "    -\n",
    "\n",
    "    Returns\n",
    "    -\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Anzahl der {realm} (Titel+Abstract) der vorverarbeiteten Daten nach dem Preprocessing:\")\n",
    "    print(len(processed_list))\n",
    "    print(80*\"=\")\n",
    "    print(f\"Anzahl der Wörter/Token der vorverarbeiteten Daten ({realm}) nach dem Preprocessing:\")\n",
    "    list_of_words = []\n",
    "    for x in processed_list:\n",
    "        b = x.split(\" \")\n",
    "        list_of_words.append(b)\n",
    "    print(sum([sum([1 for x in y]) for y in list_of_words]))\n",
    "    print(80*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454982ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1770112586740,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "454982ac",
    "outputId": "cecf4e70-2d8e-470c-ad9e-5a2f6082baf0"
   },
   "outputs": [],
   "source": [
    "# Funtkionsaufruf für den Check\n",
    "preprocessing_check(cleaned_docs, \"Publikationen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c91fa4",
   "metadata": {
    "id": "20c91fa4"
   },
   "source": [
    "## Fuktionsdefinition der Embeddings\n",
    "\n",
    "Nachdem die Vorverarbeitung bereinigte, nutzbare Daten erzeugt hat, können diese zur Erstellung der Vektorembeddings genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9f21a",
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1770112587032,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "e5d9f21a"
   },
   "outputs": [],
   "source": [
    "# Die folgende Funktion erstellt ODER lädt bestehende Embeddings der drei verwendeten Modelle\n",
    "# (Anm.: Da das Erstellen der Embeddings einige Zeit in Anspruch nimmt, wurden diese gespeichert und werden jedes Mal wieder geladen,\n",
    "# wenn man es so einstellt bzw. sie vorhanden sind. Dafür ist allerdings auch die richtige Ordnerstruktur entscheidend, damit diese\n",
    "# gespeichert und geladen werden können. )\n",
    "\n",
    "\n",
    "def create_or_load_embeddings(realm: Annotated[str, \"Entweder 'publications' oder 'tpf'\"],\n",
    "                              docs: list[str],\n",
    "                              model_dict: dict,\n",
    "                              # model_names: list[str] = [b.name for _,b in model_dict.items()],\n",
    "                              load_embeds: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Diese Funktion erstellt die Embeddings der Titel+Abstract-Kombinationen für Publikationen und Drittmitteldaten mit vier verschiedenen\n",
    "    Sentence-Transformer-Modellen:\n",
    "\n",
    "    1. Allgemeines Modell\n",
    "    2. PubMed-Modell\n",
    "    3. SciBERT\n",
    "    4. SPECTER2\n",
    "\n",
    "    Dafür werden nur die folgenden Argumente gebraucht:\n",
    "\n",
    "    Args:\n",
    "    - realm = \"publications\" oder \"tpf\"\n",
    "    - docs =\n",
    "    - model_dict =\n",
    "    - load_embedds =\n",
    "\n",
    "    Returns:\n",
    "    - es wird direkt nichts ausgegeben, wohl aber werden die Embeddings in der jeweiligen Model-Class gespeichert!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ###############################################\n",
    "    # 1. Teil: Embeddings **laden**\n",
    "    ###############################################\n",
    "    # Wenn Arg \"load_embeds\" == True (Standardwert), dann werden keine Embeddings erstellt, sondern lokal geladen! Es wird automatisch die\n",
    "    # zuletzt erstelle Datei gesucht\n",
    "\n",
    "    if load_embeds is True:\n",
    "        # Hier werden zunächst die jeweils *letzten* Embeddings identifiziert\n",
    "        embedding_folder_files = list(Path(embedds_dir).glob(\"*.npy\"))\n",
    "\n",
    "        # Schleife für alle Modelle\n",
    "        for x,y in model_dict.items():#\n",
    "            try:\n",
    "                files = [x for x in embedding_folder_files if y.name + \"_\" in str(x).lower()]\n",
    "                latest_file = max(files, key=lambda x: x.stat().st_mtime, default=None)\n",
    "\n",
    "                model_dict[x].embeddings = np.load(latest_file)\n",
    "\n",
    "                print(f\"Name der zuletzt gespeicherten Embeddings aus dem Modell \\\"{y.name}\\\": {latest_file}.\")\n",
    "                print(f\"Prüfung der Anzahl der Embeddings von {y.name} und ihrer Dimensionalität:\")\n",
    "                print(f\"{y.embeddings.shape[0]} Datensätze mit {y.embeddings.shape[1]} Dimensionen.\")\n",
    "                print(80*\"=\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Es konnte keine letzte Datei mit Embeddings zu diesem Modell ({y.name}) gefunden werden.\")\n",
    "                return False\n",
    "\n",
    "    ###############################################\n",
    "    # 2. Teil: Embeddings **erzeugen** und speichern (wenn so angegeben!)\n",
    "    ###############################################\n",
    "    # Wenn Arg \"load_embeds\" == False, dann werden keine Embeddings erstellt, sondern geladen.\n",
    "    # Das Erzeugen der Embeddings dauert je nach Kapazitäten und Modellen bis zu 30 Minuten\n",
    "\n",
    "    if load_embeds is False:\n",
    "\n",
    "        # Die Embedding-Objekte sind schon in der ersten Zelle definiert\n",
    "        for x,y in model_dict.items():\n",
    "\n",
    "            try:\n",
    "                # Embeddings werden erstellt\n",
    "                print(f\"Modell \\\"{y.name}\\\" startet.\")\n",
    "                start = time.time()\n",
    "                embeddings = y.raw_instance.encode(docs, batch_size=128, show_progress_bar=True)\n",
    "                end = time.time()\n",
    "                print(\"Die Embeddings mit {} sind mit einer Laufzeit von {} Minuten erstellt worden.\\n\".format(y.name, int((end-start)/60)))\n",
    "\n",
    "                # Embedings werden gespeichert\n",
    "                embeddings_df = pd.DataFrame(embeddings)\n",
    "                embeddings_df.to_excel(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.xlsx\",\n",
    "                                    sheet_name=\"embeddings\", engine=\"openpyxl\")\n",
    "                np.save(rf\"{embedds_dir}/embeddings_{realm}_{y.name}_{datum}.npy\", embeddings)\n",
    "\n",
    "                # Embeddings zuweisen\n",
    "                y.embeddings = embeddings\n",
    "\n",
    "                # Überprüfung\n",
    "                print(f\"Prüfung der Anzahl der Embeddings von {y.name} und ihrer Dimensionalität:\")\n",
    "                print(f\"{y.embeddings.shape[0]} Datensätze mit {y.embeddings.shape[1]} Dimensionen.\")\n",
    "                print(80*\"=\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Modell {y.name}: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620325ae",
   "metadata": {
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1770112587418,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "620325ae"
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Funktion zum Check auf lokale Embeddings\n",
    "##########################################\n",
    "\n",
    "def check_local_embeddings(model_dict: dict) -> bool:\n",
    "    \"\"\"Diese Funktion checkt, ob für alle Modelle im übergebenen Dict Embeddings\n",
    "    lokal vorhanden sind.\n",
    "\n",
    "    Args:\n",
    "    - model_dict = Dict mit den Modellen\n",
    "\n",
    "    Returns:\n",
    "    - bool: True, wenn für alle Modelle Embeddings vorhanden sind, sonst False\n",
    "    \"\"\"\n",
    "\n",
    "    all_exist = True\n",
    "\n",
    "    for x,y in model_dict.items():\n",
    "        if y.embeddings is None:\n",
    "            print(f\"Für das Modell {y.name} sind keine lokalen Embeddings vorhanden.\")\n",
    "            all_exist = False\n",
    "        else:\n",
    "            print(f\"Für das Modell {y.name} sind lokale Embeddings vorhanden.\")\n",
    "\n",
    "    return all_exist\n",
    "\n",
    "# Funktionsaufruf\n",
    "# check_local_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1db47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1770112587941,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "d7a1db47",
    "outputId": "fd17d378-dd6b-4173-c836-86741c24f858"
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Funktionsaufruf zum ERSTELLEN der Embeddings für die Publikationen\n",
    "##########################################\n",
    "\n",
    "if using_all_models is True:    # Dieser Weg führt zum Grid Search, Embeddings werden neu erstellt und gespeichert\n",
    "    print(\"Es werden alle Modelle genutzt, für die die Embeddings **neu** erstellt werden.\\n\")\n",
    "    create_or_load_embeddings(realm=\"publications\", docs=cleaned_docs, model_dict=model_dict, load_embeds=False)\n",
    "else:\n",
    "    print(\"Embeddings werden hier nicht erstellt, da die Auswertung der besten Modelle folgt.\\n\")\n",
    "\n",
    "# elif using_top_models is True:  # Dieser Weg führt zur Auswertung, Embeddings werden nur noch geladen\n",
    "#     print(\"Es werden nur die besten Modelle genutzt, für die die Embeddings geladen werden.\\n\")\n",
    "#     create_or_load_embeddings(realm=\"publications\", docs=cleaned_docs, model_dict=top_model_dict, load_embeds=True)\n",
    "#     print(f\"Check der geladenen Embeddings für die besten Modelle:\\n{[top_model_dict[x].embeddings.shape for x in top_model_dict.keys()]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356bfa9",
   "metadata": {
    "id": "2356bfa9"
   },
   "source": [
    "## Funktionserstellung zur Durchführung des _Topic Modeling_\n",
    "\n",
    "Folgend wird eine Funktion definiert, die das Themenclustering durchführt. Dafür werden zunächst die Stopwörter definiert und weitere Vorbereitungsschritte durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d952a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1770112588732,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "d3d952a6"
   },
   "outputs": [],
   "source": [
    "# Da sich in verschiedenen Testläufen die Entfernung der Stopwörter durch die Standardstopwörterliste als ungeeignet erwiesen hat, weil immer wieder eine\n",
    "# große Anzahl von ihnen in den Topic-Clustern erschienen ist, mussten die Stopwörter umfassend manuell erweitert werden. Integriert sind jetzt all diejenigen,\n",
    "# die standardmäßig in hoher Anzahl in (natur-)wissenschaftlichen, englischen Texten vorkommen und das Topic-Modeling dahingehend beeinflussen.\n",
    "\n",
    "# Erweiterte Stop-Wörterliste\n",
    "# (Quellen: Eigene Analyse der Topic-Cluster-Ergebnisse sowie\n",
    "# https://www.ranks.nl/stopwords und in der finalen Überarbeitung\n",
    "# eine Überprüfungs- und Ergänzungsanfrage bei ChatGPT [KI])\n",
    "custom_additions = [\n",
    "    \"the\", \"and\", \"of\", \"in\", \"to\", \"is\", \"for\", \"was\", \"we\", \"that\",\n",
    "    \"with\", \"by\", \"as\", \"are\", \"this\", \"it\", \"from\", \"on\", \"an\", \"be\",\n",
    "    \"were\", \"which\", \"or\", \"at\", \"can\", \"been\", \"has\", \"have\", \"had\",\n",
    "    \"they\", \"their\", \"these\", \"those\", \"than\", \"then\", \"them\", \"there\",\n",
    "    \"when\", \"where\", \"who\", \"will\", \"would\", \"should\", \"could\", \"may\",\n",
    "    \"might\", \"must\", \"our\", \"my\", \"your\", \"its\", \"his\", \"her\", \"into\",\n",
    "    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"up\", \"down\",\n",
    "    \"out\", \"off\", \"over\", \"under\", \"again\", \"further\", \"once\", \"here\",\n",
    "    \"also\", \"such\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\",\n",
    "    \"can\", \"just\", \"don\", \"now\", \"use\", \"using\", \"used\"\n",
    "]\n",
    "\n",
    "# Weitere spezifische Stopwörter\n",
    "academic_stopwords = [\n",
    "    \"study\", \"studies\", \"research\", \"article\", \"paper\", \"results\", \"data\",\n",
    "    \"analysis\", \"methods\", \"method\", \"approach\", \"examined\", \"investigated\",\n",
    "    \"findings\", \"conclusion\", \"conclusions\", \"present\", \"presented\",\n",
    "    \"show\", \"showed\", \"shown\", \"demonstrate\", \"demonstrated\", \"found\",\n",
    "    \"observed\", \"reported\", \"compared\", \"based\", \"studied\", \"analyzed\",\n",
    "    \"identified\", \"examined\", \"evaluated\", \"assessed\", \"determined\",\n",
    "    \"associated\", \"related\", \"significant\", \"ignificantly\", \"effects\",\n",
    "    \"effect\", \"between\", \"among\", \"across\", \"within\", \"using\", \"used\",\n",
    "    \"experiment\", \"experiments\", \"sample\", \"samples\", \"population\",\n",
    "    \"participants\", \"subjects\", \"variables\", \"variable\", \"measured\",\n",
    "    \"measurement\", \"results\", \"conclusions\", \"implications\", \"limitations\",\n",
    "    \"future\", \"directions\", \"introduction\", \"background\", \"literature\",\n",
    "    \"review\", \"theory\", \"theoretical\", \"framework\", \"model\", \"models\"\n",
    "]\n",
    "\n",
    "# Zusammenführen der Stop-Wörter in einer Liste\n",
    "comprehensive_stopwords = list(ENGLISH_STOP_WORDS) + custom_additions + academic_stopwords\n",
    "\n",
    "\n",
    "# Lemmatization hinzufügen, um die KEywords der Topic Cluster zu verbessern, v.a. um doppelte Wörter zu vermeiden!\n",
    "# (Quelle: Dokumentation BERTopic unter: https://github.com/MaartenGr/BERTopic/issues/286)\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "###########################################################################################################\n",
    "# Funktion, um BERTopic zu initialisieren und das Clustering durchzuführen\n",
    "###########################################################################################################\n",
    "\n",
    "def topic_clustering(realm: str, sentence_transformer: SentenceTransformer, docs: list[str], embeddings: np.ndarray, hdbscan_min_cluster_size: int = 20, hdbscan_min_samples: int = 5,\n",
    "                     umap_n_neighbors: int = 15, vec_max_df: float = 0.95, vec_min_df: int = 2, stop_words: list = comprehensive_stopwords, save_xlsx: bool = False,\n",
    "                     model_nr_topics: int | None = None, ai_model: str | None = None, model_name: str | None = None, datum: str | None = None, save_model: bool = False):\n",
    "    \"\"\"\n",
    "    Diese Funktion führt ein Topic Modeling auf Basis von vorbearbeiteten Textdaten sowie bereits erstellen Embeddings durch und nimmt zudem\n",
    "    eine Liste mit Stop-Wörtern und Hyperparametern zu den Teilmodulen UMAP und HDBSCAN entgegen.\n",
    "\n",
    "    Args:\n",
    "    - embedding_model = Hier wird das gewählte Embedding Model übergeben.\n",
    "    - docs = Hier werden die Datensätze in Form einer Liste übergeben.\n",
    "    - embeddings = Hier werden die vorkalkulierten Embeddings in einem Array übergeben.\n",
    "    - hdbscan_min_cluster_size = Hier kann die Anzahl der Topics variiert werden (um die Granularität einzustellen). Standardmäßig ist der in dieser Arbeit beste Wert voreingestellt.\n",
    "    - umap_n_neighbors = Legt wiederum die Anzahl der Clustergrößen fest\n",
    "    - model_nr_topics = Hier kann man die Anzahl der Topics im Output direkt festlegen lassen, wenn man bspw. weiß, wie viele es sein sollen.\n",
    "    - stop_words = Hier wird die erweiterte Stopwörterliste übergeben.\n",
    "\n",
    "    Returns:\n",
    "    - Einen Dataframe mit den Ergebnissen des Topic Clusterings.\n",
    "    - Das trainierte Topic Model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Zeit nehmen\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # UMAP zur Dimensionsreduktion mit den Paramtern:\n",
    "        umap_model = UMAP(n_neighbors=umap_n_neighbors, # legt die Anzahl der Clustergröße fest\n",
    "                        n_components=5, # legt die Anzahl der Zieldimension fest, auf die reduziert werden soll\n",
    "                        min_dist=0.0, # legt den Abstand der dimensionreduzierten Clusterpunkte im Raum fest (Unschärfe)\n",
    "                        metric=\"cosine\", # Metrik zur Bestimmung der Abweichungen/Distanzen\n",
    "                        random_state=42 # Sorgt für die Reproduzierbarkeit der Ergebnisse\n",
    "                        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im UMAP-Algorithmus für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # HDBSCAN zum Clustering der Dokumente mit den Parametern\n",
    "        hdbscan_model = HDBSCAN(min_cluster_size=hdbscan_min_cluster_size, # Minimum an Dokumenten für ein Cluster\n",
    "                                min_samples=hdbscan_min_samples, # Dichte der Elemente eines Clusters\n",
    "                                metric=\"euclidean\", # Standardmetrik, passend für wenige Dimensionen\n",
    "                                cluster_selection_method=\"eom\", # Clusterauswahl; Alternative: leaf\n",
    "                                prediction_data=True # ermöglicht neue Vorhersagen für neue Dokumente\n",
    "                            )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im HDBSCAN-Algorithmus für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Vec-Model für stop-word-removal und Erstellung von N-Grammen mit den Parametern:\n",
    "        vectorizer_model = CountVectorizer(stop_words=stop_words, # Übergabe der definierten Stopwörterliste\n",
    "                                        tokenizer=LemmaTokenizer(),\n",
    "                                        min_df=vec_min_df, # wie oft ein Term in den Dokumenten vorkommen **muss**\n",
    "                                        max_df=vec_max_df, # wie oft ein Term in den Dokumenten vorkommen **darf**\n",
    "                                        ngram_range=(1, 2), # Angabe der N-Gramme (hier: Ein- bis einschl. Zwei-Wort-Paare)\n",
    "                                        token_pattern=r\"\\b[a-zA-Z]{3,}\\b\" # Akzeptiert werden nur Wörter mit mind. 3 Buchstaben\n",
    "                                        )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im CountVectorizer für das Model {model_name}: {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Representation Model (Empfehlung aus der Dokumentation) -- kann man mit OpenAI machen, muss man aber nicht\n",
    "\n",
    "    # gpt_5_1 = LLM(\n",
    "    #         model=\"gpt-5.1\",\n",
    "    #         drop_params=True,\n",
    "    #         additional_drop_params=[\"stop\"]\n",
    "    #     )\n",
    "\n",
    "    representation_model = None\n",
    "    if ai_model is None:\n",
    "        print(\"Es wird kein LLM für die Repräsentationen verwendet!\")\n",
    "        representation_model = KeyBERTInspired()\n",
    "    elif ai_model == \"open_ai\":\n",
    "        print(\"\\nOpenAI soll für das Representation Model genutzt werden.\")\n",
    "        if MY_API_KEY:\n",
    "            print(\"\\nAPI-Key konnte gefunden werden!\")\n",
    "            client = openai.OpenAI(api_key=MY_API_KEY)\n",
    "\n",
    "            # Erstellung der Prompts nach Dokumentation von Grootendorst!\n",
    "            summarization_prompt = \"\"\"\n",
    "            I have a topic that is described by the following keywords: [KEYWORDS]\n",
    "            In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
    "            [DOCUMENTS]\n",
    "\n",
    "            Based on the information above, please give a description of this topic in the following format:\n",
    "            topic: <description>\n",
    "            \"\"\"\n",
    "            title_prompt= \"\"\"\n",
    "            I have a topic that contains the following documents:\n",
    "            [DOCUMENTS]\n",
    "            The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "            Based on the information above, extract a short topic label in the following format:\n",
    "            topic: <topic label>\n",
    "            \"\"\"\n",
    "\n",
    "            #Modeldefinition\n",
    "            representation_model = {\n",
    "                \"Main\": KeyBERTInspired(),\n",
    "                \"ChatGPT\": OpenAI(client, model=\"gpt-4o\",\n",
    "                                  prompt=summarization_prompt,\n",
    "                                  nr_docs=5,\n",
    "                                  delay_in_seconds=10 #,\n",
    "                                  #generator_kwargs={\"stop\": None}\n",
    "                                  ),\n",
    "                \"ChatGPT_titles\": OpenAI(client, model=\"gpt-4o\",\n",
    "                                         prompt=title_prompt,\n",
    "                                         nr_docs=5,\n",
    "                                         delay_in_seconds=4)\n",
    "            }\n",
    "        else:\n",
    "            print(\"Kein OpenAI-API-Key vorhanden! KeyBERTInspired wird genommen!\")\n",
    "            representation_model = KeyBERTInspired()\n",
    "\n",
    "    if representation_model is None:\n",
    "        raise ValueError(\"Aufgrund eines Fehlers wurde kein Representation Model geladen!\")\n",
    "\n",
    "    try:\n",
    "        # BERTopic starten mit den Parametern:\n",
    "        topic_model = BERTopic(embedding_model=sentence_transformer,        # Sentence-Transformer-Modell\n",
    "                            umap_model=umap_model,                          # Modell zur Dimensreduktion\n",
    "                            hdbscan_model=hdbscan_model,                    # Clusteringmodell\n",
    "                            vectorizer_model=vectorizer_model,              # Vectorizer\n",
    "                            representation_model=representation_model,      # zwei Representation Models\n",
    "                            nr_topics=model_nr_topics,                      # Festlegung auf Zielwert der Topic-Anzahl\n",
    "                            verbose=True,                                   # Fortschrittsanzeige\n",
    "                            calculate_probabilities=True,                   # Topic-Wahrscheinlichkeiten\n",
    "                            )\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im Aufruf des BERTopic-Moduls für das Modell \\\"{model_name}\\\": {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Beginn des Clusterings der Themen\n",
    "    topics = None\n",
    "    probs = None\n",
    "    try:\n",
    "        print(f\"\\nDas Topic Modeling wird jetzt für das Modell \\\"{model_name}\\\" initiiert.\\n\")\n",
    "        topics, probs = topic_model.fit_transform(docs, embeddings=embeddings)\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"max_df corresponds to < documents than min_df\" in str(e):\n",
    "            print(80*\"=\", f\"\\nBeim Model \\\"{model_name}\\\" ist in diesem Durchlauf der bekannte Fehler aufgetreten\"\n",
    "                  f\": {e}.\\nDie Funktion wird weiter ausgeführt.\\n\", 80*\"=\")\n",
    "        else:\n",
    "            print(f\"Fehler im Topic Modeling für das Modell \\\"{model_name}\\\": {e}.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Outlier autom. reduzieren lassen im Sinne einer nachträglichen Clusterzuordnung\n",
    "    if topics is not None:\n",
    "        try:\n",
    "            new_topics = topic_model.reduce_outliers(docs, topics, strategy=\"distributions\")\n",
    "            topic_model.update_topics(docs, topics=new_topics, representation_model=representation_model)\n",
    "            topics = new_topics\n",
    "\n",
    "            # Speichern\n",
    "            df_doc_topics = pd.DataFrame({\"topics\": topics})\n",
    "            df_doc_topics.to_csv(topic_results_dir / f\"doc_topics_assignment_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "            print(\"\\nTopic-Dokumenten-Zuordnung wurde erfolgreich gespeichert.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Fehler in der Reduzierung der Outlier-Themen beim Modell \\\"{model_name}\\\": {e}.\")\n",
    "            new_topics = topics if topics is not None else None\n",
    "            # Speichern\n",
    "            df_doc_topics = pd.DataFrame({\"topics\": new_topics})\n",
    "            df_doc_topics.to_csv(topic_results_dir / f\"doc_topics_assignment_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "            print(\"Fehler! Die Topic-Dokumenten-Zuordnung wurde dennoch erfolgreich gespeichert.\")\n",
    "    elif topics is None:\n",
    "            new_topics = None\n",
    "            print(f\"Das Topic Modeling für das Modell \\\"{model_name}\\\" konnte nicht durchgeführt werden. Die Topics sind None.\")\n",
    "\n",
    "    # Ergebnisse der Topics als Df einer Variable zuweisen\n",
    "    topics_summary = topic_model.get_topic_info()\n",
    "\n",
    "    # Zeit nehmen\n",
    "    end_time = time.time()\n",
    "    duration = round(int(((end_time - start_time)/60)), 0)\n",
    "\n",
    "    # Kurze Auswertungen pro Durchgang ausgeben\n",
    "    print(80*\"=\")\n",
    "    print(f\"\\nAnalyseergebnisse für das Modell \\\"{str(model_name)}\\\" bei einer Laufzeit von {duration if duration > 0 else 1} Minuten:\\n\")\n",
    "    print(f\"1. Parameter:\\n1.1 HDBSCAN min_cluster_size = {hdbscan_min_cluster_size},\\n1.1 HDBSCAN min_sample_size ={hdbscan_min_samples},\"\n",
    "        f\"\\n1.2 UMAP n_neighbors = {umap_n_neighbors},\"\n",
    "        f\"\\n1.3 Vectorizer max_df = {vec_max_df},\"\n",
    "        f\"\\n1.4 Vectorizer min_df = {vec_min_df},\\n1.5 BERTopic Model min_nr_topics = {model_nr_topics},\\n1.6 AI Model = {ai_model}\")\n",
    "    print(f\"2. Anzahl der gefundenen Topics = {len(topics_summary)-1}.\") # Outlier werden nicht mit angegeben!\n",
    "    print(f\"3. Mittelwert der Publikationen pro Topic = {topics_summary[\"Count\"].mean():.0f}\")\n",
    "    print(f\"4. Relation der Outliers am Gesamtkorpus = {((topics_summary[\"Count\"].iloc[0] / topics_summary[\"Count\"].sum())*100):.2f} %.\")\n",
    "    print(f\"5. Die Variable \\\"topics\\\" enthält die Topic-Zuordnungen pro Dokument und war nicht leer = {topics is not None}.\")\n",
    "    print(80*\"=\")\n",
    "\n",
    "    # Ergebnisse pro Durchgang in xlsx und csv lokal speichern\n",
    "    if save_xlsx is True:\n",
    "        df = pd.DataFrame(topics_summary)\n",
    "        df.to_excel(rf\"{topic_results_dir}/topic_results_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.xlsx\", sheet_name=\"daten\", engine=\"openpyxl\")\n",
    "        df.to_csv(rf\"{topic_results_dir}/topic_results_{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.csv\", encoding=\"utf-8\")\n",
    "        #os.startfile(rf\"C:\\Users\\felix\\OneDrive\\Desktop\\masterarbeit\\01_data\\03_topic_modeling\\topic_results_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}.xlsx\")\n",
    "\n",
    "    # Das trainierte Modell ggf. speichern, damit es immer wieder geladen werden kann\n",
    "    full_path = models_dir / f\"{realm}_{model_name}_{datum}_{hdbscan_min_cluster_size}_{umap_n_neighbors}_{vec_max_df}_{vec_min_df}_{model_nr_topics}_{ai_model}\"\n",
    "\n",
    "    # Modell speichern\n",
    "    if save_model is True:\n",
    "        try:\n",
    "            topic_model.save(full_path,\n",
    "                            serialization=\"safetensors\",\n",
    "                            save_ctfidf=True,\n",
    "                            save_embedding_model=sentence_transformer)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern des trainierten Modells {model_name}: {e}.\")\n",
    "            pass\n",
    "\n",
    "    return probs, topics, topics_summary, topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ea3c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1770112589770,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "221ea3c6"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Definition zweier Gensim-Coherence-Score-Funktionen als eines zentralen Gütekriterium für die Topic-Modelle\n",
    "# (vgl. Röder Röder, Michael, Andreas Both, und Alexander Hinneburg. „Exploring the space of topic coherence measures“.\n",
    "# Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, 2015)\n",
    "###########################################################################\n",
    "# Dieser Code wurde mit Hilfe von Copilot vervollständigt [KI]\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def gensim_coherence(trained_topic_model: SentenceTransformer, documents: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet den C-V-Score für ein trainiertes BERTopic-Modell.\n",
    "    \"\"\"\n",
    "\n",
    "    topics = trained_topic_model.get_topics()\n",
    "\n",
    "    topic_words = []\n",
    "    for topic_id in topics:\n",
    "        if topic_id != -1:\n",
    "            words = [word for word, _ in trained_topic_model.get_topic(topic_id)[:10]]\n",
    "            topic_words.append(words)\n",
    "\n",
    "    splitted_docs = [doc.lower().split() for doc in documents]\n",
    "\n",
    "    dict = Dictionary(splitted_docs)\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=splitted_docs,\n",
    "        dictionary=dict,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "\n",
    "    score = coherence_model.get_coherence()\n",
    "\n",
    "    return score\n",
    "\n",
    "def gensim_coherence_npmi(trained_topic_model: SentenceTransformer, documents: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet den C-NPMI-Score für ein trainiertes BERTopic-Modell.\n",
    "    \"\"\"\n",
    "\n",
    "    topics = trained_topic_model.get_topics()\n",
    "\n",
    "    topic_words = []\n",
    "    for topic_id in topics:\n",
    "        if topic_id != -1:\n",
    "            words = [word for word, _ in trained_topic_model.get_topic(topic_id)[:10]]\n",
    "            topic_words.append(words)\n",
    "\n",
    "    splitted_docs = [doc.lower().split() for doc in documents]\n",
    "\n",
    "    dict = Dictionary(splitted_docs)\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=splitted_docs,\n",
    "        dictionary=dict,\n",
    "        coherence=\"c_npmi\"\n",
    "    )\n",
    "\n",
    "    score = coherence_model.get_coherence()\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e6789",
   "metadata": {
    "id": "259e6789"
   },
   "source": [
    "## Hyperparameter-Tuning und Grid Search\n",
    "\n",
    "Ab der folgenden Zelle beginnt der _grid search_ im Sinne des _hyperparameter tunings_ im Rahmen einer eigens definierten Funktion.\n",
    "\n",
    "Die Parameter, die in einem bestimmten Wertebereich durchlaufen werden, sind gelistet.\n",
    "\n",
    "Die Ergebnisse aller Modelle und ihrer Parameter werden in einer Tabelle gelistet und gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff3ebb",
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1770112590528,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "65ff3ebb"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Hyperparameter-Tuning\n",
    "###########################################################################\n",
    "\n",
    "# Erstellung der leeren Ergebnisliste\n",
    "ergebnisse = []\n",
    "\n",
    "#########################################################\n",
    "# Hyperparameter-Tuning-Funktion\n",
    "#########################################################\n",
    "\n",
    "def hyperp_tuning(tuple_list: Annotated[tuple, \"Hier werden fünf Variablen übergeben: embedding_model, docs, embeddings, model_name, datum\"],\n",
    "                  hdbscan_cluster_range: list[int] = [15],\n",
    "                  hdbscan_sample_range: list[int] = [5],\n",
    "                  umap_neighbor_range: list[int] = [10],\n",
    "                  cv_mindf_range: list[int] = [4],\n",
    "                  cv_maxdf_range: list[float] = [0.9]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Diese Funktion ist ein systematisches Hyperparamter-Tuning für die drei ausgewählten Sentence-Transformer und verschiedene\n",
    "    Hyperparameter in den folgenden Algorithmen: HDBSCAN, UMAP.\n",
    "\n",
    "    Args:\n",
    "    -\n",
    "\n",
    "    Returns:\n",
    "    - Dataframe mit den Ergebnissen für alle Modelle und Hyperparameter-Ranges\n",
    "    \"\"\"\n",
    "\n",
    "    for a,b,c,d,e in tuple_list:\n",
    "\n",
    "        for umap in umap_neighbor_range:                    # UMAP n-neighbors alternieren lassen\n",
    "\n",
    "            for hdbscan_cluster in hdbscan_cluster_range:   # HDBSCAN min_cluster_size alternieren lassen\n",
    "\n",
    "                for hdbscan_sample in hdbscan_sample_range: # HDBSCAN sample_size alternieren lassen\n",
    "\n",
    "                    for cv_mindf in cv_mindf_range:         # CountVectorizer alternieren lassen\n",
    "\n",
    "                        for cv_maxdf in cv_maxdf_range:     # CountVectorizer alternieren lassen\n",
    "\n",
    "                            probs, topics_all, topics, topic_model = topic_clustering(\n",
    "                                                                                    realm=\"publications\",\n",
    "                                                                                    sentence_transformer=a,\n",
    "                                                                                    docs=b,\n",
    "                                                                                    embeddings=c,\n",
    "                                                                                    stop_words=comprehensive_stopwords,\n",
    "                                                                                    umap_n_neighbors=umap,\n",
    "                                                                                    hdbscan_min_cluster_size=hdbscan_cluster,\n",
    "                                                                                    hdbscan_min_samples=hdbscan_sample,\n",
    "                                                                                    vec_min_df=cv_mindf,\n",
    "                                                                                    vec_max_df=cv_maxdf,\n",
    "                                                                                    save_xlsx = True,\n",
    "                                                                                    save_model=False,\n",
    "                                                                                    model_name=d,\n",
    "                                                                                    datum=e)\n",
    "                            if topics is not None:\n",
    "                                try:\n",
    "                                    ergebnisse.append({\n",
    "                                        \"model\": str(d),\n",
    "                                        \"umap_n_neighbors\": umap,\n",
    "                                        \"hdbscan_min_cluster_size\": hdbscan_cluster,\n",
    "                                        \"hdbscan_min_samples_size\": hdbscan_sample,\n",
    "                                        \"vectorizer_mind_df\": cv_mindf,\n",
    "                                        \"vectorizer_max_df\":cv_maxdf,\n",
    "                                        \"count_topics\": (len(topics)-1),\n",
    "                                        \"relation_outliers\": topics[\"Count\"].iloc[0] / topics[\"Count\"].sum(),\n",
    "                                        \"median_topic_cluster\": topics[\"Count\"][1:].median(),\n",
    "                                        \"average_topic_cluster\": topics[\"Count\"][1:].mean(),\n",
    "                                        \"topic_cluster_sizes\": topics[\"Count\"][1:].tolist(),\n",
    "                                        \"keywords_list\": topics[\"Representation\"][1:].tolist(),\n",
    "                                        \"topic_names\": topics[\"Name\"][1:].tolist(),\n",
    "                                        \"c_v_score\": gensim_coherence(topic_model, b),\n",
    "                                        \"c_npmi_score\": gensim_coherence_npmi(topic_model, b)\n",
    "                                    })\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Fehler bei Modell {str(d)} während des Speicherns der Ergebnisse: {e}.\")\n",
    "                                    pass\n",
    "                            else:\n",
    "                                print(\"Die Topics sind leer oder fehlerhaft. Die Funktion geht zum nächsten Durchlauf.\")\n",
    "\n",
    "                                ergebnisse.append({\n",
    "                                        \"model\": str(d),\n",
    "                                        \"umap_n_neighbors\": umap,\n",
    "                                        \"hdbscan_min_cluster_size\": hdbscan_cluster,\n",
    "                                        \"hdbscan_min_samples_size\": hdbscan_sample,\n",
    "                                        \"vectorizer_mind_df\": cv_mindf,\n",
    "                                        \"vectorizer_max_df\":cv_maxdf,\n",
    "                                        \"count_topics\": 0,\n",
    "                                        \"relation_outliers\": 0,\n",
    "                                        \"median_topic_cluster\": 0,\n",
    "                                        \"average_topic_cluster\": 0,\n",
    "                                        \"topic_cluster_sizes\": 0,\n",
    "                                        \"keywords_list\": 0,\n",
    "                                        \"topic_names\": 0,\n",
    "                                        \"c_v_score\": 0,\n",
    "                                        \"c_npmi_score\": 0\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82165d24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1770112591255,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "82165d24",
    "outputId": "e6ef13d8-23d0-4be2-c5f8-dc10efddab2d"
   },
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# Funktion aufrufen für Grid-Search resp. Hyperparameter-Tuning (wird nur durchgeführt, wenn die Pipeline ausgewählt ist)\n",
    "#############################################################################################\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"Es wird das Hyperparameter-Tuning (Grid-Search) für die Publikationsdaten gestartet.\\n\")\n",
    "\n",
    "    #############################################################################################\n",
    "    # Vorbereitung der Tuple-Liste für die Grid-Search\n",
    "    ##############################################################################################\n",
    "\n",
    "    # Tuple mit den wichtigsten Parametern der geladenen Basismodelle erstellen lassen\n",
    "    tuples_four_models = []\n",
    "    for x,y in model_dict.items():\n",
    "        tuples_four_models.append((y.raw_instance, cleaned_docs, y.embeddings, y.name, datum))\n",
    "\n",
    "    #############################################################################################\n",
    "    # Grid-Search durchführen: Für aktuell 4 Modelle mit 5 Parametern und je 2-4 Werten ergeben sich 4*4*3*3*3*2 = 864 Loops!\n",
    "    #############################################################################################\n",
    "\n",
    "    # Zeit nehmen\n",
    "    start_point = time.time()\n",
    "\n",
    "    # Funktionsaufruf mit den festgelegten Hyperparameter-Wertebereichen\n",
    "    try:\n",
    "        hyperp_tuning(tuple_list=tuples_four_models,\n",
    "                    hdbscan_cluster_range=[20, 40, 60, 80],\n",
    "                    hdbscan_sample_range=[5, 10, 15],\n",
    "                    umap_neighbor_range= [15, 30, 50],\n",
    "                    cv_mindf_range=[2, 3, 5],\n",
    "                    cv_maxdf_range=[0.90, 0.95])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFehler beim Hyper-Tuning: {e}.\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # Ergebnisliste als Dataframe speichern und öffnen\n",
    "        df_ergebnisse = pd.DataFrame(ergebnisse)\n",
    "\n",
    "        df_ergebnisse.to_excel(rf\"{grid_search_dir}/grid_search_results_pubs_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"tuning_results\")\n",
    "        df_ergebnisse.to_csv(rf\"{grid_search_dir}/grid_search_results_pubs_{datum}.csv\", encoding=\"utf-8\")\n",
    "        try:\n",
    "            os.startfile(rf\"{grid_search_dir}/grid_search_results_pubs_{datum}.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Öffnen der Grid-Search-Ergebnisse: {e}.\")\n",
    "            pass\n",
    "\n",
    "        # Laufzeit final ausgeben\n",
    "        end_point = time.time()\n",
    "        dur = round(int((end_point-start_point)/60), 0)\n",
    "        print(f\"Laufzeit des Grid-Search insgesamt etwa {dur} Minuten.\")\n",
    "\n",
    "else:\n",
    "    print(\"Das Hyperparameter-Tuning (Grid-Search) für die Publikationsdaten wird hier nicht durchgeführt.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520869a",
   "metadata": {
    "id": "7520869a"
   },
   "source": [
    "### Auswertung und Evaluation des Grid-Search der Publikationen\n",
    "\n",
    "Die Daten der verschiedenen Modellierungsdurchläufe werden anhand einer Überprüfung der verschiedenen Features ausgewertet, um eine Auswahl der besten Modelle / des besten Modells zu ermöglichen.\n",
    "\n",
    "Zentral dafür sind die Kennzahlen zu den folgenden Bereichen:\n",
    "- Anzahl der gefundenen Themencluster (sollte weder zu klein noch zu groß sein!)\n",
    "- Relative Anzahl an nicht-zuordbaren Dokumenten (sollte möglichst klein sein!)\n",
    "- Relative Anzahl einzigartiger Wörter in den Keyword-Listen (sollte einen hohen Wert haben, aber nicht zu hoch, um einerseits Themenredundanz zu vermeiden und andererseits nicht zu viele distrinkte Einzelthemen zu umfassen!)\n",
    "- Berechneter C-V-Score für die _topic word coherence_\n",
    "- Berechneter U-NPMI-Score  für die  _topic word coherence_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa765d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1770112591675,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "6cfa765d",
    "outputId": "49cf383f-c16b-41af-9f7e-6f822152637b"
   },
   "outputs": [],
   "source": [
    "# Einlesen der Ausgabedatei mit den Ergebnissen des Grid-Search, erste Auswertungen sowie Erstellung\n",
    "# von einem neuen Feature: Keyword Uniquness\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"Es wird die Ausgabedatei der Grid-Search für die Publikationsdaten eingelesen und ausgewertet.\\n\")\n",
    "\n",
    "    # Anzeigeoptionen für Pandas anpassen\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "    # Letzte Grid-Search-Datei finden\n",
    "    try:\n",
    "        grid_files = [x for x in grid_search_dir.glob(\"*\") if x.name.startswith(\"grid_search_results_pubs\")]\n",
    "        latest_grid_file = max(grid_files, key=lambda x: x.stat().st_mtime, default=None)\n",
    "\n",
    "        df_grid_search = pd.read_excel(latest_grid_file, engine=\"openpyxl\")\n",
    "\n",
    "        print(f\"Spalten des DataFrames: {df_grid_search.columns.tolist()}\")\n",
    "        # Output:\n",
    "        # ['Unnamed: 0', 'model', 'umap_n_neighbors', 'hdbscan_min_cluster_size', 'hdbscan_min_samples_size', 'vectorizer_mind_df',\n",
    "        # 'vectorizer_max_df', 'count_topics', 'relation_outliers', 'median_topic_cluster', 'average_topic_cluster',\n",
    "        # 'topic_cluster_sizes', 'keywords_list', 'topic_names', 'c_v_score']\n",
    "        print(\"Länge des Dataframes: \", len(df_grid_search))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Einlesen der Grid-Search-Ergebnisse: {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Umwandlung der Keywords-Listen von Strings in Listen-Objekte\n",
    "    def list_conversion(x):\n",
    "        \"\"\"Liest die Strings aus und wandelt sie in verschachtelte Listen um.\"\"\"\n",
    "\n",
    "        if pd.isna(x) or x is None:\n",
    "            return []\n",
    "\n",
    "        if isinstance(x, str):\n",
    "            return ast.literal_eval(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Anwendung der Funktion auf die Keyword-Spalte\n",
    "    try:\n",
    "        df_grid_search[\"keywords_list\"] = df_grid_search[\"keywords_list\"].apply(list_conversion)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Umwandlung der Keywords-Listen: {e}.\")\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Funktion zur Berechnung der Einzigartigkeit der Keywords\n",
    "    def uniqueness_of_keywords(keywords_list: list[list[str]]) -> float:\n",
    "        \"\"\"\n",
    "        Diese Funktion berechnet den Anteil einzigartiger Keywords in einer Liste von Keyword-Listen.\n",
    "\n",
    "        Args:\n",
    "        - keywords_list = Liste von Listen mit Keywords pro Topic\n",
    "\n",
    "        Returns:\n",
    "        - Anteil einzigartiger Keywords als Float\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(keywords_list, list):     # Sollte durch Vorverarbeitung mit \"list_conversion\" ausgeschlossen sein!\n",
    "            return 0.0\n",
    "\n",
    "        all_keywords = [x for sublist in keywords_list for x in sublist]\n",
    "        unique_keywords = set(all_keywords)\n",
    "\n",
    "        uniqueness_ratio = len(unique_keywords) / (len(all_keywords) if all_keywords else 0)\n",
    "\n",
    "        return uniqueness_ratio\n",
    "\n",
    "    # Anwendung der Funktion auf die Keywords-Spalte\n",
    "    try:\n",
    "        df_grid_search[\"keyword_uniqueness\"] = df_grid_search[\"keywords_list\"].apply(uniqueness_of_keywords)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Berechnung der Keyword-Einzigartigkeit: {e}.\")\n",
    "        pass\n",
    "\n",
    "    # Finaler Check der Ergebnisse\n",
    "    try:\n",
    "        print(\"Kurzer Check des finalen Df mit den neu erstellten Features.\\n\")\n",
    "\n",
    "        # Auswertung des Grid-Search in einigen Kennzahlen nach folgenden Überlegungen:\n",
    "        # 1. Zentral sind die verschiedenen Modelle\n",
    "        # 2. Die Hyperparameter spielen zunächst keine primäre Rolle, sondern nur die Themenergebnisse\n",
    "        # 3. count_topics: Anzahl der Topics ist kritisch und ein Gütemaß für das Modell\n",
    "        # 4. relation_outliers: Ebenfalls kritisch, da das Ausmaß von them. Außenseitern Auskunft über die Breite der Thmene gibt\n",
    "        # 5. topic_cluster_sizes: Werden genutzt, um zu überprüfen, wie gleichverteilt die Themen sind, was die Dokumente angeht\n",
    "        # 6. keywords_list und topic_names: Werden genutzt, um zu überprüfen, wie viele wörtliche Überschneidungen es zwischen den Themen gibt\n",
    "\n",
    "        df_grouped = df_grid_search.groupby(\"model\").agg({\n",
    "            \"count_topics\":[\"mean\", \"min\", \"max\"],\n",
    "            \"relation_outliers\":[\"mean\", \"min\", \"max\"],\n",
    "            #\"topic_cluster_sizes\":\"modus\",\n",
    "            \"c_v_score\": [\"mean\", \"min\", \"max\"],\n",
    "            \"c_npmi_score\": [\"mean\", \"min\", \"max\"],\n",
    "            \"average_topic_cluster\": [\"mean\", \"min\", \"max\"],\n",
    "            \"keyword_uniqueness\": [\"mean\", \"min\", \"max\"]\n",
    "        })\n",
    "\n",
    "        print(f\"Es folgt eine aggregierte Übersicht der Ergebnisse nach den benutzten Modellen:\\n\\n{df_grouped}\")\n",
    "        print(80*\"=\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Ausgabe der Ergebnisse: {e}.\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Die Ausgabedatei der Grid-Search für die Publikationsdaten wird hier nicht eingelesen und ausgewertet.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2139c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1770112592014,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "d9e2139c",
    "outputId": "977545a1-ab53-4a5c-c062-3b9174753eb3"
   },
   "outputs": [],
   "source": [
    "# Auswertung durchführen mit einer Filterung nach den oben benannten Kriterien in zwei Schritten\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "      print(\"\\nEs wird die Auswertung der Grid-Search-Ergebnisse mit Filterkriterien durchgeführt.\\n\")\n",
    "\n",
    "      # Strenge Filterkriterien anwenden, um die besten Modelle zu identifizieren\n",
    "      try:\n",
    "            df_grid_search_filtered_strong = df_grid_search[(df_grid_search[\"count_topics\"] > 15) &    # Die Anzahl der Themencluster sollte über 13 liegen\n",
    "                                                (df_grid_search[\"keyword_uniqueness\"] > 0.80) &        # Die Keywords sollten einen hohen Grad an Einzigartigkeit aufweisen\n",
    "                                                (df_grid_search[\"relation_outliers\"] < 0.05) &         # Die Relation der Outlier sollte unter 10 % liegen\n",
    "                                                (df_grid_search[\"c_v_score\"] > 0.65) &                 # Der c_v-Score sollte im oberen Bereich liegen, hier über 0.5\n",
    "                                                (df_grid_search[\"c_npmi_score\"] > -0.1)               # Der c_npmi-Score sollte nur über 0.0 liegen\n",
    "                                                ]\n",
    "\n",
    "            a1 = len(df_grid_search_filtered_strong[[\"model\", \"count_topics\", \"relation_outliers\", \"c_v_score\", \"keyword_uniqueness\", \"average_topic_cluster\"]])\n",
    "            print(f\"Anzahl der verbleibenden Modelle nach Anwendung der harten Filterkriterien: {a1}.\\n\")\n",
    "            print(df_grid_search_filtered_strong[\"model\"].value_counts())\n",
    "            df_grid_search_filtered_strong_sorted = df_grid_search_filtered_strong.sort_values(by=[\"c_v_score\"], ascending=False)\n",
    "            print(f\"Die besten Modelle sind:\\n\\n{df_grid_search_filtered_strong_sorted}\")\n",
    "            print(80*\"=\")\n",
    "\n",
    "            # Zum Gegentesten: Leichte Lockerung der Filterkriterien, um zu sehen, wie sich das auf die Modelle auswirkt\n",
    "            df_grid_search_filtered_weak = df_grid_search[\n",
    "                                                (df_grid_search[\"count_topics\"] > 10) &             # Reduziert auf 10 Themen\n",
    "                                                (df_grid_search[\"keyword_uniqueness\"] > 0.75) &     # Reduziert auf 0.75\n",
    "                                                (df_grid_search[\"relation_outliers\"] < 0.1) &       # Reduziert auf 10 % Outlier\n",
    "                                                (df_grid_search[\"c_v_score\"] > 0.60) &              # Ein hoher c_v-Score ist relevant!\n",
    "                                                (df_grid_search[\"c_npmi_score\"] > -0.2)             # Reduziert auf 0.05\n",
    "                                                ]\n",
    "\n",
    "            print(f\"\\nModelle mit gelockerten Kriterien: insgesamt {len(df_grid_search_filtered_weak)} Modelle übrig.\\n\")\n",
    "            print(df_grid_search_filtered_weak[\"model\"].value_counts())\n",
    "\n",
    "            # # Ranking der verbleibenden Modelle basierend auf dem c_v_score\n",
    "            print(\"\\nDa bei einer Lockerung der Filterkriterien viele Modelle übrig bleiben, wird nach dem c_v_score absteigend sortiert,\"\n",
    "                  \" um zu erkennen, welche Modelle die Top 5 sind:\\n\")\n",
    "            df_grid_search_filtered_weak_sorted = df_grid_search_filtered_weak.sort_values(by=[\"c_v_score\"], ascending=False)\n",
    "            print(df_grid_search_filtered_weak_sorted.head(10))\n",
    "\n",
    "      except Exception as e:\n",
    "            print(f\"Fehler bei der Filterung der Grid-Search-Ergebnisse: {e}.\")\n",
    "            pass\n",
    "\n",
    "else:\n",
    "      print(\"Die Auswertung der Grid-Search-Ergebnisse mit Filterkriterien wird hier nicht durchgeführt.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09a55a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1770112592266,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "0d09a55a",
    "outputId": "4ff9b26e-9125-4523-9871-b0fb574fada8"
   },
   "outputs": [],
   "source": [
    "# Das beste Modell wird ausgewählt für die weiteren Analysen\n",
    "\n",
    "if grid_search_pipeline is True:\n",
    "    print(\"\\nDas beste Modell wird jetzt für die finale Analyse gespeichert.\\n\")\n",
    "\n",
    "    # Das beste Modell extrahieren\n",
    "    try:\n",
    "        top_models = df_grid_search_filtered_strong.iloc[[0]]\n",
    "        top_models.to_excel(rf\"{grid_search_dir}/top_models_overview_pubs_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"top_models_pubs\")\n",
    "\n",
    "        print(\"\\nTop-Modell bei den Publikationen:\")\n",
    "        print(top_models)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Speichern der Top-Modelle nach Excel: {e}.\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Das beste Modell für die finale Analyse wird hier nicht gespeichert.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231509a2",
   "metadata": {
    "id": "231509a2"
   },
   "source": [
    "### Definition der besten/des besten Modelle/s\n",
    "\n",
    "An dieser Stelle muss entschieden werden, ob das/die beste/n Modell/e in die Modellklasse geladen werden sollen oder nicht (dieser Schritt ist deswegen nicht automatisiert!). Es kann durchaus Gründe geben, mehrere Modelle in die Top-Model-Class zu laden. Üblicherweise wird aber nur das Modell auf Platz 1 genommen.\n",
    "\n",
    "> _Grid Search_ und _Hyperparameter Tuning_ sind damit beendet!\n",
    "\n",
    "Was folgt, ist der Durchlauf für die Evaluation und die Ausgabe der Ergebnisse.\n",
    "\n",
    "---\n",
    "\n",
    "### Zwischenfazit zu den Topics der vier Modelle\n",
    "\n",
    "Der _grid search_ hat Folgendes ergeben:\n",
    "-- TODO Tabelle einfügen --\n",
    "\n",
    "Aufgrund der Metriken, die vor dem Hintergrund der domänenspezifischen Situation interpretiert wurden, ist deutlich geworden, dass nur die Modelle XX mit den Parametern XX zu sinnvollen Ergebnissen führen -- zumindest den Zahlen nach.\n",
    "Diese Modelle wurden lokal gespeichert und werden im Folgenden noch einmal durchlaufen, um mit Unterstützung eines LLMs (dem Modell \"sonnetxx\" von Anthropic) über die Einbindung via LiteLM die entstandenen _topic cluster_ zu interpretieren und ihre Themencluster zu visualisieren.\n",
    "\n",
    "Letztlich soll so ihre Verständlichkeit und Lesbarkeit erhöht werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_7YiQDAGnDtS",
   "metadata": {
    "id": "_7YiQDAGnDtS"
   },
   "source": [
    "## Evaluation auf Basis des besten/der besten Modells/Modelle\n",
    "\n",
    "> Dafür muss die Variable in der zweiten Zelle neu gesetzt werden!\n",
    "\n",
    "Damit der folgende Abschnitt durchlaufen kann, muss\n",
    "(i) in der zweiten Zelle die Variable grid_search auf False gesetzt werden,\n",
    "(ii) die Data Class top_model_dict mit dem Sentence Transformer eingestellt werden, für den man sich entschieden hat (in diesem Fall \"all-Mini\"\n",
    "\n",
    "Die Codezeilen geben dann zunächst die Modellparameter aus und kreieren mit der leeren Instanz Embeddings und schließlich eine trainierte Instanz, die lokal gespeichert wird.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227899d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1770112592829,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "227899d4",
    "outputId": "30d8e8bc-4497-4a38-84dc-6c5efffa4f7d"
   },
   "outputs": [],
   "source": [
    "# Check der Werteauslese der besten Modelle\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Hyperparameter der/des Top-Modelle/Top-Modells werden jetzt ausgegeben.\\n\")\n",
    "\n",
    "    #Finden der zuletzt gespeicherten Datei mit den Top-Modellen\n",
    "    try:\n",
    "        top_model_files = [x for x in grid_search_dir.glob(\"*\") if x.name.startswith(\"top_models_overview_pubs\")]\n",
    "        latest_top_model_file = max(top_model_files, key=lambda x: x.stat().st_mtime, default=None)\n",
    "        top_models = pd.read_excel(latest_top_model_file, engine=\"openpyxl\")\n",
    "\n",
    "        print(\"\\nTop-Modell bei den Publikationen:\")\n",
    "        print(top_models)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim finden der der letzten Top-Modelle in Excel: {e}.\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        for x in top_models[\"model\"].values:\n",
    "            aa=int(top_models[top_models[\"model\"] == x][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "            bb=int(top_models[top_models[\"model\"] == x][\"hdbscan_min_samples_size\"].values[0]),\n",
    "            cc=int(top_models[top_models[\"model\"] == x][\"umap_n_neighbors\"].values[0]),\n",
    "            dd=int(top_models[top_models[\"model\"] == x][\"vectorizer_mind_df\"].values[0]),\n",
    "            ee=float(top_models[top_models[\"model\"] == x][\"vectorizer_max_df\"].values[0])\n",
    "            print(f\"\\n{x}: HDBSCAN min_cluster_size = {aa},\"\n",
    "            f\" HDBSCAN min_sample_size = {bb}, UMAP n_neighbors = {cc},\"\n",
    "            f\" Vectorizer min_df = {dd}, Vectorizer max_df = {ee}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Ausgabe der Hyperparameter der Top-Modelle: {e}.\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yLLbMWq76dS5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "8b9538c5c6d44c179064701fff51d6f1",
      "8615a6a6397a488a8a831eaa3dde26ed",
      "9a9a342e98d040feb56ffc453701e35d",
      "687c4ea946c9462ab3af5407436b9e91",
      "1c973315221a4965b94102bda928677a",
      "0bc91addb0f34d7f9c17b474090e6501",
      "a86462277bc54ec6a006ac183263cfa6",
      "efddee3852a241bca0ebf255739909ff",
      "c3e18a4f2dab4747a70012e2b22f2350",
      "96eb63f7c50f48979ddc966657f68a0b",
      "5b4f709b0efd422396b402b8ee00f986"
     ]
    },
    "executionInfo": {
     "elapsed": 7017,
     "status": "ok",
     "timestamp": 1770112599975,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "yLLbMWq76dS5",
    "outputId": "43bf9554-de9b-41bf-c3d0-e42cba9ab595"
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Prüfung der Top-Modell-Dataclass mit anschließendem Aufruf der Embeddings\n",
    "#######################################################################\n",
    "\n",
    "if using_top_models is True:\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"Die Top-Modell-Dataclass hält aktuell folgende Modelle:\\n\")\n",
    "        print(y.name)\n",
    "\n",
    "# Suchen und Laden der Embeddings -- falls vorhanden, ansonsten werden diese noch einmal\n",
    "# erstellt\n",
    "\n",
    "##########################################\n",
    "# Funktion zum Check auf lokale Embeddings\n",
    "##########################################\n",
    "\n",
    "def check_local_embeddings_list(model_dict: dict) -> list:\n",
    "    \"\"\"Diese Funktion checkt, ob für alle Modelle im übergebenen Dict Embeddings\n",
    "    lokal vorhanden sind.\n",
    "\n",
    "    Args:\n",
    "    - model_dict = Dict mit den Modellen\n",
    "\n",
    "    Returns:\n",
    "    - list: Gibt eine Liste der Modelle zurück, für die keine Embeddings gefunden werden\n",
    "    konnten.\n",
    "    \"\"\"\n",
    "\n",
    "    not_exist = []\n",
    "\n",
    "    for x,y in model_dict.items():\n",
    "        if y.embeddings is None:\n",
    "            print(f\"Für das Modell {y.name} sind keine lokalen Embeddings vorhanden.\")\n",
    "            not_exist.append(y.name)\n",
    "        else:\n",
    "            print(f\"Für das Modell {y.name} sind lokale Embeddings vorhanden.\")\n",
    "\n",
    "    return not_exist\n",
    "\n",
    "# Funktionsaufruf\n",
    "if using_top_models is True:\n",
    "    list_no_embedds = check_local_embeddings_list(top_model_dict)\n",
    "\n",
    "    if not list_no_embedds:\n",
    "        print(\"Alle Top-Modelle aus der Data Class haben lokale Embeddings geladen.\")\n",
    "    else:\n",
    "        print(\"\\nFolgende Modelle haben keine geladenen Embeddings: {}.\".format(str(list_no_embedds)))\n",
    "        print(\"\\nDiese Embeddings werden noch einmal erstellt!\")\n",
    "\n",
    "        # Funktinausfruf zum Erstellen und Speichern der Embeddings oder zum Laden, falls Datei vorhanden\n",
    "        create_or_load_embeddings(\"publications\", cleaned_docs, top_model_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55047348",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13817,
     "status": "ok",
     "timestamp": 1770112613676,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "55047348",
    "outputId": "9d2105fb-fefe-4407-aaa2-e7715448f95d"
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Funktionsuafurf des Topic CLusterings mit Einbindung von ChatGPT im Representation-Model\n",
    "# Quelle: https://maartengr.github.io/BERTopic/getting_started/representation/llm.html#litellm\n",
    "# (Anm.: Der Api-Key wird oben schon definiert!)\n",
    "#######################################################################\n",
    "# Folgende Schritte werden durchlaufen:\n",
    "# 1. Modelle werden trainiert und gespeichert -- mit den besten Parametern aus dem Grid-Search und Anthropic als LLM im representation model\n",
    "# 2. Grafische Auswertung der Topic Clusterings mithilfe der in Bertopic integrierten Visualisierungsfunktionen\n",
    "# 3. Detaillierte Analyse der Topic Clusterings und deren Keywords\n",
    "\n",
    "# Funktionsaufruf mit den besten Parametern und den beiden besten Modellen\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "\n",
    "    # Liste zur Speicherung der Ergebnisse der besten Modelle und Entscheidung über die Nutzung von OpenAI-Einbindung\n",
    "    ergebnisse_best_models = []\n",
    "    ai_model = \"open_ai\"   # \"open_ai\" oder None\n",
    "\n",
    "    if using_top_models is True:                # Nur, wenn die besten Modelle genutzt werden sollen\n",
    "\n",
    "        for x, y in top_model_dict.items():\n",
    "\n",
    "            if y.embeddings is not None:        # Check, ob die Embeddings geladen wurden\n",
    "\n",
    "                print(f\"\\nDas Topic Modeling wird jetzt mit dem Modell \\\"{y.name}\\\" und ChatGPT als LLM im Representation-Model durchgeführt.\")\n",
    "\n",
    "                try:\n",
    "\n",
    "                    _, y.doc_topics_assignment, y.final_topics_df, y.trained_instance = topic_clustering(\n",
    "                                                                                                realm=\"publications\",\n",
    "                                                                                                sentence_transformer=y.raw_instance,\n",
    "                                                                                                docs=cleaned_docs,\n",
    "                                                                                                embeddings=y.embeddings,\n",
    "                                                                                                stop_words=comprehensive_stopwords,\n",
    "                                                                                                hdbscan_min_cluster_size=int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                                                                                                hdbscan_min_samples=int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                                                                                                umap_n_neighbors=int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                                                                                                vec_min_df=int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                                                                                                vec_max_df=float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                                                                                                save_xlsx=True,\n",
    "                                                                                                model_name=y.name,\n",
    "                                                                                                datum=datum,\n",
    "                                                                                                ai_model=ai_model,\n",
    "                                                                                                save_model=True)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Fehler beim Topic Modeling mit dem Modell {y.name} und ChatGPT als LLM: {e}.\")\n",
    "                    pass\n",
    "\n",
    "                if y.final_topics_df is not None:\n",
    "                    try:\n",
    "                        ergebnisse_best_models.append({\n",
    "                            \"model\": str(y.name),\n",
    "                            \"umap_n_neighbors\": int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                            \"hdbscan_min_cluster_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                            \"hdbscan_min_samples_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                            \"vectorizer_mind_df\": int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                            \"vectorizer_max_df\": float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                            \"count_topics\": (len(y.final_topics_df)-1),\n",
    "                            \"relation_outliers\": y.final_topics_df[\"Count\"].iloc[0] / y.final_topics_df[\"Count\"].sum(),\n",
    "                            \"median_topic_cluster\": y.final_topics_df[\"Count\"][1:].median(),\n",
    "                            \"average_topic_cluster\": y.final_topics_df[\"Count\"][1:].mean(),\n",
    "                            \"topic_cluster_sizes\": y.final_topics_df[\"Count\"][1:].tolist(),\n",
    "                            \"keywords_list\": y.final_topics_df[\"Representation\"][1:].tolist(),\n",
    "                            \"topic_names\": y.final_topics_df[\"Name\"][1:].tolist(),\n",
    "                            \"topic_names_AI\": y.final_topics_df[\"ChatGPT_titles\"][1:].tolist() if ai_model == \"open_ai\" else None,\n",
    "                            \"topic_summaries_AI\": y.final_topics_df[\"ChatGPT\"][1:].tolist() if ai_model == \"open_ai\" else None,\n",
    "                            # \"topic_names_KeyBERT\": y.final_topics_df[\"Main\"][1:].tolist(),\n",
    "                            \"c_v_score\": gensim_coherence(y.trained_instance, cleaned_docs),\n",
    "                            \"c_npmi_score\": gensim_coherence_npmi(y.trained_instance, cleaned_docs)\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Fehler bei Modell {str(y.name)} während des Speicherns der Ergebnisse: {e}.\")\n",
    "                        pass\n",
    "                else:\n",
    "                    print(\"Die Topics sind leer oder fehlerhaft. Die Funktion geht zum nächsten Durchlauf.\")\n",
    "\n",
    "                    ergebnisse_best_models.append({\n",
    "                            \"model\": str(y.name),\n",
    "                            \"umap_n_neighbors\": int(top_models[top_models[\"model\"] == y.name][\"umap_n_neighbors\"].values[0]),\n",
    "                            \"hdbscan_min_cluster_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_cluster_size\"].values[0]),\n",
    "                            \"hdbscan_min_samples_size\": int(top_models[top_models[\"model\"] == y.name][\"hdbscan_min_samples_size\"].values[0]),\n",
    "                            \"vectorizer_mind_df\": int(top_models[top_models[\"model\"] == y.name][\"vectorizer_mind_df\"].values[0]),\n",
    "                            \"vectorizer_max_df\": float(top_models[top_models[\"model\"] == y.name][\"vectorizer_max_df\"].values[0]),\n",
    "                            \"count_topics\": 0,\n",
    "                            \"relation_outliers\": 0,\n",
    "                            \"median_topic_cluster\": 0,\n",
    "                            \"average_topic_cluster\": 0,\n",
    "                            \"topic_cluster_sizes\": 0,\n",
    "                            \"keywords_list\": 0,\n",
    "                            \"topic_names\": 0,\n",
    "                            \"topic_names_AI\": 0,\n",
    "                            \"topic_summaries_AI\": 0,\n",
    "                            # \"topic_names_KeyBERT\": 0,\n",
    "                            \"c_v_score\": 0,\n",
    "                            \"c_npmi_score\": 0\n",
    "                        })\n",
    "\n",
    "                print(80*\"=\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Die Embeddings für das Modell {y.name} wurden nicht geladen.\")\n",
    "                pass\n",
    "\n",
    "        # Ergebnisse der besten Modelle speichern\n",
    "        df_ergebnisse_best_models = pd.DataFrame(ergebnisse_best_models)\n",
    "        df_ergebnisse_best_models.to_excel(rf\"{grid_search_dir}/best_models_results_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"best_model_results\")\n",
    "        try:\n",
    "            os.startfile(rf\"{grid_search_dir}/best_models_results_{datum}.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Öffnen der Exceldatei! Evtl. OS-Modul vorhanden.\")\n",
    "    else:\n",
    "        print(\"Die besten Modelle wurden nicht geladen! BItte erste Zelle prüfen.\")\n",
    "\n",
    "    # Checks\n",
    "    print(f\"Länge der Docs: {len(cleaned_docs)}.\")\n",
    "    for x,y in top_model_dict.items():\n",
    "        try:\n",
    "            print(f\"Länge der Topics: {len(y.doc_topics_assignment)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler in der Auswertung der Länge: {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39807b2",
   "metadata": {
    "id": "a39807b2"
   },
   "source": [
    "### Graphische Auswertungen der Publikationen\n",
    "\n",
    "Die ausgewählten Modelle sind erstellt, gespeichert und in der Modellklasse geladen.\n",
    "\n",
    "In diesem Teil wird eine Funktion erstellt und dann aufgerufen, die automatisch verschiedenen Visualisierungen der Topic-Cluster erstellt, ausgibt und lokal speichert.\n",
    "\n",
    "Eine Interpretation der Ergebnisse erfolgt zum Abschluss des Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4db229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1770112614030,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "bd4db229",
    "outputId": "c26695c7-35f7-473e-8da5-06a7601639f3"
   },
   "outputs": [],
   "source": [
    "# Check auf korrekte befüllte Modellklassen\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nEs wird ein Check der befüllten Modellklassen der Top-Modelle durchgeführt.\\n\")\n",
    "\n",
    "    try:\n",
    "        for x, y in top_model_dict.items():\n",
    "            print(f\"\\nModell: {y.name}\")\n",
    "            print(f\"Document-Topic-Zuweisungen: {type(y.doc_topics_assignment)}\")\n",
    "            print(f\"Länge der Document-Topic-Zuweisung: {len(y.doc_topics_assignment)}\")\n",
    "            print(f\"Finales Topic-Df: {type(y.final_topics_df)}\")\n",
    "            print(f\"Länge des finalen Topic-Df: {len(y.final_topics_df)-1}\") # Outlier müssen herausgenommen werden!\n",
    "            print(f\"Trainiertes Modell: {type(y.trained_instance)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Check der Modellklassen: {e}.\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d33ee",
   "metadata": {
    "executionInfo": {
     "elapsed": 175,
     "status": "ok",
     "timestamp": 1770112614315,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "f22d33ee"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Funktion definieren für insg. sieben Visualisierungen\n",
    "###########################################################\n",
    "\n",
    "def visuals_per_topic_model(\n",
    "    realm: str,\n",
    "    topic_model: Annotated[object, \"Hier muss das trainierte topic.model übergeben werden\"],\n",
    "    docs: list[str],\n",
    "    top_n_topics: int = 10,\n",
    "    n_words: int = 10,\n",
    "    model_name: str | None = None,\n",
    "    embeddings: np.ndarray | None = None,\n",
    "    sample_documents: list | None = None,\n",
    "    visualizations: Annotated[list[str], \"Eine Auswahl aus heatmap, topics, barchart, term_rank, hierarchy, documents, hierarchical_documents]\"] = None,\n",
    "    show_visuals: bool = False\n",
    ") -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Sammelfunktion, um die graphischen Auswertungen zu den Topic-Clustern zu erstellen und lokal zu speichern!\n",
    "\n",
    "    Args:\n",
    "    - ...\n",
    "\n",
    "    Returns:\n",
    "    - Dict der erstellen Plots\n",
    "    \"\"\"\n",
    "\n",
    "    # Ordner Set Up mit Pathlib\n",
    "    current_dir = Path.cwd()\n",
    "    target_folder = current_dir.parent / \"01_data\" / \"03_topic_modeling\"\n",
    "    topic_visuals_folder = target_folder / \"03_topic_visuals\"\n",
    "\n",
    "    # Zielordner checken (relativ zum Notebook)\n",
    "    try:\n",
    "        if Path(topic_visuals_folder).exists():\n",
    "            print(f\"Ordner \\\"{str(topic_visuals_folder)}\\\" vorhanden.\")\n",
    "        else:\n",
    "            print(f\"Ordner \\\"{str(topic_visuals_folder)}\\\" nicht vorhanden. Der Ordner wird im folgenden Schritt erstellt werden.\")\n",
    "            topic_visuals_folder.mkdir(parents=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Aufgrund eines Fehlers konnte nicht weiter verfahren werden: {e}.\")\n",
    "    print(80*\"=\")\n",
    "\n",
    "    # Dict initialisieren, um die Visualisierungen zu speichern!\n",
    "    figures = {}\n",
    "\n",
    "    if visualizations is None:\n",
    "        visualizations = [\"heatmap\", \"topics\", \"barchart\", \"term_rank\",\n",
    "                         \"hierarchy\", \"documents\", \"hierarchical_documents\"]\n",
    "\n",
    "    ###########################################################################\n",
    "    # 1. Topic Heatmap\n",
    "    ###########################################################################\n",
    "    if \"heatmap\" in visualizations:\n",
    "        try:\n",
    "            print(\"1. Topic Heatmap erstellen.\")\n",
    "\n",
    "            # Plot erstellen!\n",
    "            fig = topic_model.visualize_heatmap()\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"heatmap\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/heatmap_{realm}_{model_name}_{datum}\"\n",
    "            fig.write_html(rf\"{path}.html\")\n",
    "            try:\n",
    "                fig.write_image(rf\"{path}.png\")\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido Version ist vorhanden!): {e}\")\n",
    "            # Plot ausgeben lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 2. 2D Topic Map\n",
    "    ###########################################################################\n",
    "    if \"topics\" in visualizations:\n",
    "        try:\n",
    "            print(\"2. Topic Map erstellen.\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_topics(width=1200, height=800)\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"topics\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/topic-map_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 3. Topic Words Bar Chart\n",
    "    ###########################################################################\n",
    "    if \"barchart\" in visualizations:\n",
    "        try:\n",
    "            print(\"3. Topic Barchart erstellen.\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_barchart(\n",
    "                top_n_topics=top_n_topics,\n",
    "                n_words=n_words,\n",
    "                height=500\n",
    "            )\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"barchart\"] = fig\n",
    "\n",
    "            # Ergebnis speichern\n",
    "            path = rf\"{topic_visuals_folder}/bar-chart-words_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 4. Term Rank Plot\n",
    "    ###########################################################################\n",
    "    if \"term_rank\" in visualizations:\n",
    "        try:\n",
    "            print(\"4. Term Ranking erstellen\")\n",
    "\n",
    "            # Plot erstellen\n",
    "            fig = topic_model.visualize_term_rank(log_scale=True)\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"term_rank\"] = fig\n",
    "\n",
    "            # Plot speichern und anzeigen lassen\n",
    "            path = rf\"{topic_visuals_folder}/term-rank_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Plot gespeichert: \\\"{path}\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler \\\"{e}\\\".\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 5. Hierarchical Topic Structure\n",
    "    ###########################################################################\n",
    "    if \"hierarchy\" in visualizations:\n",
    "        try:\n",
    "            print(\"5. Topic Hierarchy erstellen.\")\n",
    "\n",
    "            # Hierarchie erzeugen\n",
    "            hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "            # Plot erstellen lassen\n",
    "            fig = topic_model.visualize_hierarchy(\n",
    "                hierarchical_topics=hierarchical_topics,\n",
    "                width=1200,\n",
    "                height=800\n",
    "            )\n",
    "\n",
    "            # Plot dem Dict zuweisen\n",
    "            figures[\"hierarchy\"] = fig\n",
    "\n",
    "            path = rf\"{topic_visuals_folder}/hierarchy_{realm}_{model_name}_{datum}.html\"\n",
    "            fig.write_html(path)\n",
    "            try:\n",
    "                fig.write_image(path.replace(\".html\", \".png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "            # Plot anzeigen lassen\n",
    "            if show_visuals is True:\n",
    "                fig.show()\n",
    "\n",
    "            print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            # Speichern:\n",
    "            tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "            tree_path = rf\"{topic_visuals_folder}/topic-tree_{realm}_{model_name}_{datum}.html\"\n",
    "            with open(tree_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(tree)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "            print(f\"Gespeichert: \\\"{tree_path}\\\".\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler: {e}\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 6. Document Distribution\n",
    "    ###########################################################################\n",
    "    if \"documents\" in visualizations:\n",
    "        if embeddings is not None:\n",
    "            try:\n",
    "                print(\"6. Dokumenten-Karte erstellen.\")\n",
    "\n",
    "                # Plot erstellen\n",
    "                fig = topic_model.visualize_documents(\n",
    "                    docs,\n",
    "                    embeddings=embeddings,\n",
    "                    sample=sample_documents,\n",
    "                    width=1500,\n",
    "                    height=1000\n",
    "                )\n",
    "\n",
    "                # Plot dem Dict zuweisen\n",
    "                figures[\"documents\"] = fig\n",
    "\n",
    "                path = rf\"{topic_visuals_folder}/doc-map-2D_{realm}_{model_name}_{datum}.html\"\n",
    "                fig.write_html(path)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido 0.2.1 ist aber vorhanden!): {e}\")\n",
    "\n",
    "                # Plot anzeigen lassen\n",
    "                if show_visuals is True:\n",
    "                    fig.show()\n",
    "\n",
    "                print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler: {e}\")\n",
    "        else:\n",
    "            print(\"6. Da keine Embeddings übergeben wurden, konnte nicht geplottet werden.\")\n",
    "\n",
    "    ###########################################################################\n",
    "    # 7. Hierarchical Document Visualization\n",
    "    ###########################################################################\n",
    "    if \"hierarchical_documents\" in visualizations:\n",
    "        if embeddings is not None:\n",
    "            try:\n",
    "                print(\"7. Dokumenten-Karte in 2D nach Hierarchie erstellen.\")\n",
    "\n",
    "                # Check, ob die Hierarchie schon erstellt wurde\n",
    "                if \"hierarchy\" not in figures:\n",
    "                    hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "                # Plot erstellen\n",
    "                fig = topic_model.visualize_hierarchical_documents(\n",
    "                    docs,\n",
    "                    hierarchical_topics=hierarchical_topics,\n",
    "                    embeddings=embeddings,\n",
    "                    sample=sample_documents,\n",
    "                    width=1500,\n",
    "                    height=1000\n",
    "                )\n",
    "\n",
    "                # Plot dem Dict zuweisen\n",
    "                figures[\"hierarchical_documents\"] = fig\n",
    "\n",
    "                # Plotten und anzeigen lassen\n",
    "                path = rf\"{topic_visuals_folder}/hier-doc-map-2D_{realm}_{model_name}_{datum}.html\"\n",
    "                fig.write_html(path)\n",
    "                try:\n",
    "                    fig.write_image(path.replace(\".html\", \".png\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"PNG-Export fehlgeschlagen (kaleido >=1.0.0 ist aber vorhanden!): {e}\")\n",
    "\n",
    "                # Plot anzeigen lassen\n",
    "                if show_visuals is True:\n",
    "                    fig.show()\n",
    "\n",
    "                # Speichern\n",
    "                print(f\"Gespeichert: \\\"{path}\\\".\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler: \\\"{e}\\\".\")\n",
    "\n",
    "        else:\n",
    "            print(\"7. Da keine Embeddings übergeben wurden, konnte nicht geplottet werden.\")\n",
    "\n",
    "    print(f\"\\nAuswertung: Es wurden insgesamt {len(figures)} Plots erstellen und in folgendem Ordner gespeichert: {topic_visuals_folder}.\\n\")\n",
    "\n",
    "    return figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bf069",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16772,
     "status": "ok",
     "timestamp": 1770112631269,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "7e7bf069",
    "outputId": "51940fc5-d541-4eaf-8563-0df124136727"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Visualisierungsfunktion aufrufen für das beste Modell\n",
    "# (Es kann sinnvoll sein, vorzuentscheiden, ob die Visualisierungen\n",
    "#  erstellt werden sollen oder nicht, da dies Zeit in Anspruch nimmt [s. Parameter show_visuals]!)\n",
    "###########################################################\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Visualisierungen für die Top-Modelle werden jetzt erstellt und gespeichert.\\n\")\n",
    "\n",
    "    # Dict initialisieren, um die Visualisierungen zu speichern\n",
    "    figures_dict = {}\n",
    "\n",
    "    for x,y in top_model_dict.items():\n",
    "\n",
    "        figures_pubs = visuals_per_topic_model(\n",
    "                                realm=\"publications\",\n",
    "                                topic_model=y.trained_instance,\n",
    "                                docs=cleaned_docs,\n",
    "                                embeddings=y.embeddings,\n",
    "                                model_name=y.name,\n",
    "                                show_visuals=False\n",
    "                            )\n",
    "\n",
    "        figures_dict[y.name] = figures_pubs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e40c22",
   "metadata": {
    "id": "46e40c22"
   },
   "source": [
    "## Dynamisches Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99486078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1770112631508,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "99486078",
    "outputId": "815ee462-0816-436a-d3c7-50a7c9efb81e"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Dynamisches Topic Modeling nach Jahren\n",
    "# Quelle: https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#bins\n",
    "###########################################################\n",
    "\n",
    "# Vorverarbeitung der Jahresdaten, angepasst an die unterschiedlichen, in den Rohdaten vorhandenen Formate\n",
    "# Diese Funktion wurde mit Hilfe von Copilot komplettiert und dann erfolgreich gestestet! [KI]\n",
    "def extract_year(date_str):\n",
    "    \"\"\"Hier werden die unterschiedlichen Formate, wie sie in den Daten vorhanden waren, passend aufbereitet.\"\"\"\n",
    "\n",
    "    date_str = str(date_str).strip()\n",
    "\n",
    "    if len(date_str) == 4 and date_str.isdigit():\n",
    "        return int(date_str)\n",
    "\n",
    "    if \"-\" in date_str:\n",
    "        return int(date_str.split(\"-\")[0])\n",
    "\n",
    "    if \".\" in date_str:\n",
    "        return int(date_str.split(\".\")[-1])\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Datenvorvereitung mit den Jahresdaten mit dem ursprünglichen Dataframe\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie Jahresdaten für das dynamische Topic Modeling werden jetzt vorbereitet.\\n\")\n",
    "\n",
    "    df_all_copy = df_all.copy()\n",
    "    print(df_all_copy.columns)\n",
    "\n",
    "    df_all_copy[\"publication_year\"] = df_all_copy[\"publication_date\"].apply(extract_year)\n",
    "    df_all_copy[\"publication_year\"] = df_all_copy[\"publication_year\"].astype(int)\n",
    "    df_all_copy.loc[df_all_copy[\"publication_year\"] == 1987, \"publication_year\"] = 2016\n",
    "    df_all_copy.loc[df_all_copy[\"publication_year\"] == 2013, \"publication_year\"] = 2015\n",
    "    df_all_copy.loc[df_all_copy[\"publication_year\"] == 2014, \"publication_year\"] = 2015\n",
    "    date_list = df_all_copy[\"publication_year\"].tolist()\n",
    "\n",
    "    df_aggre = df_all_copy.groupby(\"publication_year\")[\"title\"].count()\n",
    "    print(df_aggre)\n",
    "\n",
    "    # Check der Längen\n",
    "    print(f\"Dokumente zu Datumsangaben passend = {len(date_list) == len(cleaned_docs)}.\")\n",
    "\n",
    "    print(f\"Länge der Jahresangaben = {len(date_list)}.\")\n",
    "    print(f\"Jahreszeitraum: {min(date_list)} - {max(date_list)}\")\n",
    "    print(f\"Verteilung der Jahresdaten:\\n{sorted(set(date_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439460d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6641,
     "status": "ok",
     "timestamp": 1770112638301,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "439460d6",
    "outputId": "c98ba5e7-b4cd-4822-c426-df13c098bc1e"
   },
   "outputs": [],
   "source": [
    "# Aufruf der BERTopic-Funktion für dynamisches Topic Modeling mit den besten Modellen\n",
    "# (Anm.: Die Berechnung dauert bis zu 25 Minuten für zwei Graphen!)\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDas dynamische Topic Modeling für die Top-Modelle wird jetzt durchgeführt und die Graphen werden ausgegeben.\\n\")\n",
    "\n",
    "    for x, y in top_model_dict.items():\n",
    "        topics_over_time = y.trained_instance.topics_over_time(\n",
    "                                                        docs=cleaned_docs,\n",
    "                                                        timestamps=date_list,\n",
    "                                                        #datetime_format=\"%Y\",\n",
    "                                                        nr_bins=len(set(date_list))\n",
    "                                                        )\n",
    "\n",
    "        fig = y.trained_instance.visualize_topics_over_time(topics_over_time)\n",
    "        fig.write_html(rf\"{topic_visuals_dir}/dynamic_topic_modeling_{y.name}_{datum}.html\")\n",
    "        try:\n",
    "            fig.write_image(rf\"{topic_visuals_dir}/dynamic_topic_modeling_{y.name}_{datum}.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"PNG-Export fehlgeschlagen: {e}\")\n",
    "\n",
    "        print(f\"Graph für {y.name} wurde erfolgreich gespeichert.\")\n",
    "\n",
    "else:\n",
    "    print(\"Das dynamische Topic Modeling wird hier nicht durchgeführt.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f6971",
   "metadata": {
    "id": "476f6971"
   },
   "source": [
    "## Rückschreibung der Ergebnisse an die PIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68965bcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1770112638957,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "68965bcf",
    "outputId": "616995be-2269-47d8-fc39-28c63fdb28bd"
   },
   "outputs": [],
   "source": [
    "# Gesamt-Dataframe erweitern: Erstellte Topics werden Publikationen/Drittmitteln\n",
    "# und PIs zugeordnet.\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie erstellten Topics der Top-Modelle werden jetzt den Publikationen im Dataframe zugeordnet.\\n\")\n",
    "\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "    ##########################################################################################\n",
    "    # Publikationen\n",
    "    ##########################################################################################\n",
    "\n",
    "    # 1.1 Themencluster zuordnen in den ursprünglichen Dataframe. D.h., dass die im Df vorhanden Publikationen\n",
    "    # die zugehörigen Topic-Nummern erhalten\n",
    "    print(df_all.columns)\n",
    "    print(f\"Länge des Dataframes: {len(df_all)}.\")\n",
    "    print(f\"Länge der Dokumente: {len(cleaned_docs)}.\")\n",
    "\n",
    "    # Über Modelclass iterieren (nur die besten Modelle)\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"\\nDokument-Topic-Zuweisungen für Modell \\\"{y.name}\\\" werden dem Dataframe hinzugefügt.\")\n",
    "        df_all[f\"topic_assignment_{y.name}\"] = y.doc_topics_assignment\n",
    "\n",
    "    # 1.2 Themen und Keywords zuordnen in den ursprünglichen Dataframe\n",
    "    for x,y in top_model_dict.items():\n",
    "\n",
    "        # Topic-Dataframe holen\n",
    "        y.final_topics_df = y.trained_instance.get_topic_info()\n",
    "\n",
    "        # Dicts erstellen, die Topic-Namen und Keywords zu den Topic-Nummern zuordnen\n",
    "        print(f\"\\nThemen und Keywords für Modell \\\"{y.name}\\\" werden dem Dataframe hinzugefügt.\")\n",
    "        topic_names = y.final_topics_df.set_index(\"Topic\")[\"Name\"].to_dict()\n",
    "        topic_keywords = y.final_topics_df.set_index(\"Topic\")[\"Representation\"].to_dict()\n",
    "\n",
    "        df_all[f\"topic_name_{y.name}\"] = df_all[f\"topic_assignment_{y.name}\"].map(topic_names)\n",
    "        df_all[f\"topic_keywords_{y.name}\"] = df_all[f\"topic_assignment_{y.name}\"].map(topic_keywords)\n",
    "\n",
    "    print(f\"\\nNeue Spalten Publikationen: {df_all.columns}.\")\n",
    "    df_all.head()\n",
    "\n",
    "else:\n",
    "    print(\"Die erstellten Topics der Top-Modelle werden hier nicht den Publikationen zugeordnet.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609c527",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1770112640320,
     "user": {
      "displayName": "Felix Beuing",
      "userId": "09553433238687658446"
     },
     "user_tz": -60
    },
    "id": "7609c527",
    "outputId": "dde8ed70-800e-48f1-98b0-b7efbf31a658"
   },
   "outputs": [],
   "source": [
    "# Nachdem nun die Ergebnisse des Topic Modelings der Publikationen vorliegen und damit auch den\n",
    "# PIs zugeordnet wurden, erfolgt die aggregierte Informationsauswertung. Diese Auswertung wiederum\n",
    "# wird dem PI-Dataframe hinzugefügt und gespeichert.\n",
    "\n",
    "# Der Auswertungsfokus liegt auf den Fragen:\n",
    "# 1. Wie viele Topics sind den jeweiligen PIs zugeordnet (Themendiversität)?\n",
    "# 2. Wie ist die Verteilung der Topics bei den jeweiligen PIs? Und was sind die drei Hauptthemen?\n",
    "##########################################################################################\n",
    "# Publikationen (Diese Auswertung wurde durch die Hilfe von Copilot reduziert und optimiert! [KI])\n",
    "##########################################################################################\n",
    "\n",
    "if evaluation_pipeline is True:\n",
    "    print(\"\\nDie aggregierten Metriken für PIs aus den Publikationen werden jetzt erstellt und gespeichert.\\n\")\n",
    "\n",
    "    for x,y in top_model_dict.items():\n",
    "        print(f\"\\nAggregierte Metriken für PIs aus Publikationen werden für Modell \\\"{y.name}\\\" erstellt.\\n\")\n",
    "\n",
    "        # Anonymisierung der PI-Namen im Dataframe\n",
    "        pi_df = pd.read_csv(rf\"{base_dir}/01_data/01_csv_data/00_pi_basics/FINALLY_ALL_pi_data.csv\", encoding=\"utf-8\")\n",
    "        pi_hash_dict = pi_df.set_index(\"nachname\")[\"pi_name_hashed\"].to_dict()\n",
    "        \n",
    "        df_all[\"source\"] = df_all[\"source\"].map(pi_hash_dict)\n",
    "\n",
    "        # Aggregation der Metriken pro PI\n",
    "        pi_metrics = df_all.groupby(\"source\").agg(\n",
    "            topic_count=(f\"topic_assignment_{y.name}\", \"nunique\"),\n",
    "            total_pubs=(f\"topic_assignment_{y.name}\", \"size\")\n",
    "        ).reset_index()\n",
    "\n",
    "        # Top 3 Themen\n",
    "        pi_metrics[\"top3_topics_nr\"] = df_all.groupby(\"source\")[f\"topic_assignment_{y.name}\"].apply(\n",
    "            lambda x: x.value_counts().head(3).index.tolist()).values\n",
    "        pi_metrics[\"top3_topics_title\"] = df_all.groupby(\"source\")[f\"topic_name_{y.name}\"].apply(\n",
    "            lambda x: [x for x in x.value_counts().head(3).index.tolist()]).values\n",
    "\n",
    "        # Speichern als csv\n",
    "        pi_metrics.to_csv(rf\"{topic_results_dir}/pi_publication_metrics_{y.name}_{datum}.csv\", index=False, encoding=\"utf-8\")\n",
    "        pi_metrics.to_excel(rf\"{topic_results_dir}/pi_publication_metrics_{y.name}_{datum}.xlsx\",\n",
    "                            engine=\"openpyxl\", sheet_name=\"pi_metrics\")\n",
    "\n",
    "    print(pi_metrics)\n",
    "\n",
    "else:\n",
    "    print(\"Die aggregierten Metriken für PIs aus den Publikationen werden hier nicht erstellt und gespeichert.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810fadb",
   "metadata": {
    "id": "c810fadb"
   },
   "source": [
    "## Abschluss\n",
    "\n",
    "Die Ergebnisse dieser Analyse werden in der Arbeit dargestellt und im Kontext der Forschungsfragen bewertet."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001e44680e4c4fae87ea4ae9e0323227": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "006294675d3941458f54fd12cf2826af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0361a1cbed894fe49e47b5a1164250f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06dc79abdaf54fd4874a95e8b15b10a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_547516fa6c814160a671ce5e21855c4f",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a72773701f54e2cad530f409c5cd1c3",
      "value": 349
     }
    },
    "092f642e4feb48b58db627031c80a5ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f07c489ee664a4d8ffbbe92ac969cab",
      "placeholder": "​",
      "style": "IPY_MODEL_5cd3bf01885d4e73abafdca6030ddc69",
      "value": " 190/190 [00:00&lt;00:00, 24.1kB/s]"
     }
    },
    "09c2ed0a73064af0aded60394b07bd45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3c58e28774a440588a562b82ff44737",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f4f6b7d495e441bb59313720b79e9a4",
      "value": 112
     }
    },
    "0a7006b93aa644caa1f830486a38f2e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50ee3feb8a5d4914beadc9799e7483aa",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a69e6ccd2a4a406c91b0a26e57b0ec30",
      "value": 53
     }
    },
    "0aee7c0e3acb4db393b1aa3d64440b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ba29c6cac854f64baf07d40e0803895": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bc91addb0f34d7f9c17b474090e6501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ceb23b8ae894d85ba7ce4fa27bd0648": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f07c489ee664a4d8ffbbe92ac969cab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f23f43179604143b51146b7d3198607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fd1bf10997c4caba64f121bce009a08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24fc139b1443486195f3bbc93f6812cb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d99fdbc5a364e90b4389468c93886cc",
      "value": 1
     }
    },
    "100a230e69e1495cb5393b2223585653": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ed61e1e6f714b15a6b118f2bbef4c47",
      "placeholder": "​",
      "style": "IPY_MODEL_49fd834ce84c45558e08b2db3d4fa4b3",
      "value": " 612/612 [00:00&lt;00:00, 80.5kB/s]"
     }
    },
    "103b02dda6f94a0e88785e639aea0322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10836b558e1a443c892ef53f413bfcd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12320e5f2798412c8d626f4d564a9afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "124d802d693b4f6dbfe00c7a37d59307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "152a45558f8b4c9eaa99a6d918746f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "184ddc3a33274d70a3775b52f6d7a919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e5a0261dc96455ea16067b137522190",
      "placeholder": "​",
      "style": "IPY_MODEL_421211f2d5d24c9d91771923a1d48422",
      "value": "config.json: 100%"
     }
    },
    "1953357f073c4c9c831f549c50c4649c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c973315221a4965b94102bda928677a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "203c31490aff4bffb223f91fadb277a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21aee6958542461e89270e438540b1d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e18a139aa1184d4c970d6a32e3e1ce72",
      "placeholder": "​",
      "style": "IPY_MODEL_124d802d693b4f6dbfe00c7a37d59307",
      "value": " 90.9M/90.9M [00:01&lt;00:00, 128MB/s]"
     }
    },
    "24fc139b1443486195f3bbc93f6812cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "321ea8ba5190492fabe1bf8b16f59641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "388a0c605c234e80816750a072531667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b64fde42b614b0384901deaae1e7309",
       "IPY_MODEL_a00852d5c2a7431f8d780f141f47dc2c",
       "IPY_MODEL_7f12fe9381b04e37bc215ef0f69600be"
      ],
      "layout": "IPY_MODEL_0f23f43179604143b51146b7d3198607"
     }
    },
    "3ddebb3f8c5c4c0cad2a3070699eb247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ed61e1e6f714b15a6b118f2bbef4c47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400f2572c3834034899c92a0699127b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "421211f2d5d24c9d91771923a1d48422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44cf97cf9a474d09855eaa91f811a047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc34adb28cd84ddda931c28b6a02d560",
      "placeholder": "​",
      "style": "IPY_MODEL_48073bc8273c4319863d29acac30a449",
      "value": " 116/116 [00:00&lt;00:00, 15.3kB/s]"
     }
    },
    "45324baa7d0f46c6b92547973f405533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f3e9fd338c945a7bb090e9b85efd654",
      "placeholder": "​",
      "style": "IPY_MODEL_f76ce00e79e64372b633da51f8fcfedc",
      "value": "Loading weights: 100%"
     }
    },
    "4617358298a04411805432945806ee5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48073bc8273c4319863d29acac30a449": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48d1d887b7e54414b101f1843c155d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49fd834ce84c45558e08b2db3d4fa4b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a35e599e8694e758a426185da996848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8448aee8f874ecc9f44ae1b2f76d826",
      "placeholder": "​",
      "style": "IPY_MODEL_eb7de8020b7b4d6f8ce01f1c7f9fc5bb",
      "value": "model.safetensors: 100%"
     }
    },
    "4a72773701f54e2cad530f409c5cd1c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a7c31a76fc9493daab759b2ae55773e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80374424dcde493ebca4faba22dd60b8",
      "placeholder": "​",
      "style": "IPY_MODEL_9d47580c2cc4429a9d2587eb0f65f63f",
      "value": " 103/103 [00:00&lt;00:00, 987.97it/s, Materializing param=pooler.dense.weight]"
     }
    },
    "50ee3feb8a5d4914beadc9799e7483aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52c06a3b4212423380622b21a6bdd16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86ecd893c2524304bb1b8caa821dde20",
       "IPY_MODEL_09c2ed0a73064af0aded60394b07bd45",
       "IPY_MODEL_f60acf6d13cb44098eb12aa0deb028eb"
      ],
      "layout": "IPY_MODEL_fc0da9e60b1e47f18f569eef7449716f"
     }
    },
    "531c26f657d842378324b1a20e919fd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "547516fa6c814160a671ce5e21855c4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54ba441a824e41989771538ba067f285": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aaaae36ac2a4f7b86cd49a7f60a2823": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae637d714ba442a8dac72629842bb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b4f709b0efd422396b402b8ee00f986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b555ba2b2bf4db5842b7470b26463f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7cc3a5746d8410ba233fdffda6b43c6",
      "placeholder": "​",
      "style": "IPY_MODEL_0361a1cbed894fe49e47b5a1164250f8",
      "value": " 10.5k/? [00:00&lt;00:00, 1.17MB/s]"
     }
    },
    "5b64a5b176984b3bbb38e59760eb2bcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cd3bf01885d4e73abafdca6030ddc69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dad3f51c5704ca481349958262c6755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63167ce30aa24b338ab4738822a66a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "685d82f06451494eabaae8708d90d9c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_750b4d5a3ebe48f890c88967466ba8c0",
      "placeholder": "​",
      "style": "IPY_MODEL_1953357f073c4c9c831f549c50c4649c",
      "value": "tokenizer.json: "
     }
    },
    "687c4ea946c9462ab3af5407436b9e91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96eb63f7c50f48979ddc966657f68a0b",
      "placeholder": "​",
      "style": "IPY_MODEL_5b4f709b0efd422396b402b8ee00f986",
      "value": " 12/12 [00:01&lt;00:00, 10.27it/s]"
     }
    },
    "6ac84be5507f436ca96c66adf0530af8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c738b9eb27b244bab71e8dd53835c53e",
       "IPY_MODEL_06dc79abdaf54fd4874a95e8b15b10a7",
       "IPY_MODEL_70387217e487473d9f5f7130099dc544"
      ],
      "layout": "IPY_MODEL_54ba441a824e41989771538ba067f285"
     }
    },
    "6b4a78bccc534f23aa139843cf7825d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b755017e21248939d01df24bda77c61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e266059709c4e8da76ac8b432aebb2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_952865af8cc14f8fada9d67fd1c387cc",
       "IPY_MODEL_0fd1bf10997c4caba64f121bce009a08",
       "IPY_MODEL_5b555ba2b2bf4db5842b7470b26463f9"
      ],
      "layout": "IPY_MODEL_4617358298a04411805432945806ee5e"
     }
    },
    "6fd4206a037f4d74a838c6a1b6a9e8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a67b41eee7104c8ea686f56951975700",
       "IPY_MODEL_b2e542f080f24845893b78ccd8e4d2fc",
       "IPY_MODEL_44cf97cf9a474d09855eaa91f811a047"
      ],
      "layout": "IPY_MODEL_321ea8ba5190492fabe1bf8b16f59641"
     }
    },
    "70387217e487473d9f5f7130099dc544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe9d1835c02845f4adc03a3adea46f27",
      "placeholder": "​",
      "style": "IPY_MODEL_3ddebb3f8c5c4c0cad2a3070699eb247",
      "value": " 349/349 [00:00&lt;00:00, 41.2kB/s]"
     }
    },
    "711d899c4510446e8a30a5c1f03af7c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73060e4d9a5740fc83c43b17a3d27926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec9ee1e6da94496aaa424ada2c2cb6a9",
       "IPY_MODEL_948a95f038304279804e902c66ca985c",
       "IPY_MODEL_966c55f7933e4568ba729df29d395f08"
      ],
      "layout": "IPY_MODEL_a9a6595e66b24c7392fd289b4ec4e834"
     }
    },
    "7386d0c375694f0b9c3ce6f74568e37f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7419de8221bc4ff0b47c494fe9e69cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd769ee14ae44ff687f217a5fb66959f",
       "IPY_MODEL_85a899b958c04ff2a7160ddcf1639e38",
       "IPY_MODEL_092f642e4feb48b58db627031c80a5ca"
      ],
      "layout": "IPY_MODEL_b692ae2291324c03bb7710e10eb4d30e"
     }
    },
    "750b4d5a3ebe48f890c88967466ba8c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f905f415e045f5a979ac3d110a0625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "773e6fdb95054b5f9861bc25bfda4f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78e4b7f0cb254069820a1e45ba5485a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a35e599e8694e758a426185da996848",
       "IPY_MODEL_954d6b552e624d85819cdd5b5781ace3",
       "IPY_MODEL_21aee6958542461e89270e438540b1d1"
      ],
      "layout": "IPY_MODEL_ea2408f84e09467da81c4b80a943c602"
     }
    },
    "7d99fdbc5a364e90b4389468c93886cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e5a0261dc96455ea16067b137522190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f12fe9381b04e37bc215ef0f69600be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcf464f966234150a0ebfab001017465",
      "placeholder": "​",
      "style": "IPY_MODEL_e8beb0303ce847379c8de7bd89bba663",
      "value": " 350/350 [00:00&lt;00:00, 38.1kB/s]"
     }
    },
    "80374424dcde493ebca4faba22dd60b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843ef5a9d5054ed486b2cac12d5e4943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dad3f51c5704ca481349958262c6755",
      "placeholder": "​",
      "style": "IPY_MODEL_c941a4f50962445aa187619d9343fcaa",
      "value": " 466k/? [00:00&lt;00:00, 14.1MB/s]"
     }
    },
    "85a899b958c04ff2a7160ddcf1639e38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b64a5b176984b3bbb38e59760eb2bcc",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_711d899c4510446e8a30a5c1f03af7c2",
      "value": 190
     }
    },
    "8615a6a6397a488a8a831eaa3dde26ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bc91addb0f34d7f9c17b474090e6501",
      "placeholder": "​",
      "style": "IPY_MODEL_a86462277bc54ec6a006ac183263cfa6",
      "value": "Batches: 100%"
     }
    },
    "86ecd893c2524304bb1b8caa821dde20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da06737b4e294ebd8bae23fd72e8206e",
      "placeholder": "​",
      "style": "IPY_MODEL_0ceb23b8ae894d85ba7ce4fa27bd0648",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "89ec2573750c4e7d9c5fb18871dc3cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_184ddc3a33274d70a3775b52f6d7a919",
       "IPY_MODEL_8aa9e93254344b30a5040956a5320ea3",
       "IPY_MODEL_100a230e69e1495cb5393b2223585653"
      ],
      "layout": "IPY_MODEL_400f2572c3834034899c92a0699127b0"
     }
    },
    "8aa9e93254344b30a5040956a5320ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ba29c6cac854f64baf07d40e0803895",
      "max": 612,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df68c0b1156f4d40b719c68cdc28b493",
      "value": 612
     }
    },
    "8b9538c5c6d44c179064701fff51d6f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8615a6a6397a488a8a831eaa3dde26ed",
       "IPY_MODEL_9a9a342e98d040feb56ffc453701e35d",
       "IPY_MODEL_687c4ea946c9462ab3af5407436b9e91"
      ],
      "layout": "IPY_MODEL_1c973315221a4965b94102bda928677a"
     }
    },
    "8d62d68952e140afbadb2c65c17a5f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f3e9fd338c945a7bb090e9b85efd654": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "948a95f038304279804e902c66ca985c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_001e44680e4c4fae87ea4ae9e0323227",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0820732b1eb4c9c9f50d2f6f8db3a2b",
      "value": 1
     }
    },
    "952865af8cc14f8fada9d67fd1c387cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d62d68952e140afbadb2c65c17a5f2b",
      "placeholder": "​",
      "style": "IPY_MODEL_103b02dda6f94a0e88785e639aea0322",
      "value": "README.md: "
     }
    },
    "954d6b552e624d85819cdd5b5781ace3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b755017e21248939d01df24bda77c61",
      "max": 90868376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_203c31490aff4bffb223f91fadb277a8",
      "value": 90868376
     }
    },
    "966c55f7933e4568ba729df29d395f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_531c26f657d842378324b1a20e919fd8",
      "placeholder": "​",
      "style": "IPY_MODEL_6b4a78bccc534f23aa139843cf7825d0",
      "value": " 232k/? [00:00&lt;00:00, 4.37MB/s]"
     }
    },
    "96eb63f7c50f48979ddc966657f68a0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9a342e98d040feb56ffc453701e35d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efddee3852a241bca0ebf255739909ff",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3e18a4f2dab4747a70012e2b22f2350",
      "value": 12
     }
    },
    "9b64fde42b614b0384901deaae1e7309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfade998fc6c4824be853e595ed107dd",
      "placeholder": "​",
      "style": "IPY_MODEL_0aee7c0e3acb4db393b1aa3d64440b6c",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9d1be63d01e4447a8095784ed07a1e34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d47580c2cc4429a9d2587eb0f65f63f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f4f6b7d495e441bb59313720b79e9a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a00852d5c2a7431f8d780f141f47dc2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5cc9cd9d9334da6933eb33117913f0a",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6eace21bfc549989e84e4a1e7f34533",
      "value": 350
     }
    },
    "a0820732b1eb4c9c9f50d2f6f8db3a2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a67b41eee7104c8ea686f56951975700": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_006294675d3941458f54fd12cf2826af",
      "placeholder": "​",
      "style": "IPY_MODEL_9d1be63d01e4447a8095784ed07a1e34",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "a69e6ccd2a4a406c91b0a26e57b0ec30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7357d54281d4641957f974737e7e84f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a86462277bc54ec6a006ac183263cfa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9a6595e66b24c7392fd289b4ec4e834": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adab518d679242f88115f919206df001": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45324baa7d0f46c6b92547973f405533",
       "IPY_MODEL_b5552eceab5145daa640df28a3bf88f5",
       "IPY_MODEL_4a7c31a76fc9493daab759b2ae55773e"
      ],
      "layout": "IPY_MODEL_c97304670cf74c70808911e048c5fe19"
     }
    },
    "b2e542f080f24845893b78ccd8e4d2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5a32f1579ff4b378706fc5816642cc8",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd64bfa0c0474aa1a112f1dbe3842dc7",
      "value": 116
     }
    },
    "b54cfd03086c4c8e878bdfd2c5ce9c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7dfc341b9f2467d9bf71b14feac176d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_152a45558f8b4c9eaa99a6d918746f6e",
      "value": 1
     }
    },
    "b5552eceab5145daa640df28a3bf88f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be397afe174b4c9cafb6a69317e96416",
      "max": 103,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf909adfbdca48909350450e471a7e8a",
      "value": 103
     }
    },
    "b569672b051d4ef9b6dd250328a2a2cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_685d82f06451494eabaae8708d90d9c9",
       "IPY_MODEL_b54cfd03086c4c8e878bdfd2c5ce9c21",
       "IPY_MODEL_843ef5a9d5054ed486b2cac12d5e4943"
      ],
      "layout": "IPY_MODEL_ef27c2f15b1c4472b215973097858ba5"
     }
    },
    "b692ae2291324c03bb7710e10eb4d30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc34adb28cd84ddda931c28b6a02d560": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc825ca42a804ce4b6ba7d678a0af366": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd64bfa0c0474aa1a112f1dbe3842dc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be397afe174b4c9cafb6a69317e96416": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfade998fc6c4824be853e595ed107dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3e18a4f2dab4747a70012e2b22f2350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c738b9eb27b244bab71e8dd53835c53e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_773e6fdb95054b5f9861bc25bfda4f6f",
      "placeholder": "​",
      "style": "IPY_MODEL_bc825ca42a804ce4b6ba7d678a0af366",
      "value": "modules.json: 100%"
     }
    },
    "c7cc3a5746d8410ba233fdffda6b43c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8a381a0f75244efac263d955feaa61a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c941a4f50962445aa187619d9343fcaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c97304670cf74c70808911e048c5fe19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf909adfbdca48909350450e471a7e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5cc9cd9d9334da6933eb33117913f0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73ab88a270441bdb0cbf99c840db267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e202b6bda6d6476b807ecd6f53acf532",
      "placeholder": "​",
      "style": "IPY_MODEL_48d1d887b7e54414b101f1843c155d66",
      "value": " 53.0/53.0 [00:00&lt;00:00, 6.56kB/s]"
     }
    },
    "d8448aee8f874ecc9f44ae1b2f76d826": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d85311b89c014e8686d788c11bbf5563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fab4221220d64df6bc706b88446f9c34",
       "IPY_MODEL_0a7006b93aa644caa1f830486a38f2e2",
       "IPY_MODEL_d73ab88a270441bdb0cbf99c840db267"
      ],
      "layout": "IPY_MODEL_5aaaae36ac2a4f7b86cd49a7f60a2823"
     }
    },
    "da06737b4e294ebd8bae23fd72e8206e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcf464f966234150a0ebfab001017465": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df68c0b1156f4d40b719c68cdc28b493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e18a139aa1184d4c970d6a32e3e1ce72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e202b6bda6d6476b807ecd6f53acf532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3c58e28774a440588a562b82ff44737": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5a32f1579ff4b378706fc5816642cc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6eace21bfc549989e84e4a1e7f34533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7dfc341b9f2467d9bf71b14feac176d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "e8beb0303ce847379c8de7bd89bba663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea2408f84e09467da81c4b80a943c602": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb7de8020b7b4d6f8ce01f1c7f9fc5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec9ee1e6da94496aaa424ada2c2cb6a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8a381a0f75244efac263d955feaa61a",
      "placeholder": "​",
      "style": "IPY_MODEL_10836b558e1a443c892ef53f413bfcd1",
      "value": "vocab.txt: "
     }
    },
    "ef27c2f15b1c4472b215973097858ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efddee3852a241bca0ebf255739909ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f60acf6d13cb44098eb12aa0deb028eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7386d0c375694f0b9c3ce6f74568e37f",
      "placeholder": "​",
      "style": "IPY_MODEL_12320e5f2798412c8d626f4d564a9afe",
      "value": " 112/112 [00:00&lt;00:00, 14.1kB/s]"
     }
    },
    "f76ce00e79e64372b633da51f8fcfedc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fab4221220d64df6bc706b88446f9c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7357d54281d4641957f974737e7e84f",
      "placeholder": "​",
      "style": "IPY_MODEL_63167ce30aa24b338ab4738822a66a5e",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "fc0da9e60b1e47f18f569eef7449716f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd769ee14ae44ff687f217a5fb66959f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75f905f415e045f5a979ac3d110a0625",
      "placeholder": "​",
      "style": "IPY_MODEL_5ae637d714ba442a8dac72629842bb7f",
      "value": "config.json: 100%"
     }
    },
    "fe9d1835c02845f4adc03a3adea46f27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
